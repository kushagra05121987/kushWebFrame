Node --- 
Dependencies attribute is used for production environment while devDependencies are used for local development environment.
dependencies are install when using npm install on a directory having package.json or npm install $package on other directory not having packge.json
devDependencies are installed using npm install on a directory having package.json unless --production is supplied so if we run 
npm install --production then devDependencies are not installed or if we run npm install $package on a directory not having package.json file then deveDependencies are not installed unless we give --dev option.

Grunt -- 
watch options

these braces are just to create a holder for examples below which helps in rolling the code up they are not required in actual code
{
    options.spawn
    Type: Boolean
    Default: true

    Whether to spawn task runs in a child process. Setting this option to false speeds up the reaction time of the watch (usually 500ms faster for most) and allows subsequent task runs to share the same context. Not spawning task runs can make the watch more prone to failing so please use as needed.

    Example:

    watch: {
    scripts: {
        files: ['**/*.js'],
        tasks: ['jshint'],
        options: {
        spawn: false,
        },
    },
    },
    For backwards compatibility the option nospawn is still available and will do the opposite of spawn.

    options.interrupt
    Type: Boolean
    Default: false

    As files are modified this watch task will spawn tasks in child processes. The default behavior will only spawn a new child process per target when the previous process has finished. Set the interrupt option to true to terminate the previous process and spawn a new one upon later changes.

    Example:

    watch: {
    scripts: {
        files: '**/*.js',
        tasks: ['jshint'],
        options: {
        interrupt: true,
        },
    },
    },

    options.event
    Type: String|Array
    Default: 'all'

    Specify the type of watch events that triggers the specified task. This option can be one or many of: 'all', 'changed', 'added' and 'deleted'.

    Example:

    watch: {
    scripts: {
        files: '**/*.js',
        tasks: ['generateFileManifest'],
        options: {
        event: ['added', 'deleted'],
        },
    },
    },

    options.reload
    Type: Boolean
    Default: false

    By default, if Gruntfile.js is being watched, then changes to it will trigger the watch task to restart, and reload the Gruntfile.js changes. When reload is set to true, changes to any of the watched files will trigger the watch task to restart. This is especially useful if your Gruntfile.js is dependent on other files.

    watch: {
    configFiles: {
        files: [ 'Gruntfile.js', 'config/*.js' ],
        options: {
        reload: true
        }
    }
    }

    options.livereload
    Type: Boolean|Number|Object
    Default: false

    Set to true or set livereload: 1337 to a port number to enable live reloading. Default and recommended port is 35729.

    If enabled a live reload server will be started with the watch task per target. Then after the indicated tasks have run, the live reload server will be triggered with the modified files.

    See also how to enable livereload on your HTML.

    Example:

    watch: {
    css: {
        files: '**/*.sass',
        tasks: ['sass'],
        options: {
        livereload: true,
        },
    },
    },
    Passing an object to livereload allows listening on a specific port and hostname/IP or over https connections (by specifying key and cert paths).

    Example:

    watch: {
    css: {
        files: '**/*.sass',
        tasks: ['sass'],
        options: {
        livereload: {
            host: 'localhost',
            port: 9000,
            key: grunt.file.read('path/to/ssl.key'),
            cert: grunt.file.read('path/to/ssl.crt')
            // you can pass in any other options you'd like to the https server, as listed here: http://nodejs.org/api/tls.html#tls_tls_createserver_options_secureconnectionlistener
        }
        },
    },
    },
}


When working with core javascript functions functions like get element by id and get elements by classname , etc. are bound to find children on the element on which it is called.
So for example when we do something like document.forms[0].email.getElementsByTagName('input') this will find all the input elements inside the element with name email. 

We can also bind elevents like document.forms[0].onmouseover = function(event) {
    console.log(e.target)
}

We can do the same with document.forms[0].addEventListener("click", function(e){console.log('inside clicked')})

If we use submit or any event as name of the element in form then that event will not work because form.<Event Name> is going to give the element and not the event so for example if my submit button's name is submit then form.submit() will not work because form.submit is now an element's name not a function.


Html5 has formenctype attribute to override the enctype given in form 

application/x-www-form-urlencoded ----	Default. All characters are encoded before sent (spaces are converted to "+" symbols, and special characters are converted to ASCII HEX values). Example -- MyVariableOne=ValueOne&MyVariableTwo=ValueTwo

multipart/form-data ----	No characters are encoded. This value is required when you are using forms that have a file upload control

text/plain ----  Spaces are converted to "+" symbols, but no special characters are encoded


During Html5 Validation we get following properties on element getting validated inside javascript 
console.log(elem.validationMessage);
elem.setCustomValidity("custom validation message");
console.log(elem.checkValidity());
console.log(elem.validity);
console.log(elem.validationMessage);
console.log(elem.willValidate);

in addition to this we can have an event oninvalid on the element by which we can trap the invalidation event of an element if we dont want to do it on submit or press of any other button

elem.oninvalid = function(e) {
	console.log("%c On Invalid Event ", "background: black; color: darkgreen", e.target.validity)
}

There are two psuedo elements that we get with html 5 validation they are :valid and :invalid

If we want to insert html using css then we can use before and after psuedo elements to do that.
Remember property is necessary for these psuedo elements to work.

var elem               = document.createElement('div');
    elem.id            = 'notify';
    elem.style.display = 'none';
    form.appendChild(elem);

Filter method in jquery
Reduce the set of matched elements to those that match the selector or pass the function's test.

<ul>
  <li>list item 1</li>
  <li>list item 2</li>
  <li>list item 3</li>
  <li>list item 4</li>
  <li>list item 5</li>
  <li>list item 6</li>
</ul>
We can apply this method to the set of list items:

1
$( "li" ).filter( ":even" ).css( "background-color", "red" );
<ul>
  <li><strong>list</strong> item 1 - one strong tag</li>
  <li><strong>list</strong> item <strong>2</strong> -
    two <span>strong tags</span></li>
  <li>list item 3</li>
  <li>list item 4</li>
  <li>list item 5</li>
  <li>list item 6</li>
</ul>
We can select the list items, then filter them based on their contents:

$( "li" )
  .filter(function( index ) {
    return $( "strong", this ).length === 1;
  })
    .css( "background-color", "red" );

Css3 sibling selectors
ADJACENT SIBLING SELECTORS
p + p { font-size: smaller; } /* Selects all paragraphs that follow another paragraph */
#title + ul { margin-top: 0; } /* Selects an unordered list that directly follows the element with ID title */
GENERAL SIBLING SELECTORS
The general sibling combinator selector is very similar to the adjacent sibling combinator selector we just looked at. The difference is that that the element being selected doesn't need to immediately succeed the first element, but can appear anywhere after it.
If we use the same example structure as above, the last <p> element will be selected by p ~ p as well, because it is preceded by another <p> element, even though not directly.

oninput vs onchange event
oninput event occurs when the text content of an element is changed through the user interface.
onchange occurs when the selection, the checked state or the contents of an element have changed. In some cases, it only occurs when the element loses the focus. The onchange attribute can be used with: <input>, <select>, and <textarea>.


The DOM input event is fired synchronously when the value of an <input>, <select>, or <textarea> element is changed. For input elements with type=checkbox or type=radio, the input event should fire when a user toggles the control (via touch, mouse or keyboard) per the HTML5 specification, but historically, this has not been the case. Check compatibility, or attach to the change event instead for elements of these types.

Additionally, the input event fires on a contenteditable editor when its contents are changed. In this case, the event target is the editing host element. If there are two or more elements which have contenteditable as true, “editing host” is the nearest ancestor element whose parent isn’t editable. Similarly, it’s also fired on root element of designMode editors.


<input type="text" class="test"/>
<textarea></textarea>
<select>
  <option>1</option>
  <option>2</option>
  <option>3</option>
</select>
<pre></pre>

$(".test").on("input", function() {
	$("pre").prepend("\nOn Input.");
}).on("change", function () {
    $("pre").prepend("\nOn change.");
}).on("focus", function () {
    $("pre").prepend("\nOn focus.");
}).on("blur", function () {
    $("pre").prepend("\nOn blur.");
});

$("textarea").change(function() {
	$('pre').prepend("\n On change text area")
}).on("input", function() {
	$("pre").prepend("\nOn Input textarea.");
})

$("select").change(function() {
	$('pre').prepend("\n On change select")
}).on("input", function() {
	$("pre").prepend("\nOn Input Select.");
})

So for html5 custom validations we can check for elements validation as user types using input event.
But still following process is available.

There are two events we need to deal with. First, the invalid event which calls when the value of the input does not match the pattern. We’ll run the following within the invalid event:

input.addEventListener('invalid', function(event){
    event.preventDefault(); ----<<<<<<<---->>>>>>> ------<<<<<< This thing here prevents html5 error message popup from showing. So that we can show our own error messages.
    if ( ! event.target.validity.valid ) {
        elem.textContent   = 'Username should only contain lowercase letters e.g. john';
        elem.className     = 'error';
        elem.style.display = 'block';
 
        input.className    = 'invalid animated shake';
    }
});
Herein, with event.preventDefault();, we prevent the default behavior so that the default browser popup message does not appear. Instead, we are going to show our own through the new div element. We add the text message within the content, add a new class, error and show the message by setting the display to block.

For event bubbling 
A handler on a parent element can always get the details about where it actually happened.
The most deeply nested element that caused the event is called a target element, accessible as event.target.
Note the differences from this (=event.currentTarget):

event.target – is the “target” element that initiated the event, it doesn’t change through the bubbling process.
this – is the “current” element, the one that has a currently running handler on it.

event.stopImmediatePropagation()
If an element has multiple event handlers on a single event, then even if one of them stops the bubbling, the other ones still execute.

In other words, event.stopPropagation() stops the move upwards, but on the current element all other handlers will run.

To stop the bubbling and prevent handlers on the current element from running, there’s a method event.stopImmediatePropagation(). After it no other handlers execute.

To catch an event on the capturing phase, we need to set the 3rd argument of addEventListener to true.

There are two possible values for that optional last argument:

If it’s false (default), then the handler is set on the bubbling phase.
If it’s true, then the handler is set on the capturing phase.
Note that while formally there are 3 phases, the 2nd phase (“target phase”: the event reached the element) is not handled separately: handlers on both capturing and bubbling phases trigger at that phase.

<style>
  body * {
    margin: 10px;
    border: 1px solid blue;
  }
</style>

<form>FORM
  <div>DIV
    <p>P</p>
  </div>
</form>

<script>
  for(let elem of document.querySelectorAll('*')) {
    elem.addEventListener("click", e => alert(`Capturing: ${elem.tagName}`), true);
    elem.addEventListener("click", e => alert(`Bubbling: ${elem.tagName}`));
  }
</script>

The code sets click handlers on every element in the document to see which ones are working.

If you click on <p>, then the sequence is:

HTML → BODY → FORM → DIV → P (capturing phase, the first listener), and then:
P → DIV → FORM → BODY → HTML (bubbling phase, the second listener).
Please note that P shows up two times: at the end of capturing and at the start of bubbling.

There’s a property event.eventPhase that tells us the number of the phase on which the event was caught. But it’s rarely used, because we usually know it in the handler.


Hoisting is a JavaScript mechanism where variables and function declarations are moved to the top of their scope before code execution.

var a = 100;
It is however important to remember that in the background, JavaScript is religiously declaring then initialising our variables.

As we mentioned before, all variable and function declarations are hoisted to the top of their scope. I should also add that variable declarations are processed before any code is executed.

However, in contrast, undeclared variables do not exist until code assigning them is executed. Therefore, assigning a value to an undeclared variable implicitly creates it as a global variable when the assignment is executed. This means that, all undeclared variables are global variables.


global variables
console.log(hoist); // Output: undefined

var hoist = 'The variable has been hoisted.';

We expected the result of the log to be: ReferenceError: hoist is not defined, but instead, its output is undefined.

Why has this happened?

This discovery brings us closer to wrangling our prey.

JavaScript has hoisted the variable declaration. This is what the code above looks like to the interpreter:

var hoist;

console.log(hoist); // Output: undefined
hoist = 'The variable has been hoisted.';

Function scoped variables
As we've seen above, variables within a global scope are hoisted to the top of the scope. Next, let's look at how function scoped variables are hoisted.

function hoist() {
  console.log(message);
  var message='Hoisting is all the rage!'
}

hoist();
Take an educated guess as to what our output might be.

If you guessed, undefined you're right. If you didn't, worry not, we'll soon get to the bottom of this.

This is how the interpreter views the above code:

function hoist() {
  var message;
  console.log(message);
  message='Hoisting is all the rage!'
}

hoist(); // Ouput: undefined

Strict Mode
Thanks to a utility of the es5 version of JavaScript known as strict-mode, we can be more careful about how we declare our variables. By enabling strict mode, we opt into a restricted variant of JavaScript that will not tolerate the usage of variables before they are declared.

Running our code in strict mode:

Eliminates some silent JavaScript errors by changing them to explicit throw errors which will be spit out by the interpreter.
Fixes mistakes that make it difficult for JavaScript engines to perform optimisations.
Prohibits some syntax likely to be defined in future versions of JavaScript.
We enable strict mode by prefacing our file or function with

'use strict';

// OR
"use strict";
Let's test it out.

'use strict';

console.log(hoist); // Output: ReferenceError: hoist is not defined
hoist = 'Hoisted'; 

const PI;
console.log(PI); // Ouput: SyntaxError: Missing initializer in const declaration
PI=3.142;
Therefore, a constant variable must be both declared and initialised before use.


Function declarations
These are of the following form and are hoisted completely to the top. Now, we can understand why JavaScript enable us to invoke a function seemingly before declaring it.

hoisted(); // Output: "This function has been hoisted."

function hoisted() {
  console.log('This function has been hoisted.');
};

Function expressions
Function expressions, however are not hoisted.

expression(); //Output: "TypeError: expression is not a function

var expression = function() {
  console.log('Will this work?');
};


function a()                                                
{
    var x = 10;

    function x() {
        return 20;
    }

    return x;
}

above will be hoisted like
function a() {
  var x;
  function x() { // this function is assigned to variable indicator "x"
    return 20;
  }
  x = 10; // this overrides the variable indicator "x"
  return x;
}

so variable declaration goes first then function declaration then variable assignment.


javascript ajax for ie 6 or lesser versions
if (window.XMLHttpRequest) {
    //Firefox, Opera, IE7, and other browsers will use the native object
    var request = new XMLHttpRequest();
} else {
    //IE 5 and 6 will use the ActiveX control
    var request = new ActiveXObject("Microsoft.XMLHTTP");
}


req.open( "GET", 'boo.txt', false );
the third parameter is for making the request to synchronous or asynchronous.

req.onreadystatechange = function()
{
    if( req.readyState == 4 && req.status == 200 )
    {
        document.write( req.responseText );
    }
}

0 – The default value when the XMLHttpRequest object is created.
1 – The open() method has been called.
2 – The send() method has been called.
3 – Some data has been retrieved, but the request isn’t finished.
4 – All data has been retrieved and the request is finished.

false in open makes it synchronous default value is true which is asynchronous.

XMLHttpRequest {onreadystatechange: null, readyState: 0, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, …}
onabort : null
onerror : null 
onload : null
onloadend : null
onloadstart : null
onprogress : null
onreadystatechange : null
ontimeout : null
readyState : 0
response : ""
responseText : ""
responseType : ""
responseURL : ""
responseXML : null
status : 0
statusText : ""
timeout : 0
upload :
XMLHttpRequestUpload {onloadstart: null, onprogress: null, onabort: null, onerror: null, onload: null, …}
withCredentials : false
__proto__ : XMLHttpRequest


// not all the events will work in synchronous calls but for asynchronous calls all the events will work.

for synchronous calls progress events was received only in onloadend event onloadstart evet didnot fire at all in synchronous call.
Timeout is zero in synchronous call and cannot be changed.

First on progress event for asynchronous calls is received in onLoadStart with lengthComputable: false and loaded:0 and readyState is 2
Second on progress event for asynchronous calls is received in onProgress with lengthComputable: true and loaded:<full length of the object received> and readyState is 3
Third on progress event for asynchronous calls is received in onLoadEnd with lengthComputable: true and loaded:<full length of the object received> and readyState is 4

So xhr.onProgress event gets fired only when complete object is received

for aborting the ajax request 
var xhr = new XMLHttpRequest(),
    method = "GET",
    url = "https://developer.mozilla.org/";
xhr.open(method,url,true);

xhr.send();

xhr.abort();

.ajaxStop() ->>> Register a handler to be called when all Ajax requests have completed. This is an Ajax Event.

Aborting jquery ajax request.
var calculationRequest = null;

function PerformAbortableCalculation()
{
        if(calculationRequest != null)
                calculationRequest.abort();
        calculationRequest = $.get("/tests/calc.php", function(data, textStatus)
        {
                alert(data);
        });
}


req.responseType is supposed to allow only the response type set in this variable as a response from server if response is different the this value is null.
responseText is based on responseType value if responseType is somthing other than text or '' then the responseText is empty.
responseText is string representation of response.
so if responseType is json then responseText is empty.

In jquery ajax responseType id dataType. dataType is you telling jQuery what kind of response to expect.

Accept header tells the server about the type of content it is expecting 
Content-type tells the server about the type of request it is sending.

dataType and accpets must mapped together.

in order to get the response header we need to use getResponseHeader('header name') method.
in order to get all the response headers we need to use getAllResponseHeaders() method.

To set request headers in ajax we can use two approaches by setting headers: {} property on ajax call or by xhr.setRequestHeader in beforeSend


The same-origin policy controls interactions between two different origins, such as when you use XMLHttpRequest or an <img> element. These interactions are typically placed in three categories:

Cross-origin writes are typically allowed. Examples are links, redirects and form submissions. Certain rarely used HTTP requests require preflight.
Cross-origin embedding is typically allowed. Examples are listed below.
Cross-origin reads are typically not allowed, but read access is often leaked by embedding. For example you can read the width and height of an embedded image, the actions of an embedded script, or the availability of an embedded resource.
Here are some examples of resources which may be embedded cross-origin:

JavaScript with <script src="..."></script>. Error messages for syntax errors are only available for same-origin scripts.
CSS with <link rel="stylesheet" href="...">. Due to the relaxed syntax rules of CSS, cross-origin CSS requires a correct Content-Type header. [...]

JSONP is nothing but json with padding. In order to accomplish this we make use of the fact that script tags are not a part of cross-origin restrictions .
So we can call any urls to read stuff using a callback query parameter in request url. The service endpoint responsding to this must give back the output as passing the json argument to that callback in url.
Example
function response(resposne) {
  return response;
}
http://www.abc.com/?callback=callMe
service enpoint should respond with 
callMe({json object values})

datatype:script or .getScript() method work the same they are used to read the resonse as javascript and return it as string.
$.ajax({
  url: url,
  dataType: "script",
  success: success
}); this is equivalent to 
$.getScript( "ajax/test.js", function( data, textStatus, jqxhr ) {
  console.log( data ); // Data returned
  console.log( textStatus ); // Success
  console.log( jqxhr.status ); // 200
  console.log( "Load was performed." );
});

when datatype is jsonp the default callback is supplie in the url if you want to overrite it then we can give an option like 
datatype: jsonp,
jsonp:function(){}

defining jquery function 
$.fn.myfunction = function() {
      alert('hello world');
      return this;
};

when calling function this will give the object on which it is called
so if we cann myfunction() then this will be window because its called on window.myfunction 

global (default: true)
Type: Boolean
Whether to trigger global Ajax event handlers for this request. The default is true. Set to false to prevent the global handlers like ajaxStart or ajaxStop from being triggered. This can be used to control various Ajax Events.

So if we call .json file in ajax jquery we dont get success method executed. The error in this case is unknow but if we use the same request for local server having same origin then it works fine.

Setting xhr.withCredentials = true inside beforeSend doesent work 
instead we need to use xhrFields key 
xhrFields: {
  withCredentials: true
}
withCredentials field need to be set on both server and ui side in order to start setting cookies from server on UI.
Cookies get set if requests are between same domains.

document.cookie are sent to the servers in ajax request when the requests are in same domain but local cookies dont get send to server unless they are set using Set-Cookie header.

Although CORS allows cross-origin requests, the cookies are still subject to the browser's same-origin policy, which means only pages from the same origin can read/write the cookie. withCredentials only means that any cookies set by the remote host are sent to that remote host. You will have to set the cookie from the remote server by using the Set-Cookie header.


upload: XMLHttpRequestUpload
onabort: null
onerror: null
onload: null
onloadend: null
onloadstart: null
onprogress: null
ontimeout: null

when events on upload are bound then events on core xhr object wont work or we can say if both core xhr events and upload events are bound then upload events will take precedence over core events exmaple if xhr.onloadstart and xhr.upload.onloadstart are bound at the same time the xhr.upload.onloadstart will be executed.
On readystate change will be executed on xhr object only.
onload gets executed after the ajax call is completed sucessfully but before onloadEnd is called its available on both xhr and xhr.upload

ProgressEvent {isTrusted: true, lengthComputable: true, loaded: 699, total: 699, type: "load", …}
bubbles:false
cancelBubble:false
cancelable:false
composed:false
currentTarget:XMLHttpRequest {onreadystatechange: null, readyState: 4, timeout: 4294967295, withCredentials: false, upload: XMLHttpRequestUpload, …}
defaultPrevented:false
eventPhase:0
isTrusted:true
lengthComputable:true
loaded:699
path:[]
returnValue:true
srcElement:XMLHttpRequest {onreadystatechange: null, readyState: 4, timeout: 4294967295, withCredentials: false, upload: XMLHttpRequestUpload, …}
target:XMLHttpRequest {onreadystatechange: null, readyState: 4, timeout: 4294967295, withCredentials: false, upload: XMLHttpRequestUpload, …}
timeStamp:2793.985
total:699
type:"load"

we get this object in 4 places onloadstart, onprogress, onload, onloadend.
We need to consider 3 things in this object
lengthComputable: true or false
loaded
total

lengthComputable - a read-only (Boolean) property indicating if the resource concerned by the ProgressEvent has a length that can be calculated
total - a read-only (Unsigned Long) property representing the total amount of work that the underlying process is in the progress of performing
loaded - a read-only (Unsigned Long) property representing the amount of work already performed by the underlying process

'responseXML' property from 'XMLHttpRequest': The value is only accessible if the object's 'responseType' is '' or 'document'

There are two progress events in a XmlHttpRequest object:

The response progress (XmlHttpRequest.onprogress)
This is when the browser is downloading the data from the server.

The request progress (XmlHttpRequest.upload.onprogress)
This is when the browser is sending the data to the server (including POST parameters, cookies, and files)

In your code you are using the response progress event, but what you need is the request progress event. This is how you do it:

$.ajax({
    async: true,
    contentType: file.type,
    data: file,
    dataType: 'xml',
    processData: false,
    success: function(xml){
        // Do stuff with the returned xml
    },
    type: 'post',
    url: '/fileuploader/' + file.name,
    xhr: function(){
        // get the native XmlHttpRequest object
        var xhr = $.ajaxSettings.xhr() ;
        // set the onprogress event handler
        xhr.upload.onprogress = function(evt){ console.log('progress', evt.loaded/evt.total*100) } ;
        // set the onload event handler
        xhr.upload.onload = function(){ console.log('DONE!') } ;
        // return the customized object
        return xhr ;
    }
});

onload event can be used as combination of onreadystate change and readystate = 4

.ajaxStart(): Register a handler to be called when the first Ajax request begins. This is an Ajax Event.

Note: Global callback functions should be set with their respective global Ajax event handler methods—.ajaxStart(), .ajaxStop(), .ajaxComplete(), .ajaxError(), .ajaxSuccess(), .ajaxSend()—rather than within the options object for $.ajaxSetup().

URL provides methods to generate url for blobs. So that we can directly show it in UI and also pass it to the api that accepts it.


WorkerGlobalScope interface is an interface representing scope of any worker.
Workers have no browsing context. This scope contains information usually conveyed by window object.
in this case event handlers, the console or the associated WorkerNavigator object.
WindowNavigator is just representation of window.navigator object.

This interface is usually specialized by each worker type:
DedicatedWorkerGlobalScope for dedicated workers, 
SharedWorkerGlobalScope for shared workers, and 
ServiceWorkerGlobalScope for ServiceWorker. 
The self property returns the specialized scope for each context.


Web workers are of three types 
Dedicated
Shared
Service

When main js starts a worker it spawns a new thread which runs in background without affecting other things.
It can use ajax calls aswell.
But workers don't have any browsing context so inorder to use the global context object window we use self.
	
Web Workers don't have a window object.
To access global state, use self instead, code that will work on both the main thread and the worker thread.
But note that you still won't be able to access or manipulate the parent DOM (e.g. get window.jQuery via self.jQuery).
While the main thread window self points to the Window object, in worker threads self points to a separate WorkerGlobalScope object.

window object is not equal to self object its just a reference to window object and provides the few methods available on window object such as navigator, location, etc. But setting a value in window object and then trying to access it in self is not going to work.

Shared workers can be accessed by multiple scripts and not just one script as in case of dedicated workers.
These scripts can be anywhere inside a different window or frame or script.

Inorder to comunicate in shared workers we need to use port object.
The port connection needs to be started either implicitly by use of the onmessage event handler or explicitly with the start() method before any messages can be posted

When using the start() method to open the port connection, it needs to be called from both the parent thread and the worker thread if two-way communication is needed.

myWorker.port.start();  // called in parent thread
port.start();  // called in worker thread, assuming the port variable references a port

myWorker.port.postMessage([squareNumber.value,squareNumber.value]);

onconnect = function(e) {
  var port = e.ports[0];

  port.onmessage = function(e) {
    var workerResult = 'Result: ' + (e.data[0] * e.data[1]);
    port.postMessage(workerResult);
  }
}

we use an onconnect handler to fire code when a connection to the port happens (i.e. when the onmessage event handler in the parent thread is setup, or when the start() method is explicitly called in the parent thread).

self is equivalent to window in worker file but gives WorkerGlobalScope object and not actual global scope object which in case of Dedicated worker is DedicatedWorkerGlobalScope and in case of shared SharedWorkerGlobalScope.

Service workers work only with https requests and async requests so localstorage and synchronous XHR are not allow.

Service worker scopes are restricted to both the location of service worker file and the current url.
If service worker file is inside a directory such as src then it will be restricted to track the fetching of
files inside that directory.

If the current page url or request url is different than the directory of service worker and we use scope like {scope: './'} then error is thown that the request we are trying to make is out of scope of service worker and then inorder to resolve this we need to move the service worker script to another location to match the request url or we need to add Service-Worker-Allowed: true or we can omit the scope argument.

Install event allows to registers specific resources for worker such as caches.
while install is happening we get one more event
event.waitUntill to wait untill the installation process is completed and install stage in resolved.
if install event is taking too long the we can even skip it by self.skipWaiting()

After the install is finished and is waiting for the clients using other service workers to be closed.

Activate state begins when there are no workers left on which clients are working. This stage can be used to clean up anything that was being used by other clients and workers and now after they have stopped they are no more required.

Activate events can also be extended and be waited for to be finished using same methods as above in install phase
event.waitUntill
and self.clients.claim() --- start handling and controlling all open clients without reloading them. 

So while serving script files from servers that have htaccess support we can set the response headers in htaccess file like 
Header add Custom-Header "parameter=value"
request will be 
GET / HTTP/1.1
Host: example.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
DNT: 1
Connection: keep-alive
Cache-Control: max-age=0

.to which the server responded with the following headers:

HTTP/1.1 200 OK
Server: nginx
Date: Mon, 01 Aug 2016 17:58:14 GMT
Content-Type: text/html; charset=UTF-8
Transfer-Encoding: chunked
Connection: keep-alive
X-Powered-By: PHP/5.6.24, PleskLin
strict-transport-security: max-age=63072000; includeSubDomains; preload
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Expires: 0
Custom-Header: parameter=value
Content-Language: en

there i can also check if file requested is a js file or not

Fetch API
There are new objects like Request, response and fetch().
Fetch is used to fetch any resource like a normal ajax call . It takes as an argument the request object or url string and returns back a promise object which can be clubbed with then and catch methods.
Then method receives Response object.

Promise<Response> fetch(input[, init]);
Parameters
input
This defines the resource that you wish to fetch. This can either be:
A USVString containing the direct URL of the resource you want to fetch. Some browsers accept blob: and data: as schemes.
A Request object.
init Optional
An options object containing any custom settings that you want to apply to the request. The possible options are:
method: The request method, e.g., GET, POST.
headers: Any headers you want to add to your request, contained within a Headers object or an object literal with ByteString values.
body: Any body that you want to add to your request: this can be a Blob, BufferSource, FormData, URLSearchParams, or USVString object. Note that a request using the GET or HEAD method cannot have a body.
mode: The mode you want to use for the request, e.g., cors, no-cors, or same-origin.
credentials: The request credentials you want to use for the request: omit, same-origin, or include. To automatically send cookies for the current domain, this option must be provided. Starting with Chrome 50, this property also takes a FederatedCredential instance or a PasswordCredential instance.
cache: The cache mode you want to use for the request: default, no-store, reload, no-cache, force-cache, or only-if-cached.
redirect: The redirect mode to use: follow (automatically follow redirects), error (abort with an error if a redirect occurs), or manual (handle redirects manually). In Chrome the default was follow before Chrome 47 and manual starting with Chrome 47.
referrer: A USVString specifying no-referrer, client, or a URL. The default is client.
referrerPolicy: Specifies the value of the referer HTTP header. May be one of no-referrer, no-referrer-when-downgrade, origin, origin-when-cross-origin, unsafe-url.
integrity: Contains the subresource integrity value of the request (e.g., sha256-BpfBw7ivV8q2jLiT13fxDYAe2tJllusRSZ273h2nFSE=).
keepalive: The keepalive option can be used to allow the request to outlive the page. Fetch with the keepalive flag is a replacement for the Navigator.sendBeacon() API. 
signal: An AbortSignal object instance; allows you to communicate with a fetch request and abort it if desired via an AbortController.

Request object is for preparing and creating a request object which can be passed to fetch.
It takes input and init as arguments.
Input can be url or another request object.
Init can be an options object with method, headers, body which can be Blob, BufferSource, FormData, URLSearchParams, USVString, or ReadableStream object, mode which can be cors, no-cors, same-origin, or navigate, credentials, etc

var myRequest = new Request(input, init);
Parameters
input
Defines the resource that you wish to fetch. This can either be:
A USVString containing the direct URL of the resource you want to fetch.
A Request object, effectively creating a copy. Note the following behavioural updates to retain security while making the constructor less likely to throw exceptions:
If this object exists on another origin to the constructor call, the Request.referrer is stripped out.
If this object has a Request.mode of navigate, the mode value is converted to same-origin.
init Optional
An options object containing any custom settings that you want to apply to the request. The possible options are:
method: The request method, e.g., GET, POST.
headers: Any headers you want to add to your request, contained within a Headers object or an object literal with ByteString values.
body: Any body that you want to add to your request: this can be a Blob, BufferSource, FormData, URLSearchParams, USVString, or ReadableStream object. Note that a request using the GET or HEAD method cannot have a body.
mode: The mode you want to use for the request, e.g., cors, no-cors, same-origin, or navigate. The default is cors. In Chrome the default is no-cors before Chrome 47 and same-origin starting with Chrome 47.
credentials: The request credentials you want to use for the request: omit, same-origin, or include. The default is omit. In Chrome the default is same-origin before Chrome 47 and include starting with Chrome 47.
cache: The cache mode you want to use for the request.
redirect: The redirect mode to use: follow, error, or manual. In Chrome the default is manual before Chrome 47 and follow starting with Chrome 47.
referrer: A USVString specifying no-referrer, client, or a URL. The default is client.
integrity: Contains the subresource integrity value of the request (e.g., sha256-BpfBw7ivV8q2jLiT13fxDYAe2tJllusRSZ273h2nFSE=).


Response is the object for preparing and creating a response along with body and headers. which can then be passed to other calling methods.

It takes two arguments body and init as options.
BOdy can be one of the following
Blob
BufferSource
FormData
ReadableStream
URLSearchParams
USVString

init takes following options
status,
statusText,
headers

headers in both request and response are an object of Headers which has some methods like get getall append delete has etc

File Blob and Filereader

File is an extension on Blob object. Its specific use is to create a reference object for a file which will give some meta properties of file such as size, last modified, name , type , etc.

File does not define any methods of its own. It inherits them from blob.

File constructor takes three arguments 
An Array of ArrayBuffer, ArrayBufferView, Blob, or DOMString objects — or a mix of any such objects. This is the file content encoded as UTF-8.
name of file,
options which include 
type and lastModified
var file = new File(["foo"], "foo.txt", {
  type: "text/plain",
});


Blob is the representation of file like objects in raw immutable form.
We can construct blob object from other non blob objects using Blob() constructor
Blob constructor takes two arguments
An Array of ArrayBuffer, ArrayBufferView, Blob, or DOMString objects — or a mix of any such objects. This is the file content encoded as UTF-8.
options which contains type -> the mine type of the file 
endings: which defines how the line breaks in the given data are supposed to be treated in new raw file. The values are native which converts all breaks into os specific breaks. Transparent which keeps the breaks as it is.

var aFileParts = ['<a id="a"><b id="b">hey!</b></a>']; // an array consisting of a single DOMString
var oMyBlob = new Blob(aFileParts, {type : 'text/html'}); // the blob

New blob can be constructed from another blob object using slice method
Slice is browser specific method which means for different browsers we have different variants of slice.

var blob = instanceOfBlob.slice([start [, end [, contentType]]]);

To obtain a Blob object for a file on the user's file system we use File object.


The FileReader object lets web applications asynchronously read the contents of files (or raw data buffers) stored on the user's computer, using File or Blob objects to specify the file or data to read.

Properties
FileReader.error Read only
A DOMException representing the error that occurred while reading the file.
FileReader.readyState Read only
A number indicating the state of the FileReader. This is one of the following:
EMPTY	0	No data has been loaded yet.
LOADING	1	Data is currently being loaded.
DONE	2	The entire read request has been completed.
FileReader.result Read only
The file's contents. This property is only valid after the read operation is complete, and the format of the data depends on which of the methods was used to initiate the read operation.

Event handlers
FileReader.onabort
A handler for the abort event. This event is triggered each time the reading operation is aborted.
FileReader.onerror
A handler for the error event. This event is triggered each time the reading operation encounter an error.
FileReader.onload
A handler for the load event. This event is triggered each time the reading operation is successfully completed.
FileReader.onloadstart
A handler for the loadstart event. This event is triggered each time the reading is starting.
FileReader.onloadend
A handler for the loadend event. This event is triggered each time the reading operation is completed (either in success or failure).
FileReader.onprogress
A handler for the progress event. This event is triggered while reading a Blob content.


Methods
FileReader.abort()
Aborts the read operation. Upon return, the readyState will be DONE.
FileReader.readAsArrayBuffer()
Starts reading the contents of the specified Blob, once finished, the result attribute contains an ArrayBuffer representing the file's data.
FileReader.readAsBinaryString() 
Starts reading the contents of the specified Blob, once finished, the result attribute contains the raw binary data from the file as a string.
FileReader.readAsDataURL()
Starts reading the contents of the specified Blob, once finished, the result attribute contains a data: URL representing the file's data.
FileReader.readAsText()
Starts reading the contents of the specified Blob, once finished, the result attribute contains the contents of the file as a text string.

FileReader object and File can be used with File , blob or even with FileList object from input elements.

FileList ->>> FileList is the object which represents the list of files in given file input element.
var inputFile = document.getElementsByName("file").item(0);
so inputFile.files will give FileList

createDocumentFragment doesnot modify the actual untill its added to html . It creates a virtual dom or fragment and we keep on doing modification to that but not to actual dom.

The difference is that a document fragment effectively disappears when you add it to the DOM. What happens is that all the child nodes of the document fragment are inserted at the location in the DOM where you insert the document fragment and the document fragment itself is not inserted. The fragment itself continues to exist but now has no children.

This allows you to insert multiple nodes into the DOM at the same time:

var frag = document.createDocumentFragment();
var textNode = frag.appendChild(document.createTextNode("Some text"));
var br = frag.appendChild(document.createElement("br"));
var body = document.body;
body.appendChild(frag);
alert(body.lastChild.tagName); // "BR"
alert(body.lastChild.previousSibling.data); // "Some text"
alert(frag.hasChildNodes()); // false

using document fragment we create an empty document fragment so anything like createDocumentFragment('div') has got no meaning. Once we create document-fragment we will need to append new elements to it. Then that is finally added to dom and fragment disappears and only child elements of fragment are left.

inroder to append elements we will anyhow need to use createElement and hence fragments maybe used to group all attachment into one fragment and the append only once.

createElement transparently in the backend keep manipulating the DOM though we not see it in the page but it actually modifies the dom.

File and Blobs cannot read file on local machine unless they are uploaded.

Script type
module: HTML5 For HTML5-compliant browsers the code is treated as a JavaScript module. The processing of the script contents is not affected by the charset and defer attributes.

Module types js are automatically 'use-strict'
Module types can use import and exports.
Module types behave like defer by default.
Defer by default
<!-- This script will execute after… -->
<script type="module" src="1.js"></script>

<!-- …this script… -->
<script src="2.js"></script>

<!-- …but before this script. -->
<script defer src="3.js"></script>

nomodule 
This Boolean attribute is set to indicate that the script should not be executed in browsers that support ES6 modules — in effect, this can be used to serve fallback scripts to older browsers that do not support modular JavaScript code.

Async works on external & inline modules
<!-- This executes as soon as its imports have fetched -->
<script async type="module">
  import {addTextToBody} from './utils.js';

  addTextToBody('Inline module executed.');
</script>

<!-- This executes as soon as it & its imports have fetched -->
<script async type="module" src="1.js"></script>


<!-- 1.js only executes once -->
Modules only execute once
<script type="module" src="1.js"></script>
<script type="module" src="1.js"></script>
<script type="module">
  import "./1.js";
</script>

<!-- Whereas normal scripts execute multiple times -->
<script src="2.js"></script>
<script src="2.js"></script>

Always CORS
<!-- This will not execute, as it fails a CORS check -->
<script type="module" src="https://….now.sh/no-cors"></script>

<!-- This will not execute, as one of its imports fails a CORS check -->
<script type="module">
  import 'https://….now.sh/no-cors';

  addTextToBody("This will not execute.");
</script>

<!-- This will execute as it passes CORS checks -->
<script type="module" src="https://….now.sh/cors"></script>

No credentials
<!-- Fetched with credentials (cookies etc) -->
<script src="1.js"></script>

<!-- Fetched without credentials -->
<script type="module" src="1.js"></script>

<!-- Fetched with credentials -->
<script type="module" crossorigin src="1.js?"></script>

<!-- Fetched without credentials -->
<script type="module" crossorigin src="https://other-origin/1.js"></script>

<!-- Fetched with credentials-->
<script type="module" crossorigin="use-credentials" src="https://other-origin/1.js?"></script>

In HTML5, some HTML elements which provide support for CORS, such as <img>, <video> or <script>, have a crossorigin attribute (crossOrigin property), which lets you configure the CORS requests for the element's fetched data. These attributes are enumerated, and have the following possible values:

Keyword	Description
anonymous	CORS requests for this element will not have the credentials flag set.
use-credentials	CORS requests for this element will have the credentials flag set; this means the request will provide credentials.
By default (that is, when the attribute is not specified), CORS is not used at all. The "anonymous" keyword means that there will be no exchange of user credentials via cookies, client-side SSL certificates or HTTP authentication

When you use the crossorigin attribute it sets the "use-URL-credentials" flag and maps anonymous to "same-origin" and use-credentails to "include" for the crendentials mode. If you omit the crossorigin attribute, "use-URL-credentials" is unset and, the default for credentials mode is assumed, which is omit.

You can add credentials to a same-origin module by including the crossorigin attribute (which seems a bit weird to me, and I've questioned this in the spec). If you want to send credentials to other origins too, use crossorigin="use-credentials".

You can use the following <script> or <link> element to tell a browser that before executing the https://example.com/example-framework.js script, the browser must first compare the script to the expected hash, and verify that there’s a match.

<script src="https://example.com/example-framework.js"
        integrity="sha384-oqVuAfXRKap7fdgcCY5uykM6+R9GqQ8K/uxy9rx7HNQlGYl1kPzQho1wx4JwY8wC"
        crossorigin="anonymous"></script>



using module we can use import and export but for other features we dont need to use module. Normal text/javascript will work.

nomodule works only with text/javascript. If given with tyep module its omitted and script still executes.

Error: Failed to load http://sysblog.local:8080/index.php: Response for preflight is invalid (redirect)
indicates that the page requested is redirecting the user somewhere.

jqXHR is superset of xhr which is actual representation of XMLHttpRequest object.

Access-Control-Allow-Origin
Access-Control-Allow-Credentials
these are headers which are required to be present in both OPTIONS request and GET request.

it is contentType in ajax call that defines enctype of form
using application/x-www-form-urlencoded, multipart/form-data, or text/plain values with contentType will mimic the behaviour of actual form submission with enctype as these values.

crossDomain jquery option -> If you wish to force a crossDomain request (such as JSONP) on the same domain, set the value of crossDomain to true 

converters (default: {"* text": window.String, "text html": true, "text json": jQuery.parseJSON, "text xml": jQuery.parseXML})
Type: PlainObject
An object containing dataType-to-dataType converters. Each converter's value is a function that returns the transformed value of the response. 

Default value of content-type header (in ajax or form) or enctype (in form) is application/x-www-form-urlencoded.

if data is sent as application/x-www-form-urlencoded it is received in both $_POST and php://input stream ( as name=kushagra&age=38).

processData By default, data passed in to the data option as an object (technically, anything other than a string) will be processed and transformed into a query string, fitting to the default content-type "application/x-www-form-urlencoded".  If you want to send a DOMDocument, or other non-processed data, set this option to false.

Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8
Accept-Encoding:gzip, deflate
Accept-Language:en-US,en;q=0.9,fr;q=0.8
Cache-Control:max-age=0
Connection:keep-alive
Content-Length:365
Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrosnbEUsHNClsQYZ
Cookie:PHPSESSID=m9tpj4fnn5n7uh48s939n7ri32
DNT:1
Host:sysblog.local:8080
Origin:http://localhost:9000
Referer:http://localhost:9000/
Upgrade-Insecure-Requests:1
User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36

------WebKitFormBoundary76JWxVOm9dQTKlbs
Content-Disposition: form-data; name="email"

karizmatic.kay@gmail.com
------WebKitFormBoundary76JWxVOm9dQTKlbs
Content-Disposition: form-data; name="firstname"

Kushagra
------WebKitFormBoundary76JWxVOm9dQTKlbs
Content-Disposition: form-data; name="lastname"

Mishra
------WebKitFormBoundary76JWxVOm9dQTKlbs
Content-Disposition: form-data; name="ufile"; filename="adhaar.png"
Content-Type: image/png


------WebKitFormBoundary76JWxVOm9dQTKlbs--

multipart/formdata 
With this method of transmitting name/value pairs, each pair is represented as a "part" in a MIME message (as described by other answers). Parts are separated by a particular string boundary (chosen specifically so that this boundary string does not occur in any of the "value" payloads). Each part has its own set of MIME headers like Content-Type, and particularly Content-Disposition, which can give each part its "name." The value piece of each name/value pair is the payload of each part of the MIME message. The MIME spec gives us more options when representing the value payload -- we can choose a more efficient encoding of binary data to save bandwidth (e.g. base 64 or even raw binary).

So as we can see the multipart/formdata request uses boundries for every key/value pair which creates its own mime-type . So very mime has its own set of headers such as content type and content Disposition

This type of behaviour cannot be mimiced with normal ajax flow hence we need Formdata otherwise it prepares a query string similar to application/x-www-form-urlencoded with & and %20.

Content-Type can be anything event application/kushagra and whatever we pass as a data for post method 
it will be converted to application/x-www-form-urlencoded format with & and %20 or whatever encoding is required.

If enctype is unsupported (even if it is application/json) then it will automatically convert to application/x-www-form-urlencoded such as in case of application/kushagra.

text/plain enctype sends request payload and not form data like in normal application/x-www-form-urlencoded request. Hence it can only be retrieved from php://input.In this case only filename will go with the post request and not actual file object.
email=karizmatic.kay@gmail.com
firstname=Kushagra
lastname=Mishra
ufile=adhaar.png

but if used with ajax calls then the request payload goes as in application/x-www-form-urlencoded.
name=kushagra&age=38

Whatever w3school says about text/plain enctype is wrong no encryption is performed even + is not used

In XMLHttpRequest content type with value application/x-www-form-urlencoded, multipart/formdata, text/plain if the actual content is not in required format the value gets converted to application/x-www-form-urlencoded format that is with & and %20 etc.
So if json value or anyother value other than normal text is supplied with text/plain or json value, anyother value which is not multipart request with boundary is supplied with multipart/formdata or any other content-type then the payload is converted to application/x-www-form-urlencoded.

Blob can set its content-type and hence we can see the use of other property Content-Type in multipart request which belongs to only a specific mime subpart.

"------WebKitFormBoundaryXlk8RvQzJKAhmGr4
Content-Disposition: form-data; name="username"

Groucho
------WebKitFormBoundaryXlk8RvQzJKAhmGr4
Content-Disposition: form-data; name="accountnum"

123456
------WebKitFormBoundaryXlk8RvQzJKAhmGr4
Content-Disposition: form-data; name="ufile"

undefined
------WebKitFormBoundaryXlk8RvQzJKAhmGr4
Content-Disposition: form-data; name="webmasterfile"; filename="blob"
Content-Type: text/xml

<a id="a"><b id="b">hey!</b></a>
------WebKitFormBoundaryXlk8RvQzJKAhmGr4--
"

when sending formdata with file through ajax we need to skip setting content-type header because for multipart requests we need to set boundary value also with multipart/formdata which when setting manually can't be set so we need to just let it set automatically which will add boundary value. Content-Type:multipart/form-data; boundary=----WebKitFormBoundarybkqwsY2nEFys9wg5

If no content-type is set and json or anyother unsupported format like text is passed then in core XmlHttpRequest it is passed as raw data with text/plain as content-type.

Which in case of jquery ajax would have been set to application/x-www-form-urlencoded and data converted accordingly.

.hover() is jquery event it binds tagNameo events mouseenter and mouseleave.

For upload both xhr.progressEvent and xhr.upload.progressEvent work in which xhr.progressEvent does not give the total amount to be uploaded, it only gives the amount upload till now but xhr.upload.progressEvent will give both the uploaded aswell as total to be uploaded.
Upload process is not completed untill xhr.progressEvent is finished and xhr.onload event is fired or xhr.readyState is 4. 

for downloading using jquery ajax we need to setup responseType to blob , dataType: blob doesnot work.

The response progress (XmlHttpRequest.onprogress)
This is when the browser is downloading the data from the server.

The request progress (XmlHttpRequest.upload.onprogress)
This is when the browser is sending the data to the server (including POST parameters, cookies, and files)

progressevent on ajax should be bound using xhrFiles anyother way will not work
xhrFields: {
    withCredentials: true,
    responseType: 'blob',
    onprogress: function(e) {console.log("%c On Progress ", "background: darkgreen; color: #ffffff", e);}
},

We can het XmlHttpRequest object in jquery ajax using $.ajaxSettings.xhr();
Where as $.ajaxSettings gives the json object of settings done by $.ajaxSetup

accepts:{*: "*/*", text: "text/plain", html: "text/html", xml: "application/xml, text/xml", json: "application/json, text/javascript", …}
async:true
contentType:"application/x-www-form-urlencoded; charset=UTF-8"
contents:{xml: /\bxml\b/, html: /\bhtml/, json: /\bjson\b/, script: /\b(?:java|ecma)script\b/}
converters:{* text: ƒ, text html: true, text json: ƒ, text xml: ƒ, text script: ƒ}
flatOptions:{url: true, context: true}
global:true
isLocal:false
jsonp:"callback"
jsonpCallback:ƒ ()
processData:true
responseFields:{xml: "responseXML", text: "responseText", json: "responseJSON"}
type:"GET"
url:"http://localhost:9000/"
xhr:ƒ ()


xhr: function() {} is the callback used to prepare XmlHttpRequest object and hence here we can bind upload progress event 
xhr: function() {
    var myXhr = $.ajaxSettings.xhr();
    myXhr.upload.onprogress = function(e) {console.log("%c On Progress Upload ", "background: orange; color: #ffffff", e);}
    return myXhr;
},

delete operator removes property from object.


Web applications can allow or disallow other webapplication to incude their pages in an iframe by using following header
X-Frame-Options: DENY
X-Frame-Options: SAMEORIGIN
X-Frame-Options: ALLOW-FROM https://example.com/

inorder to add headers in htaccess request we need to enable mod_headers directive in apache.

Chrome and Safari don't support X-Frame-Options
so for that we need to use Content-Security-Policy
Syntax
Content-Security-Policy: <policy-directive>; <policy-directive>

This response header tell the browser that load different sections according to the given value in the header such as
default-src
Serves as a fallback for the other fetch directives.
font-src
Specifies valid sources for fonts loaded using @font-face.
frame-src
Specifies valid sources for nested browsing contexts loading using elements such as <frame> and <iframe>.
img-src
Specifies valid sources of images and favicons.
manifest-src
Specifies valid sources of application manifest files.
media-src
Specifies valid sources for loading media using the <audio> , <video> and <track> elements.
object-src
Specifies valid sources for the <object>, <embed>, and <applet> elements.
script-src
Specifies valid sources for JavaScript.
style-src
Specifies valid sources for stylesheets.
worker-src
Specifies valid sources for Worker, SharedWorker, or ServiceWorker scripts.

It can be used as response header as well as a meta tag 
<meta http-equiv="Content-Security-Policy" content="default-src 'self'">
with unsafe inline we can allow the use of inline <script> tags , javascript: and also inline event handlers which otherwise wont be allowed.

Content-Security-Policy actually gives a white list of src to browser to load resources from these src's only.

From the DOM iframe element, scripts can get access to the window object of the included HTML page via the contentWindow property. The contentDocument property refers to the document element inside the iframe (this is equivalent to contentWindow.document), but is not supported by Internet Explorer versions before IE8.

We cannot access the content of another window such as iframe window(iframe.contentWindow) or new window from window.open or anyother window from different domain using javascript. Hence in order to communicate between different windows from different origins we make use of Message event and postMessage method on window object.


window.history.back();
window.history.forward();
window.history.go(-1);
window.history.go(1);
var numberOfEntries = window.history.length;

onpopstate is an event handler for the popstate event on the window.

A popstate event is dispatched to the window each time the active history entry changes between two history entries for the same document. If the activated history entry was created by a call to history.pushState(), or was affected by a call to history.replaceState(), the popstate event's state property contains a copy of the history entry's state object.

Note: calling history.pushState() or history.replaceState() won't trigger a popstate event. The popstate event is only triggered by performing a browser action, such as clicking on the back button (or calling history.back() in JavaScript), when navigating between two history entries for the same document.

window.onpopstate = function(event) {
  alert("location: " + document.location + ", state: " + JSON.stringify(event.state));
};

history.pushState({page: 1}, "title 1", "?page=1");
history.pushState({page: 2}, "title 2", "?page=2");
history.replaceState({page: 3}, "title 3", "?page=3");
history.back(); // alerts "location: http://example.com/example.html?page=1, state: {"page":1}"
history.back(); // alerts "location: http://example.com/example.html, state: null
history.go(2);  // alerts "location: http://example.com/example.html?page=3, state: {"page":3}

Popstate event 
PopStateEvent {isTrusted: true, state: {…}, type: "popstate", target: Window, currentTarget: Window, …}
bubbles:false
cancelBubble:false
cancelable:true
composed:false
currentTarget:Window {postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, frames: Window, …}
defaultPrevented:false
eventPhase:0
isTrusted:true
path:[Window]
returnValue:true
srcElement:Window {postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, frames: Window, …}
state:{foo: "bar"}
target:Window {postMessage: ƒ, blur: ƒ, focus: ƒ, close: ƒ, frames: Window, …}
timeStamp:16264.45
type:"popstate" 


Example of pushState() method
Suppose http://mozilla.org/foo.html executes the following JavaScript:

var stateObj = { foo: "bar" };
history.pushState(stateObj, "page 2", "bar.html");

The pushState() method
pushState() takes three parameters: a state object, a title (which is currently ignored), and (optionally) a URL. Let's examine each of these three parameters in more detail:

state object — The state object is a JavaScript object which is associated with the new history entry created by pushState(). Whenever the user navigates to the new state, a popstate event is fired, and the state property of the event contains a copy of the history entry's state object.

The state object can be anything that can be serialized. Because Firefox saves state objects to the user's disk so they can be restored after the user restarts the browser, we impose a size limit of 640k characters on the serialized representation of a state object. If you pass a state object whose serialized representation is larger than this to pushState(), the method will throw an exception. If you need more space than this, you're encouraged to use sessionStorage and/or localStorage.

title — Firefox currently ignores this parameter, although it may use it in the future. Passing the empty string here should be safe against future changes to the method. Alternatively, you could pass a short title for the state to which you're moving.

URL — The new history entry's URL is given by this parameter. Note that the browser won't attempt to load this URL after a call to pushState(), but it might attempt to load the URL later, for instance after the user restarts the browser. The new URL does not need to be absolute; if it's relative, it's resolved relative to the current URL. The new URL must be of the same origin as the current URL; otherwise, pushState() will throw an exception. This parameter is optional; if it isn't specified, it's set to the document's current URL.

hashchange event is fired when location's href changes.

pushstate changes the current url and creates a new state and pushes it to the history so that the url of the page containing the pushstate script is still in history. and hence when we click back button we can get to that url but in case of replaceState the url of the page that included replaceState script will be removed from the history and replaced the new state defined by replaceState.

Jquery's `on` method helps to bind events based on when they bubble or when event occurs directly to the objects that are present at time of event attaching.
so 
When doing something like 
$(window).on('load', function(e) {
    console.log("Body Load Done", e)
})
load event is directly bound to window object which is present at all times.

but when doing something like 
$(window).on('load','body', function(e) {
    console.log("Body Load Done", e)
})
load event callback doesnot gets called because above is delegated way of binding events when they bubble up to the element to which the event is actully bound, in this case window.

Delegation helps us to bind events with elements which are of present at time time of binding but will be available sometime later.

So above call is trying to bind an event on body inside a window element , because body is not available in start or at the time when this event will be bound hence we are using window to bind the event so that when body is avaiable, any event that occurs on body will propogate up till window and there we catch the event on window binding.

But in this case load event is not caught because load / on load events dont bubble up.

Promise 
The Promise object represents the eventual completion (or failure) of an asynchronous operation, and its resulting value.
A Promise is a proxy for a value not necessarily known when the promise is created. It allows you to associate handlers with an asynchronous action's eventual success value or failure reason. This lets asynchronous methods return values like synchronous methods: instead of immediately returning the final value, the asynchronous method returns a promise to supply the value at some point in the future.

In short promise gives a guarantee that the method which is returning promise will return something either success or error.
While chaining .then calls whatever is returned from then method if it is Promise then the next .then method will be chained with the returned promise and the message passed in the callback of current .then will be from the resolve of the promise that was returned from the previous .then callback but if something else is returned say a number or integer then .then chaining will still work but on the main promise in the same sequence as it was registered and it will take that returned integer as its argument in the .then callback.
.catch method call is similar to catch in try catch.
We even have finally method which will be executed no matter if error happened or success happened.

A Promise is in one of these states:

pending: initial state, neither fulfilled nor rejected.
fulfilled: meaning that the operation completed successfully.
rejected: meaning that the operation failed 

The callback passed to new Promise constructor is called executor.

Nested then clause reject cannot be handled by the parent catch. There has to be a chained catch with every .then chain.

In order to remove event listener on an element in javascript we have removeEventListener('eventname', "callback");
In order to remove all the event listeners on an element we need to do a copy and then replace that node with the copy

var new_el = el.cloneNode(true); //true means a deep copy
el.parentNode.replaceChild(new_el,el);
.on was previously called bind()
.off was previously called unbind()

If a simple event name such as "click" is provided, all events of that type (both direct and delegated) are removed from the elements in the jQuery set.

The .off() method removes event handlers that were attached with .on(). See the discussion of delegated and directly bound events on that page for more information. Calling .off() with no arguments removes all handlers attached to the elements. Specific event handlers can be removed on elements by providing combinations of event names, namespaces, selectors, or handler function names. 

Remove all event handlers from all paragraphs:
$( "p" ).off();

Remove all delegated click handlers from all paragraphs:
$( "p" ).off( "click", "**" );

We can even pass two callbacks inside promise object success and failed which can be used to proceed with the .then chain based on the message received in the .then callback. So that if success then we can do something otherwise if error then we can do something else.

promiseReject().then(function() {
    console.log('Success');
    return 1;
}, function() {
    console.log('Error');
    return 2;
}).then(function(message) {
    console.log("Error chain", message);
});

if promise returns an event handler binding then calling that same promise inside .then wont work because all the root calls to promise registered the event handlers initially and so when the event occurred they got called but in case of promise inside .then it registered a new event handler and after it got registered no new events occured hence it was not called.

setTimeout(callback, 2000, params);
params get passed to the callback.

Promise.all is used to watch all the promises inside an array if all resolve then only .then method of .all is called which receives an object with resolve messages of all the resolved promises. but if either one of the promises passed to the .all array rejected then complelete .all is rejected and catch method of .all is called.

all the resolved promises
Promise {<resolved>: 3}__proto__: Promise[[PromiseStatus]]: "resolved"[[PromiseValue]]: 3 Promise {<pending>} 12345 Promise {<resolved>: 40}

resolved promise 
Promise {<resolved>: 3}
__proto__:Promise
[[PromiseStatus]]:"resolved"
[[PromiseValue]]:3

async function is another way of returning the promise without manualy creating a new object. If async function returns anything then proomise is resolved else if error occurs in async function then promise is rejected.

the return value of an async function is implicitly wrapped in Promise.resolve.

Example
async function returnPromise() {
  return 12;
}
returnPromise().then(function() {});

The await operator is used to wait for a Promise. It can only be used inside an async function.
The await expression causes async function execution to pause until  a Promise is fulfilled or rejected, and to resume execution of the async function after fulfillment. When resumed, the value of the await expression is that of the fulfilled Promise.

If the Promise is rejected, the await expression throws the rejected value.

If the value of the expression following the await operator is not a Promise, it's converted to a resolved Promise.

Using setTimeout with async function will not work correctly 

async function returnPromise() {
    setTimeout(function() {
        return "Success";
    }, 500);
}

if returned value from the expression after await returns Promise then await will wait untill promise is resolved or rejected.
if the returned value is not a promise then it will be treated as the resolved promise value.

setTimeout pushes the code in timeout event queue which gets executed in a context other that the holding block and hence aync method returns empty promise.

setTimeout is an async call code doesnot wait for it to get executed. So following method
function test() {
	setTimeout(function() {console.log("Hello")}, 5000);
	console.log("After setTimeout");
}
prints After setTimeout first and exists the function and then after 5 seconds hello is printed.
setInterval is also asynchronous operation as setTimeout.

Await method returns the message passed by resolve or reject methods of Promise.
function waiting() {
    return new Promise(function(resolve, reject) {
        setTimeout(function() {
            console.log("resolved");
            resolve(30);
        }, 5000);
    });
}
var cld = await waiting(); // cld gets 30
console.log(cld);

In order to get various information about function like the number of arguments and the caller we can use 'arguments' keyword.
callee:ƒ Hello()
length:0
Symbol(Symbol.iterator):ƒ values()
__proto__:Object

callee gives the calling method.
length gives the number of arguments received by the function.

Jquery.Deffered() returns a factory Deffered object which is similar to javascript Promise and hence we can bind .then(), .done(), .always(), .fail() and the method receiving deferred object can call .resolve or .resolveWith and .reject or .rejectWith().

.always() is executed when either of resolve or reject is executed. Its similar to finally.

Deferred object has same states as javascript Promise object that is initial Pending, then Resolved or Rejected (known as fulfilled) and then finished.

$.Deferred() takes a callback which is optional, it run just before the actual deferred object is returned. This object is the actual new deferred object and is passed as first argument.

$.Deferred(function(deferred) {
	console.log("Before ",deferred)
});

Both in javascript Promise and $.Deffered once state is resolved or rejected it cannot be changed to other.

function returnVal() {
	return new Promise(function(resolve, reject) {
		setTimeout(reject, 5000, "failed");
		setTimeout(resolve, 5000, "success");
    });
}
Promise {<pending>}
api.jquery.com/:1 Uncaught (in promise) failed

once the state is resolved or rejected any .then or .done() methods attached to the chain will get immediately executed.

If state is resolved or rejected then any .then methods attached to it are immediately executed.

Once the reject is handled in one .catch it will not get passed to another subsequent catch calls.

The callbacks attached to done() will be fired when the deferred is resolved. The callbacks attached to fail() will be fired when the deferred is rejected.

Prior to jQuery 1.8, then() was just syntactic sugar:

promise.then( doneCallback, failCallback )
// was equivalent to
promise.done( doneCallback ).fail( failCallback )

$.Deferred gives a complete object with handler methods as well as state changing methods thats why we use the same object to return as a promise to the calling function and also to bind the state changer methods such as resolve, reject, resolveWith, rejectWith in the called method. And thats why its not secure to share $.Deffered to other methods because they can modify the promise state there, hence $.Deffered.promise() is used which gives only binding methods such as .then, .done, .always, .progress, etc.

Description: Return a Deferred's Promise object.
deferred.promise( [target ] )
target
Type: Object
Object onto which the promise methods have to be attached.

.progress is used to bind live notification from the promise object before it is resolved or rejected. .notify is used to in conjunction with .progress to keep sending information from promise object to calling method.

In $.Deferred we can pass any number of arguments in the .then, .done, .fail method callback but in case of javascript Promise only one argument can be passed.

$.when is similar to Promise.all. .all method takes array but $.when takes any number of Thenable arguments without array.

If $.when is passed single thenable argument then it will bind all the subsequent then, done, fail, etc to the deferred or promise object returned from that argument.

If $.when is passed a single argument that is not a promise or deferred then it will be immediately resolved and any then , etc callbacks attached will be called.

If $.when is passed with a number of Thenable arguments then a master Deferred object will be created which will watch all the Deffered objects passed into the $.when method and when all of them have resolved or if a single one fails then its resolved or rejected.

If $.when is passed nothing then immediatelya resolved promise is returned.

.promise() Return a Promise object to observe when all actions of a certain type bound to the collection, queued or not, have finished.
The .promise() method returns a dynamically generated Promise that is resolved once all actions of a certain type bound to the collection, queued or not, have ended.

By default, type is "fx", which means the returned Promise is resolved when all animations of the selected elements have completed.

.promise() works same as $.when

Jquery $.get and $.post both give jqXHR object which implements $.Deffered Promise interface ( not exactly $.Deffered ) and hence methods like .then(), .done() etc are available to bind with this object.


When we serialize a form it prepares a query string like get "email=&firstname=&lastname="

$.get, $.post and $.ajax all return jqXHR which also implements promise interface from $.deferred and hence only the methods such as .then and .done are available in addition to a success callback.

jquery .then method takes three callbacks ƒ ( onFulfilled, onRejected, onProgress )

Same origin policy
Allows or defines how a resource on one origin can interact with the resource on other origin.
SOP restricts two origins to talk to each other if they are on different domain, port or schemes(http or https).
There are still some exceptions such as 
Embedding of img, script and link are allowed. 
Post or write requests are allowed.
Read requests are not allowed but can be tricked using embbeding.

Application can change their domain using document.domain with some limitations.
document.domain can change the current domain to the superdomain such as in case of ltl.binarybulb.com document.domain can be changed to binarybulb.com but not to xyz.com.
The change is supposed to be done on both the sides on the pages that can include javascript which can run document.domain.

When doing document.domain port are also replaced with null.

While working with localstorage and cookies they will work only on same origins because they are origin dependent and for every origin they are different.

Things like iframe are allowed to be embedded but with X-Frame-Options or Content-Security-Policy. They are still not allowed to be accessed from a frame from different domain using contentDocument or contentWindow.document. But scripts execution is allowed.
Other things like
Media files with <video> and <audio>.
Plug-ins with <object>, <embed> and <applet>.
Fonts with @font-face. Some browsers allow cross-origin fonts, others require same-origin fonts.
are also allowed.

Ajax calls are subjected to same origin policy.
So even if we include or embed things like js and all from different origins without any issues if those files make cross domain ajax requests then they wont be allowed because now the requests originates from our server and pings other remote server.

For security reasons, browsers restrict cross-origin HTTP requests initiated from within scripts. 
 XMLHttpRequest and the Fetch API follow the same-origin policy.

 During cross domain requests even it is a simple request which does not trigger options request Cors header Access-Control-Allow-Origin is required because the request is from different origin and hence it needs to be allowed.

Requests are treated as CORS request and a preflight request is sent when either the method or headers are not one out of the following 
The only allowed methods are:
GET
HEAD
POST
Apart from the headers set automatically by the user agent (for example, Connection, User-Agent, or any of the other headers with names defined in the Fetch spec as a “forbidden header name”), the only headers which are allowed to be manually set are those which the Fetch spec defines as being a “CORS-safelisted request-header”, which are:
Accept
Accept-Language
Content-Language
Content-Type (but note the additional requirements below)
Last-Event-ID
DPR
Save-Data
Viewport-Width
Width
The only allowed values for the Content-Type header are:
application/x-www-form-urlencoded
multipart/form-data
text/plain

Unlike “simple requests” (discussed above), "preflighted" requests first send an HTTP request by the OPTIONS method to the resource on the other domain, in order to determine whether the actual request is safe to send. Cross-site requests are preflighted like this since they may have implications to user data.

In particular, a request is preflighted if any of the following conditions is true:

If the request uses any of the following methods:
PUT
DELETE
CONNECT
OPTIONS
TRACE
PATCH
Or if, apart from the headers set automatically by the user agent (for example, Connection, User-Agent, or any of the other header with a name defined in the Fetch spec as a “forbidden header name”), the request includes any headers other than those which the Fetch spec defines as being a “CORS-safelisted request-header”, which are the following:
Accept
Accept-Language
Content-Language
Content-Type (but note the additional requirements below)
Last-Event-ID
DPR
Save-Data
Viewport-Width
Width
Or if the Content-Type header has a value other than the following:
application/x-www-form-urlencoded
multipart/form-data
text/plain
Or if one or more event listeners are registered on an XMLHttpRequestUpload object used in the request.
Or if a ReadableStream object is used in the request.

The cors request sends Access-Control-Request-<Any type that is sent extra or other than the ones allowed>: requested types. In response we get Access-control-Allow-<Any type that is sent extra or other than the ones allowed>: the allowed types.

Access-Control-Request-Method: POST
Access-Control-Request-Headers: X-PINGOTHER, Content-Type
Access-Control-Allow-Origin: http://foo.example
Access-Control-Allow-Methods: POST, GET, OPTIONS
Access-Control-Allow-Headers: X-PINGOTHER, Content-Type
Access-Control-Max-Age: 86400

Access-Control-Allow-Methods, Access-Control-Allow-Headers,  Access-Control-Allow-Origin, Access-Control-Max-Age,  Access-Control-Allow-Credentials, Access-Control-Expose-Headers

Access-Control-Max-Age tells for how much time should the results or response headers from preflight request  are supposed to be cached and once the time ends a new prflight request is supposed to be made.

Redirects in normal ajax requests are allowed but not in preflight requests. If there is a redirection in preflight requests then error is generated.

In order to by pass them we can do following things

change the server-side behavior to avoid the preflight and/or to avoid the redirect—if you have control over the server the request is being made to
change the request such that it is a simple request that doesn’t cause a preflight
But if it’s not possible to make those changes, then another way that may be possible is to this:

Make a simple request to determine (using Response.url for the Fetch API, or XHR.responseURL to determine what URL the real preflighted request would end up at).
Make another request (the “real” request) using the URL you obtained from Response.url or XMLHttpRequest.responseURL in the first step.

When doing CORS requests the request will actually execute without issues but client side libraries will not allow to capture the response if the headers are not correct. The response can still be seen in inspect window or browser.

So in case of with credentials request client will try to send the request along with the credentials set by responsding server but will generate error if it does not contain correct response headers from server.

Using withCredentials from client doesn't make a preflight request, the request will still be the simple request but will expect correct response headers to be set.

When using withCredentials, the server response header Access-Control-Allow-Origin should not be * because then it will allow all the hosts and doamins to send the credentials to the server. So when using withCredentials Access-Control-Allow-Origin should be set to specific host values.

The Access-Control-Expose-Headers header lets a server whitelist headers that browsers are allowed to access. For example:

Access-Control-Expose-Headers: X-My-Custom-Header, X-Another-Custom-Header
This allows the X-My-Custom-Header and X-Another-Custom-Header headers to be exposed to the browser.

Jquery No Conflict
While initialising jquery all the old references of $ are recorded $.noConflict() just restores them back. This is incase we are using any other libraries that use jquery like $ variable. For Jquery $ is just a alias to jQuery.
<script src="other_lib.js"></script>
<script src="jquery.js"></script>
<script>
$.noConflict();
// Code that uses other library's $ can follow here.
</script>

Once noConflict has been made we will not be able to use $ from jQuery direcly in the script because now in the script $ will refer to other library's $.

but still we can do few things like using the $ vairable inside the .ready(function($) {}) which can be registered as 
<script src="other_lib.js"></script>
<script src="jquery.js"></script>
<script>
$.noConflict();
jQuery( document ).ready(function( $ ) {
  // Code that uses jQuery's $ can follow here.
});
// Code that uses other library's $ can follow here.
</script>
jQuery.noConflict(); // restores $ back to previously using library. 
// Do something with jQuery
jQuery( "div p" ).hide();
// Do something with another library's $()
$( "content" ).style.display = "none";

or 
jQuery.noConflict();
(function( $ ) {
  $(function() {
    // More code using $ as alias to jQuery
  });
})(jQuery);
 
// Other code using $ as an alias to the other library



Bind method in javascript is used to change the reference of this ina method. It defines what will this keyword refer to in a method. Which can be used later.
Bind method also is ussed in currying it can take first argument as the object to which this is bound to and rest can be the arguments supplied to the function.

When http form method is not supported it converts it to GET. So in case of put or other requests the request finally gets converted to get so thats why wee need to send a post request witha a hidden field that defines the http method. 

Apache automatically adds conditional request headers in responnse such as E-Tag and Last MModified if the pages are served by apache but incases such as php fpm where pages are not served by apache or in case of pretty urls these headers are not added hence at that time we might need to add such headers manually.

Apache for adding these headers makes use of three things 
Inode -  i-node is the number generated by OS to keep track of the file, it includes things like access level, creation time,... You can configure apache to use only INode by adding this line to httpd.conf
file Mtime
file size.

Inode is different for different os even for same file and hence in case of load balancer these file will always result in complete download making etags useless.

Hence we might now at all use etags and only use cache control headers or we can change the FileEtag information to include only mtime and size.

This is already fixed in apache version 2.4 or higher and inode is removed.


Http has a concept of conditional requests which means that the result or even the success of the request can be changed based on the result that we get after comparing the resource which we are trying to access with the value of validator.

These validators are some special headers sent in the request or sent back in response which make a precondition to check based on which the resource is either returned or not.

HTTP conditional requests are requests that are executed differently, depending on the value of specific headers. These headers define a precondition, and the result of the request will be different if the precondition is matched or not.

The different behaviors are defined by the method of the request used, and by the set of headers used for a precondition:

for safe methods, like GET, which usually tries to fetch a document, the conditional request can be used to send back the document, if relevant only. Therefore, this spares bandwidth.
for unsafe methods, like PUT, which usually uploads a document, the conditional request can be used to upload the document, only if the original it is based on is the same as that stored on the server.

Validators check a specific version of a resource on the server and hence they need to send a version tex or number in the header because its not always possible and efficient to match the document byte by byte and the headers or tyoe of headers that contain such values ( version identifiers ) are called validators.

Validators are of two types 
last modified date.
etag or entity tag which contains a unique identifier for the resource.

Compairing versions is done in two ways
Weak Validation and Strong Validation.

Strong Vaildation compairs complete byte to byte value of the resource and guarantees that resourbce is exactly same.
Weak validation does not match the resource byte by byte . The two resource must be equivalent but not necessarily equal. The two resrouces are considered equal even if they are slightly different for example having a different date in footer.

The kind of validation is independent of the validator used. Both Last-Modified and ETag allow both types of validation, though the complexity to implement it on the server side may vary. HTTP uses strong validation by default, and it specifies when weak validation can be used.

Header adding enabling removing and editing in htaccess is possible only because of mod_headers.

RequestHeader append MirrorID "mirror 12"
RequestHeader unset MirrorID

#Header add X-Frame-Options "DENY"


RequestHeader  edit "If-None-Match" "^(.*)-gzip$" "$1"
Header  edit "ETag" "-gzip" ""

Above is similar to DeflateAlterETag which allows to handle how etags are generated per response
AddSuffix
Append the compression method onto the end of the ETag, causing compressed and uncompressed representations to have unique ETags. This has been the default since 2.4.0, but prevents serving "HTTP Not Modified" (304) responses to conditional requests for compressed content.

NoChange
Don't change the ETag on a compressed response. This was the default prior to 2.4.0, but does not satisfy the HTTP/1.1 property that all representations of the same resource have unique ETags.

Remove
Remove the ETag header from compressed responses. This prevents some conditional requests from being possible, but avoids the shortcomings of the preceding options.

So All these headers need to be implemented on server side these are just some standard and there no specific implementations for them. Browsers only obey the data sent from server . They will only add conditional headers when there is specific response from server. So if we are sending 304 all the time then conditional heders will not be sent they will only be sent when response is 200 OK.

So for weak etag validation a prefix of W/ is used which is also the responsibility of server to implement . Client browser has nothing to do with it. Browser sends back whatever server sent to it initially.

All the conditional requests are supposed to be handeled manually ( sending correct response headers from server or client if not already sent )

If-Unmodified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT
If-Modified-Since: <day-name>, <day> <month> <year> <hour>:<minute>:<second> GMT

If-Modified-Since can/should only be used with GET and HEAD requests.
If-Unmodified-Since can/should only be used with POST requests.

The If-Unmodified-Since request HTTP header makes the request conditional: the server will send back the requested resource, or accept it in the case of a POST or another non-safe method, only if it has not been last modified after the given date. If the request has been modified after the given date, the response will be a 412 (Precondition Failed) error.

Etag form server response has If-Match and If-None-Match 

Etag and If-Match and If-None-Match can take multiple Etags which will be the responsibility of the server and developer to match against a valid set of etags and there nothing that will happen automatically so we can use this technique to manage version of files on different servers like in case of load balancer.

Cache-Control header is used to tell the browser what to do with the cache
max-age:  tells the browser the time in seconds till which the cache will be considered fresh.
no-cache: tells the browser to cache the content but before using it must revalidate all the times using conditional requests.
no-store: The no-store directive is more strict, it means the response cannot be written to the cache at all. Ex. If you send no-store for a response then cache wont store it at all and next time when it gets request for that resource it will send that request to the originating server, which will send the full response with HTTP 200 status 
must-revalidate: will tell the browser to validate the cache to check if its ok or stale otherwise reject the cache.

Expire also works same as cache-control max-age directive but in this we can give excat data and time for the cache to expire.

If there is a Cache-Control header with the "max-age" or "s-maxage" directive in the response, the Expires header is ignored.

If there are no conditional headers in 200 ok response headers then there will be no conditional headers in the requests also.

Chrome behaves differently for cache-control headers, hitting a url in address bar or ctrl+R or ctrl+shift+R doesnot honor cache-control headers its sends a request to server. Chrome will honor cache-control headers only when coming by clicking a link or hitting back button.

But if the response is 304 then chrome will pull data from cache only and not from server as in case of 200 ok.
Cache-Control header works perfectly in firefox.

If etag or lastModified header were not present then soon after the cache timed out it would have done a 200 ok request which would have given fresh copy and more time taking .

inorder to open new window and not a tab we need to give height and with of the window 
 window.open("https://www.w3schools.com", "_blank", "location=no,height=300,width=400");

Except for the ranges request for all the other requests if conditions specified in conditional request headers is ok then 304 not modified response is sent back and the ccontent is picked from the cache otherwise is conditions fail then for safe requests like GET and HEAD a direct 200 ok response is sent back and for unsafe requests like PUT and POST if condition matches then 304 Not Modified else if condition doesn't match then 412 precondition fail response is sent back. After getting 412 response we can reload the page or fetch the new content.

If-unmodified-since and IF-Match and If-Not-Match when used for unsafe requests like post and put they are generally used for updating a form field by editing inside a textarea or an editor. They cannot be used for uploading and replaceing or updating the documents because we will not be able to know the Last Modified date or a=original ETag for such documents where as for the post and put requests for updating an editorial for example we can use ajax requests and while we open the editor we can record the etag or Last Modifed given by the server Or when we click on edit button at that time we can generate these conditional header values.

$.fn gives a prototype object for jquery 
$.fn.check creates a method on jquery object which can be invoked later as $(document).check()
$.extend merges two or more objects into one.
$.fn.extend extends $.fn prototype object of jquery so that we can add new methods to it 
<script>
jQuery.fn.extend({
  check: function() {
    return this.each(function() {
      this.checked = true;
    });
  },
  uncheck: function() {
    return this.each(function() {
      this.checked = false;
    });
  }
});
 
// Use the newly created .check() method
$( "input[type='checkbox']" ).check();

During the partial download 
First the request goes to server to download the file
Then server response by broadcasting that it supports partial downloads by sending Accept-Ranges: bytes header. So that browser now knows that request can be partially downloaded and resumed in sometime future. Along with other headers such as Last Modified and ETag.

File starts downloading but if something goes wrong in between the download and download couldn't complete then browser can resume the download anytime by sennding Ranges request which will have the next set of bytes or range of bytes to be fetched from server which were not downloaded.

But In all this if file file on server gets changed then we will two different copies of files for the given byte ranges and hence we use conditional reqest headers here ETag and Last Modified .
The client sends along with the ranges request If-Match Or If-Not-Match or If-Modified-Since or If-Unmodified-Since which can be used on server to decide if the resource being downloaded is still same or has changed. If resource has changed then server responds with 416 precondition fails error and clients then start a totally new request with 200 OK status.

This above process of determining if r esource is intact is having extra round trips and headers to check and hence another header If-Range which also takes ETag like If-Match but in case of range allows servers to respond with directly with 200 OK as in case of GET requests when If-Match or other conditional headers fail. 
Otherwise if everything is ok then server responds with 206 partial content request.

The Range HTTP request header indicates the part of a document that the server should return. Several parts can be requested with one Range header at once, and the server may send back these ranges in a multipart document. If the server sends back ranges, it uses the 206 Partial Content for the response. If the ranges are invalid, the server returns the 416 Range Not Satisfiable error. The server can also ignore the Range header and return the whole document with a 200 status code.

Directives
<unit>
The unit in which ranges are specified. This is usually bytes.
<range-start>
An integer in the given unit indicating the beginning of the request range.
<range-end>
An integer in the given unit indicating the end of the requested range. This value is optional and, if omitted, the end of the document is taken as the end of the range.


Syntax
Range: <unit>=<range-start>- // from given start till end.
Range: <unit>=<range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>, <range-start>-<range-end>

Examples
Range: bytes=200-1000, 2000-6576, 19000-

To distinguish between XHR requests and fetch api requests we dont have any specific mechanism because fetch api requests don't send x-forwarded for request header. Hence we need to send some extra header in order to notify that request is and fetch api request.
$.getJson and $.getScript both are similar to having dataType value json and script.
$.get and $.post both have dataType as last parameter.

$( "#b" ).load( "article.html #target" );

using xhr: inside ajaxSetup doesn't work but using xhr: field inside $.ajax works fine.

Using flush technique in ajax also works so ajax can keep receiving response from server as in case of normal web request but for it the ready state is 3 which means some data is received but not all.

Hence in XmlHttprequest we can use onreadystatechange without checking onreadystate value and keep receiving the output or also in on progress event or xmlhttp. In jquery ajax we need to use $.ajax to receive such outputs $.get won't work and in this case we also need to use it directly inside $.ajax as a property and not inside $.ajaxSetup.


If a client makes a request of your service with a Range header, return a 206 Partial Content response containing a Content-Range header and the requested range of bytes for the resource in the body. The Content-Length value should be the length of what is actually returned and not the full length of the resource.

If the client makes a range request that is out of bounds—that is, none of the range values overlap the extent of the resource—the service should respond with a 416 Requested Range Not Satisfiable status.

Range requests can also be used to read data from the file on server in chunks or bytes or unit specified in Accept-Range header.

Range requests are supposed to be made by clients explicitly they are never fired implicitly.

Sometimes in ajax requests we might not get all response headers and hence we may need to use Access-Control-Expose-Headers

Content-Length: 2000 header limits the amount of content tobe sent or shown and a page if content length more that the given value in Content-Length header is thrown to a page or sent in response then it will be stripped to the given value which is 2000 currently as per above.

Content-Length header also affects the XMLHttprequest download process. Ajax request takes the progress event's loaded and lengthComputable values from this header only.
If this is not set or contains wrong values then the download will not happen properly.

If Content-Length is omitted then the actual length of document is sent.

XHR onabort event also gives a promise event which has access to all the other methods and properties like in normal xhr request 
ProgressEvent {isTrusted: true, lengthComputable: true, loaded: 5381088, total: 10762150, type: "abort", …}
bubbles:false
cancelBubble:false
cancelable:false
composed:false
currentTarget:XMLHttpRequest {onreadystatechange: null, readyState: 0, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, …}
defaultPrevented:false
eventPhase:0
isTrusted:true
lengthComputable:true
loaded:5381088
path:[]
returnValue:true
srcElement:XMLHttpRequest {onreadystatechange: null, readyState: 0, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, …}
target:XMLHttpRequest {onreadystatechange: null, readyState: 0, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, …}
timeStamp:3283.86
total:10762150
type:"abort"
__proto__:ProgressEvent

No matter what type of request you send either ajax or normal http request browser will automatically append required conditional headers based on the last response headers.
For browser that don't add it we need to do it manually on our own.

Chrome is very strict regarding ajax requests and Content-Length so if the content-length is more that the data flushed to chrome it will generate error and the requests will fail. But if the content is request over a normal http request then its ok. Other browsers are ok with this limitiation its only chrome that is very strict.

Range request is generally for media streaming. With ajax generally it is used as follows 
var xmlhttp=new XMLHttpRequest();
xmlhttp.open("GET","data.dat",false);
xmlhttp.setRequestHeader("Range", "bytes=100-200");
xmlhttp.send();
console.info(xmlhttp)

Chrome is very strict about everything and headers that we send in the request. So we need to be very careful regarding putting the headers in the request.
So even if content-type is missing then also chorme will not allow to set status code to anything such as 206.

We can pull only a part of data file by range request if server supports it.

CustomElementRegistry is an interface that provides methods to register you custom elements, bind promise on those elements when they have finished registering and then get those elements or its constructor.

It has 3 methods in it
CustomElementRegistry.define()
CustomElementRegistry.get()
CustomElementRegistry.whenDefined()

Though we have facilities like we can add new custom elements to dom and attach different events to them but we cannot monitor the adding or removing of those elements from dom.

Using CustomElementRegistry we can track the addign and removing of those elements aswell.

MutationObserver
MutationObserver provides developers with a way to react to changes in a DOM. It is designed as a replacement for Mutation Events defined in the DOM3 Events specification.

So using above we can track not only addition or removal of new elements but also modification or removal of attributes.
Modifiction of child elements or change in the descendants of such elements.

javascript acessing and modifying attribute values
element.hasAttribute('foo');
element.getAttribute('foo');
element.setAttribute('foo', value);
element.removeAttribute('foo');

The contenteditable attribute specifies whether the content of an element is editable or not. Note: When the contenteditable attribute is not set on an element, the element will inherit it from its parent.

TextNode comes in javascript elem.childNodes it wont show up in children.
children will show only elem like divs , spans etc which are visibily present there

And if mutators are attached to childText node then it will be caught on every key event. If contenteditable is not put on element then it will be referenced from its parent.

Mutation Observers will not be bubbling up or delegated they will be caught only on the elems that they are attached to.

Character data works if it is attached directly on elem's textContent node.

MutationObserver is created by initializing it and it can take one argument which is a callback. Callback is passed two arguments MutationRecordList and MutationObserver. MutationRecordList gives the type of Mutation done on an element. As this is a list it contains an array of all the mutation done on an element. 

After the Observer instance is created it we need to bind this instance with elements using .observe method. .observe method takes two arguments the target node and MutationObserverInit config . MutationObserverInit has following properties


Property	                 Description
childList	                 Set to true if additions and removals of the target node's child elements (including text nodes) are to be observed.
attributes	               Set to true if mutations to target's attributes are to be observed.
characterData	             Set to true if mutations to target's data are to be observed.
subtree	                   Set to true if mutations to target and target's descendants are to be observed.
attributeOldValue	         Set to true if attributes is set to true and target's attribute value before the mutation needs to be recorded.
characterDataOldValue	     Set to true if characterData is set to true and target's data before the mutation needs to be recorded.
attributeFilter	           Set to an array of attribute local names (without namespace) if not all attribute mutations need to be observed.

out of which three should be atleast always used childList, characterData and attributes

inorder to stop observing the we can call .disconnect() method on observer instance.

.takeRecords returns whatever is there inside the MutationObserver instance's record queue and empties it.


By using Obsevers we will not be able to bind element's addition or removal into/from DOM hence we need CustomElementRegistry.

CustomElementRegistry interface provides methods to define new custom elements and query them. CustomElementRegistry doesn't work on elements added using tag notation they only work for the elements added using the .define() method.

CustomElementRegistry offers three methods 
.define() -> defines a new custom element and provides the constructor that will be called when this new element's instance is created otherwise HTMLUnknowELement constructor is used. 

.get() -> get the defined element otherwise undefined.

.whenDefined -> returns a promise to which we can chain .then and .catch methods after the element is successfully defined.

window.customElements gives the custom elements registered using .define method of CustomElementRegistry but it will not give the elements deinfed using tag notiation.
window.customElements returns a instance of CustomElementRegistry.

javascript append takes any string to append to dom if something like <div></div> is passed then it will also be treated as string only and will not be parsed to html. Where as in case of appendChild we can append actual html node string.

Object.defineProperty(obj, prop, descriptor)

This is used to define properties and allows us to change the default behavior of such properties such as can it be enumerated or assigned using assignment operator.
Normal property addition through assignment creates properties which show up during property enumeration (for...in loop or Object.keys method), whose values may be changed, and which may be deleted. This method allows these extra details to be changed from their defaults. By default, values added using Object.defineProperty() are immutable.

There are two types of descriptors data descriptors and accessor descriptors. A property can have only one of these descriptors not both at a time.
Both the type of descriptors use a cummon set of descriptor methods
configurable
true if and only if the type of this property descriptor may be changed and if the property may be deleted from the corresponding object.
Defaults to false.
enumerable
true if and only if this property shows up during enumeration of the properties on the corresponding object.
Defaults to false.

A data descriptor also has the following optional keys:
value
The value associated with the property. Can be any valid JavaScript value (number, object, function, etc).
Defaults to undefined.
writable
true if and only if the value associated with the property may be changed with an assignment operator.
Defaults to false.

An accessor descriptor also has the following optional keys:
get
A function which serves as a getter for the property, or undefined if there is no getter. When the property is accessed, this function is called without arguments and with this set to the object through which the property is accessed (this may not be the object on which the property is defined due to inheritance). The return value will be used as the value of the property.
Defaults to undefined.
set
A function which serves as a setter for the property, or undefined if there is no setter. When the property is assigned to, this function is called with one argument (the value being assigned to the property) and with this set to the object through which the property is assigned.
Defaults to undefined.

If a descriptor has neither of value, writable, get and set keys, it is treated as a data descriptor. If a descriptor has both value or writable and get or set keys, an exception is thrown.

Using Object.defineProperties we can define multiple properties for an object which is not possible in Object.defineProperty.
Object.defineProperties()
const object1 = {};
Object.defineProperties(object1, {
  property1: {
    value: 42,writable: true
  },
  property2: {}
});
console.log(JSON.stringify(object1.property1));
// expected output: 42

This also helps when using const because it is not allowed to change const using assignment after it is defined.

We can determine if object is extensible (whether it can have new properties added to it) or not by Object.isExtensible() and can prevent it from being extended by Object.preventExtensions()
const object1 = {};

console.log(Object.isExtensible(object1));
// expected output: true

Object.preventExtensions(object1);

console.log(Object.isExtensible(object1));
// expected output: false

The Object.preventExtensions() method prevents new properties from ever being added to an object (i.e. prevents future extensions to the object).
const object1 = {};

Object.preventExtensions(object1);

try {
  Object.defineProperty(object1, 'property1', {
    value: 42
  });
} catch (e) {
  console.log(e);
  // Expected output: TypeError: Cannot define property property1, object is not extensible
}

The Object.seal() method seals an object, preventing new properties from being added to it and marking all existing properties as non-configurable. Values of present properties can still be changed as long as they are writable.

const object1 = {
  property1: 42
};

Object.seal(object1);
object1.property1 = 33;
console.log(object1.property1);
// expected output: 33

delete object1.property1; // cannot delete when sealed
console.log(object1.property1);
// expected output: 33

The Object.freeze() method freezes an object: that is, prevents new properties from being added to it; prevents existing properties from being removed; and prevents existing properties, or their enumerability, configurability, or writability, from being changed, it also prevents the prototype from being changed.  The method returns the object in a frozen state.

const object1 = {
  property1: 42
};

const object2 = Object.freeze(object1);

object2.property1 = 33;
// Throws an error in strict mode

console.log(object2.property1);
// expected output: 42


In ES5, if the argument to this method is not an object (a primitive), then it will cause a TypeError. In ES2015, a non-object argument will be treated as if it was a non-extensible ordinary object, simply return false.

Object.isExtensible(1);
// TypeError: 1 is not an object (ES5 code)

Object.isExtensible(1);
// false                     

// New objects are extensible.
var empty = {};
Object.isExtensible(empty); // === true

// ...but that can be changed.
Object.preventExtensions(empty);
Object.isExtensible(empty); // === false

// Sealed objects are by definition non-extensible.
var sealed = Object.seal({});
Object.isExtensible(sealed); // === false

// Frozen objects are also by definition non-extensible.
var frozen = Object.freeze({});
Object.isExtensible(frozen); // === false

Throws a TypeError exception if the object whose [[Prototype]] is to be modified is non-extensible according to Object.isExtensible(). Does nothing if the prototype parameter isn't an object or null (i.e., number, string, boolean, or undefined). Otherwise, this method changes the [[Prototype]] of obj to the new value.

Object.setPrototypeOf() is in the ECMAScript 2015 specification. It is generally considered the proper way to set the prototype of an object, vs. the more controversial Object.prototype.__proto__ property.

// Object creates a wrapper of the type of the value passed around the value passed. Hence with json string or boolean it creates specific objects of the types. In case of function the type is Function which will be passed the function given to Object and hence the Function returns the actual function because Function doesnot create the object of the function it just defines it like we normally define a function.

Object() is similar to new Object();

Object.create use the argument's constructor to decide on its type.
Object.create considers the first argument as the object from whose prototype the new object should be created. The newly created object is of type of its contructor hence when function is passed we get Function object with the all the contents inside the object/function passed.If we were to create an object using new the classes prototype would have been used to assign to the new objects proto but with Object.create everything inside the passed argument is considered as proto.


When new function is done its prototype.constructor is used to create the object becuase prototype is used for sharing the properties and instance is something that is shared and not dedicated because we can have multiple instances of a function hence the constructor is shared thats why for objects the constructor is inside prototype.

For core functions the constructor is directly attached to the function name like f1.constructor. This constructor can also be changed. When changed Object the create uses it to create a new object of type of this constructor.

Object() when passed with a value takes its constructor as its type and then creates a wrapper of type of this constructor on the values passed . As this constructor cannot be changes manually when passing function as an argument to Object(), it always uses the builtin constructor which is Function in case of functions.

The underlying, built in constructor property is something you can’t set manually. It can only be set for you, as part of construction with the new keyword.

A function is just a special kind of object, and like any object a function can have properties. Functions automatically get a property called prototype, which is just an empty object. This object gets some special treatment.

vehicle;                          // {}

var FuzzyBear = function FuzzyBear() { };
vehicle.constructor = FuzzyBear;

vehicle;                          // { constructor: function FuzzyBear() }
vehicle.constructor == FuzzyBear; // true
vehicle instanceof FuzzyBear      // false
vehicle instanceof Vehicle        // true

Primitives are converted to their object counterparts and hence we can assign value in object style to even string types because as soon as js detects assignment of primitives it does following
var primitive = "september";
primitive.vowels = 3;
//new object created to set property 
(new String("september")).vowels = 3;
 
primitive.vowels;
//another new object created to retrieve property 
(new String("september")).vowels; //undefined

We can directly assign properties to objects even string and functions but they behave differently
if we assign a property on string or boolean 
var str = "kushagra"
str.oo = [1,2,3,4];
var bool = true;
bool.oo = [1,2,4,5]
this object if not stored somewhere then it will be destroyed immediately and it will not be accessible in future.
but if we assign the same on function then that becomes a property and is accessible via Object.create and directly on function names() {
	this.returnNames = function() {}
}
names.oo = [1,2,4,5]
names.oo
var ob = Object.create(names);
ob.__proto__.oo
ob.oo

The Function constructor creates a new Function object. Calling the constructor directly can create functions dynamically, but suffers from security and performance issues similar to eval.

var sum = new Function('a', 'b', 'return a + b');

console.log(sum(2, 6));
// expected output: 8

Function prototype object
Properties
Function.arguments 
An array corresponding to the arguments passed to a function. This is deprecated as property of Function. Use the arguments object available within the function instead.
Function.arity 
Used to specifiy the number of arguments expected by the function, but has been removed. Use the length property instead.
Function.caller 
Specifies the function that invoked the currently executing function.
Function.length
Specifies the number of arguments expected by the function.
Function.name
The name of the function.
Function.displayName 
The display name of the function.
Function.prototype.constructor
Specifies the function that creates an object's prototype. See Object.prototype.constructor for more details.
Methods
Function.prototype.apply()
Calls a function and sets its this to the provided value, arguments can be passed as an Array object.
Function.prototype.bind()
Creates a new function which, when called, has its this set to the provided value, with a given sequence of arguments preceding any provided when the new function was called.
Function.prototype.call()
Calls (executes) a function and sets its this to the provided value, arguments can be passed as they are.
Function.prototype.isGenerator() 
Returns true if the function is a generator; otherwise returns false.
Function.prototype.toSource() 
Returns a string representing the source code of the function. Overrides the Object.prototype.toSource method.
Function.prototype.toString()
Returns a string representing the source code of the function. Overrides the Object.prototype.toString method.


var x = 10;

function createFunction1() {
    var x = 20;
    return new Function('return x;'); // this |x| refers global |x|
}

function createFunction2() {
    var x = 20;
    function f() {
        return x; // this |x| refers local |x| above
    }
    return f;
}

var f1 = createFunction1();
console.log(f1());          // 10
var f2 = createFunction2();
console.log(f2());          // 20

using function keyword with Object is similar to doing 
var x = new Function('return function named() {return function() {console.log("elo")}}')
where x is 
ƒ anonymous() {
return function named() {return function() {console.log("elo")}}
}
and x() is 
ƒ named() {return function() {console.log("elo")}} which is returned when doing Object(named)

constructor property on Function which is Function() by default is just a way to tell that this is the type or the origin of this function so for every function Function is the origin and as we cannot change that property ( when we try to initialize constructor property ) we end up creating a new constructor property which is nothing but mearly a way to tell that this is my constructor and type so when we set it for a function we only change the type hint nothing more all the inheritance is already done. So nothing will be directly inherited.

At most we can create a new object of the constructor or we can directly access the properties defined on that constructor.

function kush() {
	this.name = function() {};
	this.age = function() {};
	this.gender = function() {};
	var deg = function() {console.log('hi')}
 	return this;
}
function ekta() {
	this.name = function() {};
	this.age = function() {};
	this.gender = function() {};
	var degi = function() {console.log('hi hello')}
// 	return this;
}
Object.defineProperties(kush, {
	"prop2": {enumerable: true, configurable: false},
	"prop3": {enumerable: true, configurable: true, value: 300}
})
kush.prototype.sex = function() {}
kush.dickSize = 12
kush.peelDickSkin = function() {return true;}

ekta.constructor = kush
ƒ kush() {
	this.name = function() {};
	this.age = function() {};
	this.gender = function() {};
	var deg = function() {console.log('hi')}
 	return this;
}

now we can access it 
ekta.constructor.peelDickSkin
var ok = Object.create(ekta);
kush {}
__proto__:ƒ ekta()
constructor:ƒ kush()
  dickSize:12
  peelDickSkin:ƒ ()
  prop2:undefined
  prop3:300
  arguments:null
  caller:null
  length:0
  name:"kush"
  prototype:{sex: ƒ, constructor: ƒ}
  __proto__:ƒ ()
  [[FunctionLocation]]:VM15537:1
  [[Scopes]]:Scopes[2]
arguments:null
caller:null
length:0
name:"ekta"
prototype:{constructor: ƒ}
__proto__:ƒ ()
[[FunctionLocation]]:VM15537:8
[[Scopes]]:Scopes[2]

and then calling ok.constructor.prop2.
When creating Objects from Object.create using function names directly it returns the actual object representation of that function . functions is not converted to object but all its hidden properties inherited and defined are directly exposed.

When creating object of other types such as array, same methodology is used for example
Object.setPrototypeOf([1,2,3,4],ekta);
in this a new array object (taken from ([1,2,3,4]).constructor ƒ Array() { [native code] }) is created with its proto having value of ekta.

When using setPrototypeOf with functions there is no __proto__ available in function directly, hence __proto__ property of .prototype.constructor.__proto__ is set.
With normal objects __proto__ property is directly accessible so all the things of 2nd argument are put inside the __proto__ property of first argument.
If we manually change the function.prototype.constructor property then it will not be able to setPrototypeOf.

__proto__.constructor property of object is considered as the type of object created.

Creating function Object using Object.create or assigning prototype of function to other object doesnt matter much because direct access to function methods and properties is not going to be available because the new object's body will be having every property of the function (which can only be directly accessed) such as constructor (if manually set) name, arguments , prototype etc.

Object.getPrototypeOf return the __proto__ property.

The isPrototypeOf() method checks if an object exists in another object's prototype chain.
function object1() {}
function object2() {}

object1.prototype = Object.create(object2.prototype);

const object3 = new object1();

console.log(object1.prototype.isPrototypeOf(object3));
// expected output: true

console.log(object2.prototype.isPrototypeOf(object3));
// expected output: true

Syntax
prototypeObj.isPrototypeOf(object)
Parameters
object
The object whose prototype chain will be searched.

If we need to check that if a variable is integer or if number is NaN then we can do that using Number.isInteger or Number.isNaN or isNaN from the Number class and also can get following methods 

Object.create(Number);
arguments:(...) 
caller:(...) 
__proto__:ƒ Number() 
EPSILON:2.220446049250313e-16 
MAX_SAFE_INTEGER:9007199254740991MAX_VALUE:1.7976931348623157e+308 
MIN_SAFE_INTEGER:-9007199254740991MIN_VALUE:5e-324 
NEGATIVE_INFINITY:-Infinity 
NaN:NaN 
POSITIVE_INFINITY:Infinity 
arguments:(...) 
caller:(...) 
isFinite:ƒ isFinite() 
isInteger:ƒ isInteger() 
isNaN:ƒ isNaN() 
isSafeInteger:ƒ isSafeInteger() 
length:1name:"Number"parseFloat:ƒ parseFloat() 
parseInt:ƒ parseInt() 
prototype:Number{  
   0,
   constructor:ƒ,
   toExponential:ƒ,
   toFixed:ƒ,
   toPrecision:ƒ,
   toString:ƒ,
   …
}__proto__:ƒ ()[  
   [  
      Scopes
   ]
]:Scopes[  
   0
]

ownProperty on an Object is the property which is defined on the object directly and not in any prototype chains.

The Object.getOwnPropertyDescriptor() method returns a property descriptor for an own property (that is, one directly present on an object and not in the object's prototype chain) of a given object.

Descriptors are same as used in Object.setProperty/ies. Object.getOwnPropertyDescriptor() method returns an object of all such properties defined on the given object.

function g1() {
	this.m = function() {}

}
g1.m2 = function() {}

Object.getOwnPropertyDescriptor(g1, 'm1');
undefined
Object.getOwnPropertyDescriptor(g1, 'm2');
{value: ƒ, writable: true, enumerable: true, configurable: true}

.prototype.constructor also works like direct .constructor. It has no significance and is not used automatically, it just represents the function from which the object was instanciated.  Even if we overrite it and then create a new object it wont affect, the new object will still be from the original constructor.

Thats why when we set constructor property on an object or method directly we get a new protperty created we dont actually change in core constructor property.

var a = [1,2,3,3,4];
undefined
a.constructor
ƒ Array() { [native code] }
a.constructor = fa
ƒ fa() {console.log("hello from fa")}

a
(5) [1, 2, 3, 3, 4, constructor: ƒ]
a.constructor
ƒ fa() {console.log("hello from fa")}
a instanceof Array
true
a instanceof fa
false

In the above even the constructor is fa (which says that this object is instanciated from fa) the result from instanceof is false against fa and its still the object or Array.

(Object.create(a)) instanceof Array
true
(Object.create(a)) instanceof fa
false
Object.getOwnPropertyNames
Object.keys
Object.values
Object.has
Object.deleteProperty
Object.getOwnPropertySymbols

d.prop1 = 300
300
d.method1 = function() {}

ƒ () {}
Object.getOwnPropertyNames(d)
(7)[  
   "length",
   "name",
   "arguments",
   "caller",
   "prototype",
   "prop1",
   "method1"
]0:"length"1:"name"2:"arguments"3:"caller"4:"prototype"5:"prop1"6:"method1"length:7


function getLocation() {
    if (navigator.geolocation) {
        navigator.geolocation.getCurrentPosition(showPosition);
    } else {
        x.innerHTML = "Geolocation is not supported by this browser.";
    }
}
function showPosition(position) {
    x.innerHTML = "Latitude: " + position.coords.latitude + 
    "<br>Longitude: " + position.coords.longitude; 
}


// Grab elements, create settings, etc.
var video = document.getElementById('video');

// Get access to the camera!
if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    // Not adding `{ audio: true }` since we only want video now
    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
        video.src = window.URL.createObjectURL(stream);
        URL.revokeObjectURL(stream); // releases the object stream from bindings (The URL.revokeObjectURL() static method releases an existing object URL which was previously created by calling URL.createObjectURL().  Call this method when you've finished using an object URL to let the browser know not to keep the reference to the file any longer.)
        video.play();
    });
}
// Elements for taking the snapshot
var canvas = document.getElementById('canvas');
var context = canvas.getContext('2d');
var video = document.getElementById('video');

// Trigger photo take
document.getElementById("snap").addEventListener("click", function() {
	context.drawImage(video, 0, 0, 640, 480);
});


The Proxy.revocable() method is used to create a revocable Proxy object.
Syntax
Proxy.revocable(target, handler);
Parameters
target
A target object (can be any sort of object, including a native array, a function or even another proxy) to wrap with Proxy.
handler
An object whose properties are functions which define the behavior of the proxy when an operation is performed on it.
Return value
A newly created revocable Proxy object is returned.
A revocable Proxy is an object with following two properties {proxy: proxy, revoke: revoke}.

proxy
A Proxy object created with new Proxy(target, handler) call.
revoke
A function with no argument to invalidate (switch off) the proxy.
If the revoke() function gets called, the proxy becomes unusable: Any trap to a handler will throw a TypeError. Once a proxy is revoked, it will remain revoked and can be garbage collected. Calling revoke() again has no effect.

var revocable = Proxy.revocable({}, {
  get: function(target, name) {
    return "[[" + name + "]]";
  }
});
var proxy = revocable.proxy;
console.log(proxy.foo); // "[[foo]]"

revocable.revoke();

console.log(proxy.foo); // TypeError is thrown
proxy.foo = 1           // TypeError again
delete proxy.foo;       // still TypeError
typeof proxy            // "object", typeof doesn't trigger any trap

Revocable object doesn't give proxy object direcly it gives object with two things -> 1). the actual proxy object and 2). revoke method which will be used to revoke the proxy object and stop and further processing of traps.

Function.prototype.apply()

The new.target property lets you detect whether a function or constructor was called using the new operator. In constructors and functions instantiated with the new operator, new.target returns a reference to the constructor or function. In normal function calls, new.target is undefined.

function meth() {
	console.log(new.target)
}

meth()
undefined

new meth()
meth {}

VERY IMPORTANT FINDING
when doing apply on a method and other object that object will get all the this. properties of the method attached to itself as object property.
so 
function meth2(a, b) {
    console.log("Inside meth two", a, b);
    this.m2 = function() {console.log("inside m2");}
    this.p2 = 500;
    console.log(this.p1);
    // return [this.p2, this.m2]
}

var payload = {
    x: this.p1+900,
    p1: 700
}

// apply
Reflect.apply(meth2, payload, []); // 700

will result in 
payload
m2:ƒ ()
p1:700
p2:500
x:NaN
payload will have m2, p2 also attached to it.

same is the case of function.

function meth1(a, b) {
    console.log("Inside meth one", a, b);
    this.m1 = function() {console.log("inside m1");}
    this.p1 = 300;
}
function meth2(a, b) {
    console.log("Inside meth two", a, b);
    this.m2 = function() {console.log("inside m2");}
    this.p2 = 500;
    console.log(this.p1);
    // return [this.p2, this.m2]
}

Reflect.apply(meth2, meth1, []);
this result in meth1 having m2, p2 attached to it like meth1.m2, meth1.p2

Reflect.construct will assign the .prototype object of the method passed as last argument(to be used as new constructor) to the __proto__ for the method given as first argument.
In short Reflect.construct will construct an object of method in first argument using the method or constructor in last argument as its constructor and hence using last argument's .prototype and assigning it to first argument's object's __proto__.

newTarget in Proxy or Reflect in construct is the constructor on which this new object of first argument is created.
receiver in Proxy or Reflect in get or set is the this object on which target is called or set.

// Object
var obj = { x: 1, y: 2 };
Reflect.get(obj, 'x'); // 1

// Array
Reflect.get(['zero', 'one'], 1); // "one"

// Proxy with a get handler
var x = {p: 1};
var obj = new Proxy(x, {
  get(t, k, r) { return k + 'bar'; }
});
Reflect.get(obj, 'foo'); // "foobar"

Inorder to trim strip array to a certain length we can set the lengtth property of that array and it will be trimmed to that length.

var a = [1,2,3,3,4];
a.length
5
a.length = 2
a
(2) [1, 2]

Reflect.apply()
Calls a target function with arguments as specified by the args parameter. See also Function.prototype.apply().
Reflect.construct()
 The new operator as a function. Equivalent to calling new target(...args).
Reflect.defineProperty()
Similar to Object.defineProperty(). Returns a Boolean.
Reflect.deleteProperty()
The delete operator as a function. Equivalent to calling delete target[name].
Reflect.get()
A function that returns the value of properties.
Reflect.getOwnPropertyDescriptor()
Similar to Object.getOwnPropertyDescriptor(). Returns a property descriptor of the given property if it exists on the object,  undefined otherwise.
Reflect.getPrototypeOf()
Same as Object.getPrototypeOf().
Reflect.has()
The in operator as function. Returns a boolean indicating whether an own or inherited property exists.
Reflect.isExtensible()
Same as Object.isExtensible().
Reflect.ownKeys()
Returns an array of the target object's own (not inherited) property keys.
Reflect.preventExtensions()
Similar to Object.preventExtensions(). Returns a Boolean.
Reflect.set()
A function that assigns values to properties. Returns a Boolean that is true if the update was successful.
Reflect.setPrototypeOf()
A function that sets the prototype of an object.

CustomElementRegistry requires class as its constructor callback in define but we can still use it without classes with Reflect.connect
var CEo = function ()
{
    console.log( "created" )
    return Reflect.construct( HTMLElement, [], CEo )
}

CEo.prototype = Object.create( HTMLElement.prototype )

CEo.prototype.connectedCallback = function ()
{
    console.log( "connected" )
    this.innerHTML = "Hello v1"
} 

customElements.define( "object-v1", CEo )

Template and slot elements are the elements used as placeholder for client side content which are not rendered when page is loaded. They are parsed to check if contents inside template do not have any errors but they will not be rendered.

<template> element has content property on itself which gives a document-fragment which has the actual elements defined inside the <element> tag.
Because its #document-fragment hence its not actually loaded in dom same way as it was in case of createDocumentFragment.
Once we have the document fragment we can query it for elements and their attributes.
#document-fragment also states that its not the actual document but a fragment of complete document.

var arr = [3, 5, 7];
arr.foo = 'hello';

for (var i in arr) {
   console.log(i); // logs "0", "1", "2", "foo"
}

for (var i of arr) {
   console.log(i); // logs 3, 5, 7
}

So once template content is rendered anywhere in document directly it wont be usable any further and thats why we will need to use clone of content.

Because template element has a document-fragment with itself as its content the things defined inside template tag will be scoped inside it only and wont affect outside template tag.

Details element and summary element 
Details element 
The HTML Details Element (<details>) is used to create a disclosure widget in which information is visible only when the widget is toggled into an "open" state. A summary or label can be provided using the <summary> element.
Details element is used to create a toggle element which can be opened and closed by click on black triangle next to the summary.
Summary tag is used as a legend to details tag. This is supposed to be the first thing inside details element. Anything after that can be toggled to be open or close.
If summary is not the first element in details tag the default Details label is used.

Anything inside slot element is not hidden and slot element will be rendered and will be visible as soon as page is rendered. Its not like template element which itself along anything inside it will be not rendered.
Slot elements are useful only when attached to shadow dom of element. They help in preparing the complete scaffolding of the component. The actual data to the slot elements in that scaffolding inside the shadowDom of the parent is supplied from the parent element's children having attribute values same as slot name inside shadow dom.
The actual element will not be displayed and only the slot element with the data from actual child elements with slot attributes.

Polymer js is completely based on CustomElementRegistry, MutationObserver, slot, template, html imports using <link rel="import" /> and shadown dom.

onload works for script tags but not for link tags. On link element onload event fires on import rel when success or onerror when error.

::selection element is used to change the color and background of selection made in browser for example selecting text or anyother thing.
/* Make selected text gold on a red background */
::-moz-selection {
  color: gold;
  background: red;
}

::selection {
  color: gold;
  background: red;
} 

/* Make selected text in a paragraph white on a blue background */
p::-moz-selection {
  color: white;
  background: blue;
}

When we import somethings the html is not rendered from that file but script and styles are immediately rendered.
The location of the script that is going to be imported is called import location and the document that is going to be imported is called import document.

script tags without async or defer block parsing and hence block rendering of the page aswell. This is done in order to ensure that anything that is changed by the script is avaiable to the sections below it.
Link tag doesnot stop parsing but blocks renderings.

<head>
</head>
<body>
  <!-- HTTP/2 push this resource, or inline it, whichever's faster -->
  <link rel="stylesheet" href="/site-header.css">
  <header>…</header>

  <link rel="stylesheet" href="/article.css">
  <main>…</main>

  <link rel="stylesheet" href="/comment.css">
  <section class="comments">…</section>

  <link rel="stylesheet" href="/about-me.css">
  <section class="about-me">…</section>

  <link rel="stylesheet" href="/site-footer.css">
  <footer>…</footer>
</body>

The plan is for each <link rel="stylesheet"> to block rendering of subsequent content while the stylesheet loads, but allow the rendering of content before it. The stylesheets load in parallel, but they apply in series. This makes <link rel="stylesheet"> behave similar to <script src="…"></script>.

Let's say the site-header, article, and footer CSS have loaded, but the rest are still pending, here's how the page would look:

Header: rendered
Article: rendered
Comments: not rendered, CSS before it hasn't loaded yet (/comment.css)
About me: not rendered, CSS before it hasn't loaded yet (/comment.css)
Footer: not rendered, CSS before it hasn't loaded yet (/comment.css), even though its own CSS has loaded.
Link tags load the document parallely.

link imports also block rendering because they can contain stylsheets.

link import document's contents will be available using .import method on th link tag reference.
imported document can refer to itself using document.currentScript.ownerDocument or to parent importing document using document.
import tags will not block the parsing of the page but will block the rendering of the page.
scripts inside the import document will be loaded in the given order but they will not block the importing document.
scripts outside the import document will still block the page . Any script just after import will block the page because there are scripts inside the import documents also.

The insertAdjacentElement() method inserts a given element node at a given position relative to the element it is invoked upon.

Syntax
targetElement.insertAdjacentElement(position, element);
Parameters
position
A DOMString representing the position relative to the targetElement; must match (case-insensitively) one of the following strings:
'beforebegin': Before the element itself.
'afterbegin': Just inside the element, before its first child.
'beforeend': Just inside the element, after its last child.
'afterend': After the element itself.

insertAdjacentHTML() parses the specified text as HTML or XML and inserts the resulting nodes into the DOM tree at a specified position. It does not reparse the element it is being used on and thus it does not corrupt the existing elements inside that element. This avoids the extra step of serialization, making it much faster than direct innerHTML manipulation.

Syntax
element.insertAdjacentHTML(position, text);
position is the position relative to the element, and must be one of the following strings:

'beforebegin'
Before the element itself.
'afterbegin'
Just inside the element, before its first child.
'beforeend'
Just inside the element, after its last child.
'afterend'
After the element itself.
text is the string to be parsed as HTML or XML and inserted into the tree.

CustomElementRegistry works on elements attached in any DOM inside the parent DOM.

When using CustomElementRegistry constructor will first work on every element and construct the element inside the import link then call its connect (as it normally did when using callbacks) then it will again call constructor on every element for parent dom just so that if its inserted in dom in future it can be directly sent to connect.

So if there are two documents example parent document and import link document then customElements will be registered for both the documents. If constructor is registered then it will be called for all the occurances of the element in both the documents. If connectedCallback is registered then it will be called for both the documents first. 
Then after child documents are done constructor will be called for the parent document.
Once element is inserted in parent dom connectedCallback will again be called for parent dom.

Imports block rendering
Imports block rendering of the main page. This is similar to what <link rel="stylesheet"> do. The reason the browser blocks rendering on stylesheets in the first place is to minimize FOUC. Imports behave similarly because they can contain stylsheets.

To be completely asynchronous and not block the parser or rendering, use the async attribute:

<link rel="import" href="/path/to/import_that_takes_5secs.html" async>
The reason async isn't the default for HTML Imports is because it requires developers to do more work. Synchronous by default means that HTML Imports that have custom element definitions inside of them are guaranteed to load and upgrade, in order. In a completely async world, developers would have to manage that dance and upgrade timings themselves.

You can also create an async import, dynamically:

var l = document.createElement('link');
l.rel = 'import';
l.href = 'elements.html';
l.setAttribute('async', '');
l.onload = function(e) { ... };
Imports do not block parsing
Imports don't block parsing of the main page. Scripts inside imports are processed in order but don't block the importing page. This means you get defer-like behavior while maintaining proper script order. One benefit of putting your imports in the <head> is that it lets the parser start working on the content as soon as possible. With that said, it's critical to remember <script> in the main document still continues to block the page. The first <script> after an import will block page rendering. That's because an import can have script inside that needs to be executed before the script in the main page.

<head>
  <link rel="import" href="/path/to/import_that_takes_5secs.html">
  <script>console.log('I block page rendering');</script>
</head>
Depending on your app structure and use case, there are several ways to optimize async behavior. The techniques below mitigate blocking the main page rendering.


With Shadow DOM, elements can get a new kind of node associated with them. This new kind of node is called a shadow root. An element that has a shadow root associated with it is called a shadow host. The content of a shadow host isn’t rendered; the content of the shadow root is rendered instead.

s = null
null
typeof s
"object"

extends inside the define() method can be used to customise the builtin element by attaching custom event listeners to it and attaching custom shadow dom to it.
Without extends we dont have any way to capture core builtin element's lifecycle chain. With extends we can capture core element's such as div, span, button etc.

<content></content> tag or element inside shadow dom allow us to control what gets rendered inside shadow dom from containing parent.
If we dont provide content tag that means we are telling shadow root to not render anything from shadow host.
By using content tag we are telling shadow root to render everything inside shadow root where the content tag is.
By using select clause with content tag <content select=".first"></content> to use identifier inside select attribute to search for the occurances of the element in shadow host and bring it to the place with content is used in shadow root.
If more than one content tag match with the specified element identifier the first content tag matching will get the elements from shadow host.
select can only select elements which are immediate children of the host node. That is, you cannot select descendants (e.g.select="table tr").
If there are multiple elements matching the selector then all will be linked with shadow root.
node.shadowRoot.host

If we need to import or export without curly braces then we need import * or export * or export default.
when using () => {} to in place of functions and expression the return is implicitly included in it . We don't have to say return expression. So () => console.log() is actually function() {return console.log()}.

Export default will not with let we can use export default function xyz(), export default xyz = function(), export default class but not export default let x = function () {}

encodeURI()
Use encodeURI when you want a working URL. Make this call:

encodeURI("http://www.example.org/a file with spaces.html")
to get:

http://www.example.org/a%20file%20with%20spaces.html
Don't call encodeURIComponent since it would destroy the URL and return

http%3A%2F%2Fwww.example.org%2Fa%20file%20with%20spaces.html
encodeURIComponent()
Use encodeURIComponent when you want to encode the value of a URL parameter.

var p1 = encodeURIComponent("http://example.org/?a=12&b=55")
Then you may create the URL you need:

var url = "http://example.net/?param1=" + p1 + "&param2=99";
And you will get this complete URL:

http://example.net/?param1=http%3A%2F%2Fexample.org%2F%Ffa%3D12%26b%3D55&param2=99

These two methods above help us in passing some special character data in the url while using ajax calls. Browser automatically converts these character.
with ajax requests "&", "+", and "=" have special meaning hence must be encoded.
"The escape() method does not encode the + character which is interpreted as a space on the server side as well as generated by forms with spaces in their fields. Due to this shortcoming and the fact that this function fails to handle non-ASCII characters correctly, you should avoid use of escape() whenever possible. The best alternative is usually encodeURIComponent().

escape() will not encode: @*/+


Canvas
Default size of canvas is 300 px × 150 px (width × height). But custom sizes can be defined using the HTML height and width property. 
Indeed, the <canvas> element has only two attributes, width and height.
The element can be sized arbitrarily by CSS, but during rendering the image is scaled to fit its layout size: if the CSS sizing doesn't respect the ratio of the initial canvas, it will appear distorted.

The value or tag inside canvas element is used as a fallback and will not be rendered if browser supports canvas tag.
Canvas tag is empty by default and always exposes various drawing contexts such as 2d or 3d or webgl.
We make use of getContext() method to get the drawing context from canvas.
getContext method uses following syntax
var ctx = canvas.getContext(contextType);
var ctx = canvas.getContext(contextType, contextAttributes);

Parameters
contextType
Is a DOMString containing the context identifier defining the drawing context associated to the canvas. Possible values are:
"2d", leading to the creation of a CanvasRenderingContext2D object representing a two-dimensional rendering context.
"webgl" (or "experimental-webgl") which will create a WebGLRenderingContext object representing a three-dimensional rendering context. This context is only available on browsers that implement WebGL version 1 (OpenGL ES 2.0).
"webgl2" which will create a WebGL2RenderingContext object representing a three-dimensional rendering context. This context is only available on browsers that implement WebGL version 2 (OpenGL ES 3.0). 
"bitmaprenderer" which will create an ImageBitmapRenderingContext which only provides functionality to replace the content of the canvas with a given ImageBitmap.

2d context attributes:
alpha: Boolean that indicates if the canvas contains an alpha channel. If set to false, the browser now knows that the backdrop is always opaque, which can speed up drawing of transparent content and images.
 (Gecko only) willReadFrequently: Boolean that indicates whether or not a lot of read-back operations are planned. This will force the use of a software (instead of hardware accelerated) 2D canvas and can save memory when calling getImageData() frequently. This option is only available, if the flag gfx.canvas.willReadFrequently.enable is set to true (which, by default, is only the case for B2G/Firefox OS).
 (Blink only) storage: String that indicates which storage is used ("persistent" by default).

 Css gradients cannot work with only one color. At least two colours are supposed to be used.

 With color stops we can give percentage even more that 100%. The calculation should be done from 100% or the end side.

 Element.scrollIntoView()
 Parameters
  alignToTop Optional
  Is a Boolean value:
  If true, the top of the element will be aligned to the top of the visible area of the scrollable ancestor. Corresponds to scrollIntoViewOptions: {block: "start", inline: "nearest"}. This is the default value.
  If false, the bottom of the element will be aligned to the bottom of the visible area of the scrollable ancestor. Corresponds to scrollIntoViewOptions: {block: "end", inline: "nearest"}.
  scrollIntoViewOptions Optional 
  Is an Object with the following properties:
  behavior Optional
  Defines the transition animation.
  One of "auto", "instant", or "smooth". Defaults to "auto".
  block Optional
  One of "start", "center", "end", or "nearest". Defaults to "center".
  inline Optional
  One of "start", "center", "end", or "nearest". Defaults to "nearest".
Scrolls the given element into the visisble view.

For draggable elements if we dont mess up with its opactity then we can see that element as moving from its positions.

In most cases, it is the same as parentNode. The only difference comes when a node's parentNode is not an element. If so, parentElement is null.

document.body.parentNode; // the <html> element
document.body.parentElement; // the <html> element

document.documentElement.parentNode; // the document node
document.documentElement.parentElement; // null

The Element.getBoundingClientRect() method returns the size of an element and its position relative to the viewport.

Syntax
var domRect = element.getBoundingClientRect();
he returned value is a DOMRect object which is the union of the rectangles returned by getClientRects() for the element, i.e., the CSS border-boxes associated with the element. The result is the smallest rectangle which contains the entire element, with read-only left, top, right, bottom, x, y, width, and height properties describing the overall border-box in pixels. Properties other than width and height are relative to the top-left of the viewport.

Empty border-boxes are completely ignored. If all the element's border-boxes are empty, then a rectangle is returned with a width and height of zero and where the top and left are the top-left of the border-box for the first CSS box (in content order) for the element.
The amount of scrolling that has been done of the viewport area (or any other scrollable element) is taken into account when computing the bounding rectangle. This means that the rectangle's boundary edges (top, left, bottom, and right) change their values every time the scrolling position changes (because their values are relative to the viewport and not absolute). If you need the bounding rectangle relative to the top-left corner of the document, just add the current scrolling position to the top and left properties (these can be obtained using window.scrollX and window.scrollY) to get a bounding rectangle which is independent from the current scrolling position.

The Element.getClientRects() method returns a collection of DOMRect objects that indicate the bounding rectangles for each CSS border box in a client.

Syntax
var rectCollection = object.getClientRects();

onwheel specifically fires when the mouse wheel is spun. onscroll fires for any kind of scrolling, including keyboard buttons like the arrow keys, Home, End, Page Up, Page Down, space bar, tabbing etc.

Note that onwheel is non-standard and should be avoided unless you're specifically targeting browsers that support it and/or are providing an extra feature whose absence won't be felt.

element.offsetHeight, element.offsetWidth -> gives element's height and width including border and padding.

clientHeight:

Returns the height of the visible area for an object, in pixels. The value contains the height with the padding, but it does not include the scrollBar, border, and the margin.

offsetHeight:

Returns the height of the visible area for an object, in pixels. The value contains the height with the padding, scrollBar, and the border, but does not include the margin.

So, offsetHeight includes scrollbar and border, clientHeight doesn't.

element.offsetTop and element.offsetLeft -> returns the distance of the current element relative to the top of the offsetParent node, returns the number of pixels that the upper left corner of the current element is offset to the left within the HTMLElement.offsetParent node, respectively

The HTMLElement.offsetParent read-only property returns a reference to the object which is the closest (nearest in the containment hierarchy) positioned containing element. If the element is non-positioned, the nearest table, table cell or root element (html in standards compliant mode; body in quirks rendering mode) is returned by offsetParent.

closest in jquery matches and returns the closest element matching the selector.

scrollTop and scrollLeft give the scroll position inside element.
for document scroll position inside onscroll event we need document.documentElement.offsetTop or window.scrollX and window.scrollY or their alias window.pageXOffset and window.pageYOffset

onscroll happens for all kinds of scroll events even press of space or drag or scroll bar but wheel event works only for mouse wheel.

The Element.scrollHeight read-only property is a measurement of the height of an element's content, including content not visible on the screen due to overflow.

document.getElementById('scroll').scrollHeight
1458
scrollHeight gives the height of the content along with the scrollable content. If there is no vertical scroll then clientHeight and scrollHeight is same.

jquery or javascript remove element -> .remove()

window.innerWidth and innerHeight are for visisble area in viewport including scrollbars.
window.outerHeight and outerWidth are for whole browser including the inspect window's height and width and not only wht is visible.

PageX,PageY are the coordinates relative to the top of the web page excluding the scroll. So when an actual web page has more content than the size of browser window we get a scroll on window. So pageX, and pageY refer to the points 0,0 from the top corner of the web page and not the top corner of the browser.

ClientX and ClientY are point form the top left corner of the browser and not the actual web page. So If placing mouse pointer at the top left of the browser window (winthout scrolling) gives 0,0, scrolling it to a certain point and then again placing mouse pointer to top left will also give 0, 0.

ScreenX and ScreenY are the points from the available screen top left. So if we make screen fullsize by f11 we can see getting a 0,0 when mouse pointer is on top left corner but will not be able to see that when out of full screen mode.

mousewheel properties
details indicates the scroll amount by line;
The wheelDelta attribute value is an abstract value which indicates how far the wheel turned. If the wheel has rotated away from the user, it's positive, otherwise negative.

These values differ from browser to browser and os to os.

offsetX/offsetY are a neat extension by Microsoft to mouse event objects, and mean the position of the mouse pointer relatively to the target element. Sadly, they're not implemented by Firefox, and there's discordance among the other browsers about what should be the origin point: IE thinks it's the content box, while Chrome, Opera and Safari the padding box (which makes more sense, since it's the same origin of absolutely positioned elements).

layerX/layerY are properties of MouseEvent objects defined by Gecko-based browsers (Firefox et al.). Some say they're substitutes for offsetX/offsetY - they're not. They're the position of the mouse relatively to the "closest positioned element", i.e. an element whose position style property is not static. That's not the target element if it's statically positioned.

Wheel delta is chrome thing.
delta thing (deltaX and deltaY) are generic things which will be available on all the browsers.

touches - a list of all of the touch points currently on the screen.
targetTouches - a list of the touch points on the target DOM element.
changedTouches - a list of the touch points whose items depends on the associated event type:
For the touchstart event, it is a list of the touch points that became active with the current event.
For the touchmove event, it is a list of the touch points that have changed since the last event.
For the touchend event, it is a list of the touch points that have been removed from the surface (that is, the set of touch points corresponding to fingers no longer touching the surface).

navigator.geolocation.getCurrentPosition(function(re) {console.log(re)})
http://maps.googleapis.com/maps/api/geocode/json?latlng=12.9839571,77.70535559999999&sensor=true

During these changes, the window.orientation property may change. A value of 0 means portrait view, -90 means a the device is landscape rotated to the right, and 90 means the device is landscape rotated to the left.'

Some devices don't provide orientation event so we use resize
window.addEventListener("resize", function() {
	// Get screen size (inner/outerWidth, inner/outerHeight)
	
}, false);

Although both were developed to provide client side data storage but both have different approaches and should be chosen according to the needs. localStorage stores data in key-value pair but unlike IndexedDB, they are not stored in form of objects. Instead, it stores only string key-value pairs. A simple trick to store objects in localstorage is to use JSON.stringify(), similarly to store it back to object form after reading you will need to do JSON.parse(). But it will not be a good solution when storing large number of complex objects. Moreover, localstorage was designed for smaller data and provides synchronous API.IndexedDB is great for handling large amount of data and comes with asynchronous API. It uses indexes to store data and transactions to perform operations. It even supports simple data types. IndexedDB may seem better than localstorage,but its API is complex to use and currently only latest desktop browsers are supported. For basic storage you may continue to use local storage but if you are going to store large amount of data, IndexedDB will be a better suited option as it will also allow you to perform complex search queries.

WebSQL was also a web storage API to store data at client side. Unlike IndexedDB which is a NoSQL database, WebSQL used SQL queries to store data. W3C no longer maintains this specification

For || operations system returns the first values where non-false data is received.
(0 || 2 || 3)
2
(1 || 2 || 3)
1
For && operations system returns the value where first false value is returned or otherwise the last values in expression
(1 && null && 3)
null
(1 && 2 && 3)
3

CacheStorage
caches is the global instance variable for CacheStorage.
The open() method of the CacheStorage interface returns a Promise that resolves to the Cache object matching the cacheName.
Note: If the specified Cache does not exist, a new cache is created with that cacheName and a Promise that resolves to this new Cache object is returned.

caches.open(cacheName).then(function(cache) {
  // Do something with your cache
});

Methods
Cache.match(request, options)
Returns a Promise that resolves to the response associated with the first matching request in the Cache object.
Cache.matchAll(request, options)
Returns a Promise that resolves to an array of all matching requests in the Cache object.
Cache.add(request)
Takes a URL, retrieves it and adds the resulting response object to the given cache. This is functionally equivalent to calling fetch(), then using put() to add the results to the cache.
Cache.addAll(requests)
Takes an array of URLs, retrieves them, and adds the resulting response objects to the given cache.
Cache.put(request, response)
Takes both a request and its response and adds it to the given cache.
Cache.delete(request, options)
Finds the Cache entry whose key is the request, returning a Promise that resolves to true if a matching Cache entry is found and deleted. If no Cache entry is found, the promise resolves to false.
Cache.keys(request, options)
Returns a Promise that resolves to an array of Cache keys.

prom().then(function(res) {
	console.log("inside then", res);
	throw Error();
}).catch(function(er) {
	console.log("inside catch", er);
	return 400;
}).catch(function(er) {
	console.log("inside catch", er);
	return 500;
}).then(function(res) {
	console.log("inside then 2", res);
	return 200;
});
VM92:2 inside then 40
VM92:5 inside catch Error
    at <anonymous>:3:8
    at <anonymous>
VM92:11 inside then 2 400

<link rel="stylesheet" type="text/css" media="all" href="styles/html5.css" />
media attribute in link tag specifies for which media this style sheet will be used.

The :root selector allows you to target the highest-level "parent" element in the DOM, or document tree. It is defined in the CSS Selectors Level 3 spec as a “structural pseudo-class”, meaning it is used to style content based on its relationship with parent and sibling content.

In the overwhelming majority of cases you're likely to encounter, :root refers to the <html> element in a webpage. In an HTML document the html element will always be the highest-level parent, so the behaviour of :root is predictable. However, since CSS is a styling language that can be used with other document formats, such as SVG and XML, the :root pseudo-class can refer to different elements in those cases. Regardless of the markup language, :root will always select the document's top-most element in the document tree.


The gutters between columns in our predefined grid classes can be removed with .no-gutters. This removes the negative margins from .row and the horizontal padding from all immediate children columns.

Here’s the source code for creating these styles. Note that column overrides are scoped to only the first children columns and are targeted via attribute selector. While this generates a more specific selector, column padding can still be further customized with spacing utilities.
.no-gutters {
  margin-right: 0;
  margin-left: 0;

  > .col,
  > [class*="col-"] {
    padding-right: 0;
    padding-left: 0;
  }
}

display
This defines a flex container; inline or block depending on the given value. It enables a flex context for all its direct children.

.container {
  display: flex; /* or inline-flex */
}
Note that CSS columns have no effect on a flex container.

#flex-direction

This establishes the main-axis, thus defining the direction flex items are placed in the flex container. Flexbox is (aside from optional wrapping) a single-direction layout concept. Think of flex items as primarily laying out either in horizontal rows or vertical columns.

.container {
  flex-direction: row | row-reverse | column | column-reverse;
}
row (default): left to right in ltr; right to left in rtl
row-reverse: right to left in ltr; left to right in rtl
column: same as row but top to bottom
column-reverse: same as row-reverse but bottom to top
#flex-wrap


By default, flex items will all try to fit onto one line. You can change that and allow the items to wrap as needed with this property.

.container{
  flex-wrap: nowrap | wrap | wrap-reverse;
}
nowrap (default): all flex items will be on one line
wrap: flex items will wrap onto multiple lines, from top to bottom.
wrap-reverse: flex items will wrap onto multiple lines from bottom to top.
There are some visual demos of flex-wrap here.

#flex-flow (Applies to: parent flex container element)
This is a shorthand flex-direction and flex-wrap properties, which together define the flex container's main and cross axes. Default is row nowrap.

flex-flow: <‘flex-direction’> || <‘flex-wrap’>
#justify-content

This defines the alignment along the main axis. It helps distribute extra free space left over when either all the flex items on a line are inflexible, or are flexible but have reached their maximum size. It also exerts some control over the alignment of items when they overflow the line.

.container {
  justify-content: flex-start | flex-end | center | space-between | space-around | space-evenly;
}
flex-start (default): items are packed toward the start line
flex-end: items are packed toward to end line
center: items are centered along the line
space-between: items are evenly distributed in the line; first item is on the start line, last item on the end line
space-around: items are evenly distributed in the line with equal space around them. Note that visually the spaces aren't equal, since all the items have equal space on both sides. The first item will have one unit of space against the container edge, but two units of space between the next item because that next item has its own spacing that applies.
space-evenly: items are distributed so that the spacing between any two items (and the space to the edges) is equal.
#align-items

This defines the default behaviour for how flex items are laid out along the cross axis on the current line. Think of it as the justify-content version for the cross-axis (perpendicular to the main-axis).

.container {
  align-items: flex-start | flex-end | center | baseline | stretch;
}
flex-start: cross-start margin edge of the items is placed on the cross-start line
flex-end: cross-end margin edge of the items is placed on the cross-end line
center: items are centered in the cross-axis
baseline: items are aligned such as their baselines align
stretch (default): stretch to fill the container (still respect min-width/max-width)
#align-content

This aligns a flex container's lines within when there is extra space in the cross-axis, similar to how justify-content aligns individual items within the main-axis.

Note: this property has no effect when there is only one line of flex items.

.container {
  align-content: flex-start | flex-end | center | space-between | space-around | stretch;
}
flex-start: lines packed to the start of the container
flex-end: lines packed to the end of the container
center: lines packed to the center of the container
space-between: lines evenly distributed; the first line is at the start of the container while the last one is at the end
space-around: lines evenly distributed with equal space around each line
stretch (default): lines stretch to take up the remaining space


order

By default, flex items are laid out in the source order. However, the order property controls the order in which they appear in the flex container.

.item {
  order: <integer>; /* default is 0 */
}
#flex-grow

This defines the ability for a flex item to grow if necessary. It accepts a unitless value that serves as a proportion. It dictates what amount of the available space inside the flex container the item should take up.

If all items have flex-grow set to 1, the remaining space in the container will be distributed equally to all children. If one of the children has a value of 2, the remaining space would take up twice as much space as the others (or it will try to, at least).

.item {
  flex-grow: <number>; /* default 0 */
}
Negative numbers are invalid.

#flex-shrink
This defines the ability for a flex item to shrink if necessary.

.item {
  flex-shrink: <number>; /* default 1 */
}
Negative numbers are invalid.

#flex-basis
This defines the default size of an element before the remaining space is distributed. It can be a length (e.g. 20%, 5rem, etc.) or a keyword. The auto keyword means "look at my width or height property" (which was temporarily done by the main-size keyword until deprecated). The content keyword means "size it based on the item's content" - this keyword isn't well supported yet, so it's hard to test and harder to know what its brethren max-content, min-content, and fit-content do.

.item {
  flex-basis: <length> | auto; /* default auto */
}
If set to 0, the extra space around content isn't factored in. If set to auto, the extra space is distributed based on its flex-grow value. See this graphic.

#flex
This is the shorthand for flex-grow, flex-shrink and flex-basis combined. The second and third parameters (flex-shrink and flex-basis) are optional. Default is 0 1 auto.

.item {
  flex: none | [ <'flex-grow'> <'flex-shrink'>? || <'flex-basis'> ]
}
It is recommended that you use this shorthand property rather than set the individual properties. The short hand sets the other values intelligently.

#align-self

This allows the default alignment (or the one specified by align-items) to be overridden for individual flex items.

Please see the align-items explanation to understand the available values.

.item {
  align-self: auto | flex-start | flex-end | center | baseline | stretch;
}
Note that float, clear and vertical-align have no effect on a flex item.

:target - The target pseudo class is used in conjunction with IDs, and match when the hash tag in the current URL matches that ID. So if you are at URL www.yoursite.com/#home then the selector #home:target will match. That can be extremely powerful. For example, you can create a tabbed area where the tabs link to hash tags and then the panels "activate" by matching :target selectors and (for example) using z-index to move to the top.

:enabled - Selects inputs that are in the default state of enabled and ready to be used.

:disabled - Selects inputs that have the disabled attribute. A lot of browsers will make the input a faded out gray, you can control that with this selector.


:checked - Selects checkboxes that are, wait for it, checked.

:indeterminate - Selects radio buttons that are in the purgatory state of neither chosen or unchosen (like when a page loads with radio button choices but no default is set).

:root - Selects the element that is at the root of the document. Almost certainly will select the <html> element, unless you are specifically working in some weird environment that somehow also allows CSS. Perhaps XML.

:first-child - Selects the first element within a parent.

:last-child - Selects the last element within a parent.

:nth-child() - Selects elements based on a simple provided algebraic expression (e.g. "2n" or "4n-1"). Has the ability to do things like select even/odd elements, "every third", "the first five", and things like that. Covered in more detail here with a tester tool.

:nth-of-type() - Works like :nth-child, but used in places where the elements at the same level are of different types. Like if inside a div you had a number of paragraphs and a number of images. You wanted to select all the odd images. :nth-child won't work there, you'd use div img:nth-of-type(odd). Particularly useful when working with definition lists and their alternating <dt> and <dd> elements.

:first-of-type - Selects the first element of this type within any parent. So if you have two divs, each had within it a paragraph, image, paragraph, image. Then div img:first-of-type would select the first image inside the first div and the first image inside the second div.

:last-of-type - Same as above, only would select the last image inside the first div and the last image inside the second div.

:nth-last-of-type() - Works like :nth-of-type, but it counts up from the bottom instead of the top.

:nth-last-child() - Works like :nth-child, but it counts up from the bottom instead of the top.

:only-of-type - Selects only if the element is the only one of its kind within the current parent.

:not() - Removes elements from an existing matched set that match the selector inside the parameter of :not(). So for example, all divs except those with a class of "music" = div:not(.music). The spec says that :not selectors cannot be nested, but they can be chained. Some browsers (Firefox) also support comma-separated selectors as the selector parameter, although chaining them would be a far safter bet. Also useful in conjunction with attribute selectors, e.g. input:not([disabled]).

:empty - Selects elements which contain no text and no child elements. Like: <p></p>

p:nth-child  only works when there is no other element inside container or the target element is actally the direct nth number child of the parent otherwise we will need to use nth-of-type.

Pseudo Elements vs Pseudo Selectors
These are appropriately called pseudo "elements" (not selectors) because they don't select any "real" element that exists on the page. This goes for these two, as well as the previous sections :first-letter and :first-line. Make sense? Like the first letter that ::first-letter selects isn't an element all to itself, it's just a part of an existing element, hence, pseudo element.

::	pseudo element	selects some actual content
:	pseudo selector	selects elements in certain conditions

To capture right click
Use the oncontextmenu event.

Here's an example:

<div oncontextmenu="javascript:alert('success!');return false;">
    Lorem Ipsum
</div>
And using event listeners:

el.addEventListener('contextmenu', function(ev) {
    ev.preventDefault();
    alert('success!');
    return false;
}, false);


Prior to Angular 1.3 (when you could define controllers on the global scope), Angular was able to automatically discover controllers that were defined globally.

As of Angular 1.3, all controllers have to be defined within a module, and thus, you'd get very limited functionality out of an ng-app without a module. It could potentially be beneficial for prototyping, but even there, you're not going to get much.

So, pre-angular 1.3 usage:

<div ng-app>
   <div ng-controller="SomeController">
       {{something}}
   </div>
</div>
You could define your javascript like this and it would work:

<script>
    function SomeController($scope) {
        $scope.something = "Hello";
    }
</script>

As mentioned in the comments, you can still enable this behavior by using $controllerProvider.allowGlobals(). That said, the Angular team has tried to deter us from defining controllers this way from the start, and should be avoided:
NOTE: Although Angular allows you to create Controller functions in the global scope, this is not recommended. In a real application you should use the .controller method of your Angular Module for your application [...]

Good question. The difference is simple - there is absolutely no difference between the two except that certain HTML5 validators will throw an error on a property like ng-app, but they don't throw an error for anything prefixed with data-, like data-ng-app.

So to answer your question, use data-ng-app if you would like validating your HTML to be a bit easier.

Fun fact: You can also use x-ng-app to the same effect.

 Initializing angular application without ng-app
<!DOCTYPE html>  
<html>  
<head lang="en">  
    <meta charset="utf-8">  
    <title>Manual Initializing</title>  
</head>  
<body>  
    <div id="container">  
        10 * 20 is {{ 10 * 20 }}.  
    </div>  
    <script type="text/javascript" src="angular.min.js"></script>  
    <script type="text/javascript" src="app.js"></script>  
</body>  
</html>   
In the code above, we have not used the ng-app directive in any of the elements. But we will be initializing the app from JavaScript.
 
In the app.js file: 
var app = angular.module("app", []);  
angular.bootstrap(document.getElementById("container"), ["app"])   

scope for two elements having same directive are not same they both are two separately different scopes.

By default, directives do not create their own scope; instead they use the scope of their parent, generally a controller (within the scope of which the directive is defined).

The value of the scope field defines how the scope of the directive will be created and used
When the scope of directive is not set it uses its parent scope.
Angular creates a new scope for the directive that is inherited from the parent (controller) scope.
But this restricts the directive to be used outside the controller scope, which reduces the directive’s reusability.

if we modify the controller scoped element first then all the elements using that same model will be updated including directives (isolated also) but if we change the directive value and then change the controller value the changes won't be now reflected in directives. This is because angular creates a separate variable only when there is an actual need for it untill then it only refers to parent. So in case of isolated scope all the properties are kept as reference to parent properties untill there is some another value for those properties that are directive specific. 

{} This way, the scope of the directive is not inherited from the parent and is instead completely detached from it. Thus, the directive has an isolated scope.

Both scope: true and scope:{} will create a child scope for the directive. But,

scope:true will prototypically inherit the properties from the parent(say the controller where the directive comes under) where as scope:{} will not inherit the properties from the parent and hence called isolated

When working with & prefix to interact with parent method if we have a local directive method name avaiable as used in ng-click or so then the rule defined by & is not considered and a normal call to that local method is made with the given arguments but if a local method is not found then rule & is considered and whatever is the value of the attribute of directive element used in & is replaced in ng-click or so.

when we set transclude inside directive to be true, then wherever in the directive template we encounter ng-transclude attr, the child contents from inside the custom element on which the directive is created are put inside the element on which ng-transclude was defined.
with replace:true the complete element is replaced with the directive template value instead of appending it inside the custom element.

link function can take two values, a callback and a json with post and pre as its properties.
Post link or post is what we generally refer to as link function.
The order of execution , for a nested directive , is first all the pre-link methods get executed from parent to child and then all the post-link methods get executed from child to parent.
You need almost never use preLink. Viable cases for it are when you need to manipulate data in scope, but not the DOM, before link functions (also of other directives) are executed.


Compile function executes only once and At this point it is safe for the code inside the compile function to manipulate the element, however it is not a place where you want the code to wire up event handlers. The element passed to compile in this scenario will be an element that the framework clones three times because we are working inside an ngRepeat. It will be the clones of this element the framework places into the DOM, and these clones are not available until the linking functions start to run. The idea behind the compilation step is to allow for one time DOM manipulation before the cloning – a performance optimization.
This compile function in the sample above returns an object with the pre and post linking functions.
Hence we can only use either compile method of link method.

Pre methods are executed first from top to bottom and then post methods are executed from bottom to top.

Inside compile the element received is same as that rendered in browser initially. In Pre-Link the element or dom available in compile or after compile is cloned and template is inserted into the element.
In Post-link transclude happens.

So order would be
Compile -parent
Compile -child
--------- Below three get executed iteratively when working with ng-repeat or if rendered multiple times -------
Controller
Pre top-bottom
Post bottom-to-top

Controller in directive is a place where directive can define it’s public API. A directive can have its own controller defined with a callback or an external controller used. This controller serves as the central point to manipulate and share the vairables to different directives on the same element or parent.
Controller is used for inter directive communication.

Require options states the dependencies of the current directive on other directives.
require option sign:
require: ‘shoppingWidget’ : It specifies that a directive shoppingWidget must be present on the element the current directive is applied on. If it is not found, AngularJS will throw an exception.
require: ‘^shoppingWidget’ : It specifies that a directive shoppingWidget must be present on the parent hierarchy [not necessarily immediate parent] of the element the current directive is applied on. If it is not found, AngularJS will throw an exception.
require: ‘?shoppingWidget’ : It specifies that a directive shoppingWidget is an optional dependency. If it is not found on the same element, no exception will be thrown. But then AngularJS will pass null as 4th argument to the link function. Don’t forget to null-check before using the controller in this case.
require: ‘?^shoppingWidget’ : It specifies that a directive shoppingWidget is an optional dependency. If it is not found on the parent hierarchy of the current element this directive is applied on, no exception will be thrown. But then AngularJS will pass null as 4th argument to the link function. Don’t forget to null-check before using the controller in this case.

When using controllers inside directives we need to assign values to 'this' and not $scope . $scope inside controller directive scope so if we set values on it then child direcitves will get value only when they are not in isolated scope.

$parent is used for getting values form parent scope.
bindToController binds the isolated scope variables to controller rather than to scope.
So now in directive controller 
// controller
function FooDirCtrl() {

  this.bar = {};
  this.doSomething = function doSomething(arg) {
    this.bar.foobar = arg;
    this.name = arg.prop; // reference the isolate property using `this`
  }.bind(this);

}
instead of $scope.name we can refer it by this.name.

$scope.$eval, $parse and $interpolate all are used to evaluate expressions which are angular expressions and not javascript expressions.
$eval and $interpolate both use $parse behind the scenes.

$scope.$eval takes in a string or function which it treats as angular expressions and returns the result for it. We can pass in default values for the variables . If defaults are given then they will take preceedence over the scope values.
$scope.$eval works for $scope object only and this is implicitly defined inside eval's construct so 
$scope.$eval("a + b + c", {c: 20}) will evaluate a+b+c taking a,b from scope object and c from defaults given.
We can assign value in eval when using function as angular expression instead of string.
var r = $scope.$eval(function(scope, locals) {
  scope.a = locals.a;
  return (a * b + c / 20);
}, {a:3, c: 3});

$parse works same as $eval but with following restrictions
1). It needs to be injected in controller
2). It does not return a result but returns a function
3). Its not bound to scope only as eval
4). The function it returns can be run on any onject and not only on scope.

using $parse we can use assign method which can be used to assign or change any property on the object.

$interpolate works again same as $parse but will not consider the string passed to it as a angular expression , rather it will try to find out angular expressions inside the string. So we need to include {{}} while using $interpolate. This also needs to be injected in controller.

We use transclude function when we don't want to use ng-transclude to do the job automatically.
The main use case for using the transclude function is when you need to do some non-trivial DOM manipulation involving the transcluded elements. This might mean rearranging elements, transcluding into muliple places, etc. These aren't necessarily typical scenarios but they are legitimate and real in some apps.
Looking closely at the snippet above you should noticed one important detail right away:

• you have control over how and where that content gets added to the DOM
Another equally important detail which is not visible in the snippet above, but can be seen in the one below:

• you have control over the scope bound to the transcluded content
.directive('myDirective', function() {
    return {
        transclude: true,
        templateUrl: 'someTemplate.html',
        link: function(scope, el, attrs, ctrl, transcludeFn) {
            transcludeFn( scope, function( clonedTranscludedContent ) {
                el.append( clonedTranscludedContent );
            });
        }
    };
})

The AngularJS $new method is used to create new child scope object. The $new takes boolean isolate and parent scope object as parameter. If isolate is set to true then the scope does not prototypically inherit from the parent scope and thus cannot see parent scope properties.

The default value for parent is this scope if not provided otherwise provided parent will be the $parent of the newly created scope. The scope can be removed from the scope hierarchy using $destroy() method.

Syntax

$new(isolate, parent);
AngularJS $scope.$new() Function Example
<!DOCTYPE html>        
<html>        
<head> <!-- www.techstrikers.com -->        
 <script src="//ajax.googleapis.com/ajax/libs/angularjs/1.3.0-beta.1/angular.min.js"></script>         
    <meta charset="utf-8">        
    <title>AngularJS $new Example</title>        
  <script>        
var app = angular.module('app', []);        
    app.controller("NewController", function($scope) { 
      var parent = $scope;
      var child = parent.$new();
      $scope.result = "";
      
        $scope.parentCall = function() {
           parent.salutation = "Hello";
          parent.name = "Jimi Scott";
          $scope.result = parent.salutation + " " + parent.name;
        }
        $scope.childCall = function() {
            child.salutation = "Welcome";
          child.name = "Robert J";
          $scope.result = child.salutation + " " + child.name;
        }
    });     
</script>        
</head>        
<body style="background-color:#DDE4E9;">        
  <fieldset style="background-color:#DDE4E9;">                    
    <legend>AngulerJS $new Method Example</legend>         
  <div ng-app="app">              
    <div ng-controller="NewController">   
      <p style="font-family:Arial;color:yellow;background:steelblue;padding:3px;width:350px;"    
     >{{result}}</p>
      
     <button ng-click="parentCall()">From Parent</button>
      <button ng-click="childCall()">From Child</button>
   
    </div>              
</div>        
 </fieldset>         
</body>        
</html>   

$watch -> watches a single expression given as string argument, shallow by default which means wacthes just the variable to change its reference. So if a variable is an array and we replace it with anything else such string or other array it will trigger the watch.
watch takes four arguments 
$watch(watchExpression, listener, [objectEquality], prettyPrintExpression)
1). expression to watch
2). callback or listener to excute when watch matches.
3). objectEquality which is a boolean stating if watch needs to be deep. In this case watch will watch all the properties of the element and even its sub properties to eny depth.
4). If passed, it overrides the watch expression. This parameter is NOT meant to be used in normal calls to $watch(); it is used internally by expression parser.

$watchCollection will shallow watch i.e. by reference watch, all the sub elements of array or object to first level.

$watchGroup will work same as shallow $watch but with multiple number of expressions and returns array of the old and new values for all the expressions.

For all the watch methods OLD VALUE is the value of the element before the first trigger change occured.
so if 
$scope.arrNames = ['shailendra', 'deepak', 'mohit', 'kapil'];
$scope.objs = {
  departs: ["Eng", 'Math', "Applied", "Theoretical"],
  deMap: {eng: ['IT', 'CS', 'MECH', "BIO"], applied: ['PHY', 'CHEM', 'ECO'], theoretical: ['PHY', 'CHEM']},
  teachers: {eng: 14, math: 5, applied: 10, theoretical: 20}
}

then 
$scope.arrNames.push("Kushagra"); // triggers collection change
// $scope.arrNames[0] = "Danny" // collection change
$scope.arrNames = [1,2,3,4,5];

this produces the following $watch values
Watch TRUE ===  (5) [1, 2, 3, 4, 5] (4) ["shailendra", "deepak", "mohit", "kapil"] , 0: "shailendra"1: "deepak"2: "mohit"3: "kapil"length: 4__proto__: Array(0)
Watch FALSE ===  (5) [1, 2, 3, 4, 5] (5) ["shailendra", "deepak", "mohit", "kapil", "Kushagra"]

as we can see for false the break point is when we replace the value so the old value is incluing the new push Kushagra
but for true the break point is everything we did above so it takes the value before the first change occured.

$watch and $apply are connected with $digest.
Digest cycle runs automatically when any controller is loaded. For other cases we need to run it manually.
For runny it manually we can use $apply or we can directly call $digest.
THe difference is with $scope.$apply we can use a callback method something like $scope.$apply(function() {}) so this way $apply will execute whatever is there inside callback and the call $scope.$digest. Also the code inside callback will be tied to a try and catch block.
When calling $digest instead of $apply we don't get try catch facilities we should then manually use them. 
$apply os equivalent to calling callback() and then calling $scope.$digest();

While in digest cycle parser goes through each watcher and if there is some change in the value from the last digest cycle run then its listener method gets called based on what type of watcher we are using. 

Suppose if we are using $watch and we push a new valu into array then its not that because old value is different from the new value it will go inside the callback. This is because the old value will be the value before the first break point and because for shallow watch the break point is when we change the reference of the element to new element and because there is no such break point so the old value is equal to the new value.

After parse is done with all the watchers in the list it again goes back to the top of the list and checks if due to the calls to the listeners in the current cycle has some other expression which is being watched changed. If something changed the it calls that listener and keeps repeating this process untill 10 times. If after 10 times also there are changes then angular generates error.

ng-if automatically internally binds a watcher to the expression given

$broadcast and $emit raise events and the difference between two the flow of events. 
$broadcast send event to all the child controllers from top to bottom.
$emit sends the events in opposite direction that is from child to all parent controllers.
$on is used to bind or listen to these events.

app.controller("MyController1", function ($scope, $rootScope) {
    //raise event on $rootScope
    $scope.OnClick = function (evt) {
        $rootScope.$broadcast("SendDown", "some data");
    }

    //event handler
    $scope.$on("SendDown", function (evt, data) {
        $scope.Message = "Inside MyController1 : " + data;
    });

});

app.controller("MyController2", function ($scope, $rootScope) {
    //event handler
    $scope.$on("SendDown", function (evt, data) {
        $scope.Message = "Inside MyController2 : " + data;
    });

});

app.controller("MyController3", function ($scope, $rootScope) {
    //event handler
    $scope.$on("SendDown", function (evt, data) {
        $scope.Message = "Inside MyController3 : " + data;
    });
});
broadcasting and emitting can be done on ascope or rootScope both.
If we are binding the event listener and also sending broadcasting or emitting the event then order matters.
Because As soon as event is broadcasted it looses control over the current controller and forwards everything to child or parent controller.
$$phase tells angular is in which phase is it $apply which is in case when any controller is loaded.
or Compile > Link > $digest
During the template linking phase the directives set up $watch expressions on the scope. The $watch allows the directives to be notified of property changes, which allows the directive to render the updated value to the DOM.
Different apis like $timeout and $http, they automatically call the digest cycle.
Angular expression also create watchers {{}}.
At the end of $apply, AngularJS performs a $digest cycle on the root scope, which then propagates throughout all child scopes. 
Observing directives, such as double-curly expressions {{expression}}, register listeners using the $watch() method. This type of directive needs to be notified whenever the expression changes so that it can update the view.

"$rootScope” is a parent object of all “$scope” angular objects created in a web page.

$scope is created with ng-controller while $rootscope is created with ng-app.

The root scope is created during the application bootstrap by the $injector. During template linking, some directives create new child scopes.
with ng-repeat, as its already a directive, a digest cycle is already started so when we bind our custom directive on that same element when get $digest as $$phase value.
Each web application you build is composed of objects that collaborate to get stuff done. These objects need to be instantiated and wired together for the app to work. In AngularJS apps most of these objects are instantiated and wired together automatically by the injector service.

The injector creates two types of objects, services and specialized objects.

Services are objects whose API is defined by the developer writing the service.

Specialized objects conform to a specific AngularJS framework API. These objects are one of controllers, directives, filters or animations.

When an AngularJS application starts with a given application module, AngularJS creates a new instance of injector, which in turn creates a registry of recipes as a union of all recipes defined in the core "ng" module, application module and its dependencies. The injector then consults the recipe registry when it needs to create an object for your application.

The injector needs to know how to create these objects. You tell it by registering a "recipe" for creating your object with the injector. There are five recipe types.

The most verbose, but also the most comprehensive one is a Provider recipe. The remaining four recipe types — Value, Factory, Service and Constant — are just syntactic sugar on top of a provider recipe.
The Service recipe produces a service just like the Value or Factory recipes, but it does so by invoking a constructor with the new operator. The constructor can take zero or more arguments, which represent dependencies needed by the instance of this type.

You should use the Provider recipe only when you want to expose an API for application-wide configuration that must be made before the application starts. This is usually interesting only for reusable services whose behavior might need to vary slightly between applications.

During application bootstrap, before AngularJS goes off creating all services, it configures and instantiates all providers. We call this the configuration phase of the application life-cycle. During this phase, services aren't accessible because they haven't been created yet.

Once the configuration phase is over, interaction with providers is disallowed and the process of creating services starts. We call this part of the application life-cycle the run phase.

Using Factory recipes, you can also define AngularJS's filters and animations, but the controllers are a bit special. You create a controller as a custom type that declares its dependencies as arguments for its constructor function. This constructor is then registered with a module. 
Note: All services in AngularJS are singletons. That means that the injector uses each recipe at most once to create the object. The injector then caches the reference for all future needs.

Run blocks - get executed after the injector is created and are used to kickstart the application. Only instances and constants can be injected into run blocks. This is to prevent further system configuration during application run time.

Run blocks are the closest thing in Angular to the main method. A run block is the code which needs to run to kickstart the application. It is executed after all of the service have been configured and the injector has been created. Run blocks typically contain code which is hard to unit-test, and for this reason should be declared in isolated modules, so that they can be ignored in the unit-tests.

Config block is executed during the provider registration and configuration phase. Only providers and constants can be injected into configuration blocks. This block is used to inject module wise configuration settings to prevent accidental instantiation of services before they have been fully configured.

The $provide service has a number of methods for registering components with the $injector. Many of these functions are also exposed on angular.Module.
provider(name, provider) - registers a service provider with the $injector
constant(name, obj) - registers a value/object that can be accessed by providers and services.
value(name, obj) - registers a value/object that can only be accessed by services, not providers.
factory(name, fn) - registers a service factory function that will be wrapped in a service provider object, whose $get property will contain the given factory function.
service(name, Fn) - registers a constructor function that will be wrapped in a service provider object, whose $get property will instantiate a new object using the given constructor function.
decorator(name, decorFn) - registers a decorator function that will be able to modify or replace the implementation of another service.

The provider methods off the module definition are just short cuts. Use them as often as you like because it leads to shorter, easier to read and understand code. Less ritual/ceremony is involved than injecting the $provider service and calling that directly. The main reason to use $provide directly is to access a method on it that is not a short cut from module (such as the decorator) or if you have to do something from within a service or component that is not up at the module definition level.

The common case for changing a provider after it's definition is when you are integrating a third-party component and want to add or change the behavior. The third-party module will define the service and then you step in and override or extend it in some way that is specific to your app. A common case for example is to take the built-in Angular exception handler and extend that to interface with your own components.

$scope is a special "glue" used for data-binding and only exposes properties/functions that you explicitly set on the $scope. All of the other miscellaneous modules/services are stored within Angular's dependency injection container. The very first thing Angular does is create an $injector instance to keep track of dependencies. Therefore $injector === $injector.get('$injector'). Same with $provide. Anything prefixed with a $ is by convention a service that Angular places in the $injector for you to use.

So in summary, provider, factory, and service are all providers. A factory is a special case of a provider when all you need in your provider is a $get() function. It allows you to write it with less code. A service is a special case of a factory when you want to return an instance of a new object, with the same benefit of writing less code.

Value is another provider when we just want to return a simple string or number.
mod.factory("myProvider", function() {
    return "My Value";
});
mod.value("myProvider", "My Value");
but if we need to do som calculations on it then we may need to use factory.
mod.value("multiple", 3);
mod.factory("value", function(multiple) { 
    return 10 * multiple; 
});

Constant is another case of value in which the value cannot be changed once assigned and its also available in config block.


$rootScopeProvider
- $rootScope
- provider in module ng
CONTENTSHide
Overview
Methods
digestTtl(limit);
Overview
Provider for the $rootScope service.

Methods
digestTtl(limit);

Sets the number of $digest iterations the scope should attempt to execute before giving up and assuming that the model is unstable.

The current default is 10 iterations.

In complex applications it's possible that the dependencies between $watchs will result in several digest iterations. However if an application needs more than the default 10 digest iterations for its model to stabilize then you should investigate what is causing the model to continuously change during the digest.

Increasing the TTL could have performance implications, so you should not change it without proper justification.

Factory, service, value, constant, filter are all derived from provier.

provider.service = function(name, Class) {
  provider.provide(name, function() {
    this.$get = function($injector) {
      return $injector.instantiate(Class);
    };
  });
}

provider.factory = function(name, factory) {
  provider.provide(name, function() {
    this.$get = function($injector) {
      return $injector.invoke(factory);
    };
  });
}

provider.value = function(name, value) {
  provider.factory(name, function() {
    return value;
  });
};

Some Builtin filters
currency Format a number to a currency format.
date Format a date to a specified format.
filter Select a subset of items from an array.
json Format an object to a JSON string.
limitTo Limits an array/string, into a specified number of elements/characters.
lowercase Format a string to lower case.
number Format a number to a string.
orderBy Orders an array by an expression.
uppercase Format a string to upper case.

as $get method of provider gets instantiated it happens only once.
function returnO() {
	this.mq = function() {console.log('hi')}
	return {
		1: 2,
		2: 3
	}
}

var ro = new returnO
ro
{1: 2, 2: 3}
1: 2
2: 3
__proto__: Objectconstructor: ƒ Object()hasOwnProperty: ƒ hasOwnProperty()isPrototypeOf: ƒ isPrototypeOf()propertyIsEnumerable: ƒ propertyIsEnumerable()toLocaleString: ƒ toLocaleString()toString: ƒ toString()valueOf: ƒ valueOf()__defineGetter__: ƒ __defineGetter__()__defineSetter__: ƒ __defineSetter__()__lookupGetter__: ƒ __lookupGetter__()__lookupSetter__: ƒ __lookupSetter__()get __proto__: ƒ __proto__()set __proto__: ƒ __proto__()
ro.mq
undefined

factory, service, value, constants are invoked and instantiated only once. So no matter how many time we inject them into other controllers, services or anywhere the same instance is given everytime. 

$rootScope is not avaiable till we reach run phase. Not available in config and not available inside provider except $get because that gets instantiated only when we inject it.

$RootScopeProvider {digestTtl: ƒ, $get: Array(4)}
$get:(4) ["$exceptionHandler", "$parse", "$browser", ƒ]
digestTtl:ƒ (value)

var rootscope = $rootScopeProvider.$get[3];
then we can get rootscope as rootscope();

We can take rootScopeProvider and inject it into config or any other provider and set its digestTtl limit.
$injector is also avaiable to inject in providers and config block. So as soon as app gets created it creates and injector based on the app and ng-app directive but no services or factories , etc are attached to it and only after the config has ended the loading of fatories and services are done.

AngularJS Filters allow us to format the data to display on UI without changing original format.
Filters can be used with an expression or directives using pipe | sign.
{{expression | filterName:parameter }}
Filter are not instantiated but invoked so everytime we change anything and a filter needs to be invoked it gets invoked as a fresh.

<div ng-init="age = 300">
        {{age | getAge}}
</div>

If element of expression is inside a controller then 'this' it gives the parent controller scope if inside controller otherwise it gives rootscope.

There are two important builtin filters 
orderBy, filter

orderBy filter takes in 4 arguments 
collection, expression, reverse, comparator

collection is the value or model on which the orderBy filter needs to be applied for example $scope.friends.
expression is the value inside collection which will be compared inorder to re order the collection.
reverse takes in boolean to reverse the sort order
comparator is the custom comparing function which will be called for comparing the expression. If custom comparator is unable to sort the values then default comparator will be used.
Default comparator has some rules for comparing the values
If the compared values are of different types, compare the types themselves alphabetically.
If both values are of type string, compare them alphabetically in a case- and locale-insensitive way.
If both values are objects, compare their indices instead.
Otherwise, return:
0, if the values are equal (by strict equality comparison, i.e. using ===).
-1, if the 1st value is "less than" the 2nd value (compared using the < operator).
1, otherwise.
Note: If you notice numbers not being sorted as expected, make sure they are actually being saved as numbers and not strings. Note: For the purpose of sorting, null values are treated as the string 'null' (i.e. type: 'string', value: 'null'). This may cause unexpected sort order relative to other values.
the value of the expression is converted to 
{
  value: 'foo',
  type: 'string',
  index: ...
}
If you use a custom comparator, it will be called with pairs of objects of the form {value: ..., type: '...', index: ...} and is expected to return 0 if the objects are equal (as far as the comparator is concerned), -1 if the 1st one should be ranked higher than the second, or 1 otherwise.

In order to ensure that the sorting will be deterministic across platforms, if none of the specified predicates can distinguish between two items, orderBy will automatically introduce a dummy predicate that returns the item's index as value. (If you are using a custom comparator, make sure it can handle this predicate as well.)

Filters run anytime when digest cycle runs.
filter gets executed in every digest cycle, and keeps checking your value is changed or not, if value is changed then it evaluates again and gives new result, otherwise it doesn't do anything (becaues angularJs uses "dirty-checking" method to find any change)
Thats why we return a function from filters so that a watcher can be put on that function based on the value it returns.

sorting algo in orderBy filter
if we are sorting ascending order then if we return -1 that means that 2nd value is bigger than 1st hence we are on correct track so that for next value we check if 2nd value from previous operation > that 2nd value now. If we return 1 that means we are still on right track and the new 2nd value is > 1st value(2nd value in previous operation) and hence also greater than 1st value in previous operation and hence we do not need to change the order of the values.
so for three values a, b, c the following condition holds
a < b < c (correct asc order)
but if we return 1 at some point then at that point the 2nd value is greater than 1st value and hence we need to compare it with all the other previous values becaues now the condition is 
a < b > c so now b is greater than both and hence does not define relationship between them.

filter Filter
Selects a subset of items from array and returns it as a new array.
If custom comparator is given then that will be used to return the new array.
filter expression can be a string, an object, or a function
filters always receive complete object.
comparator for filter filter takes true, false and function as values. When true it matches using angular.equals when false it matches using substring and when function then then values are passed to the Scomparator.

when expression is object then the key values inside it are checked in the actual payload and will match against that field only.
So {name: search} will match against name field only, in payload object.
If {name: '!M'} will match the values not having M in them.
If we have {$: nameModel} then it will macth all the values.
Decorators have different rules for different services. This is because services are registered in different ways. Services are selected by name, however filters and directives are selected by appending "Filter" or "Directive" to the end of the name. The $delegate provided is dictated by the type of service.

$q's custom methods (.catch and .finally) are implemented by using .then.

Decorators intercept the service and help us to modify the service at its core wihtout meddling with the actual code.
Decorators get called when the service is injected in to some other module and called. So just before instantiating it and making it available to use decorators are called.

$provide is only injectible in config.

Animations in AngularJS are completely based on CSS classes. As long as you have a CSS class attached to an HTML element within your application, you can apply animations to it.

All these methods extracts parts of a string and returns the extracted parts in a new string. And all of them does not change the original string.

1. slice() method can take 2 arguments:
Argument 1: begin, Required. The position where to begin the extraction. First character is at position 0. Use negative values to specify the position from the end of the string.

Argument 2: end, Optional. The position (up to, but not including) where to end the extraction. If omitted, slice() selects all characters from the start-position to the end of the string.Use negative numbers to select from the end of the string.

var numbers="0123456789";
console.log(numbers.slice(2,4));   // shows 23
console.log(numbers.slice(-7,-3)); // shows 3456
If end is omitted, slice extracts chars to the end of the string.

console.log(numbers.slice(3));  // shows 3456789
console.log(numbers.slice(-3)); // shows 789
If begin and end are equal or begin is greater than end, slice gives empty string.

console.log(numbers.slice(3,3));
console.log(numbers.slice(7,3));
console.log(numbers.slice(-3,-7)); 
 
// All of above shows (an empty string)
If either argument is greater than the string’s length, either argument will use the string’s length

console.log(numbers.slice(2,100));   // shows 23456789
//here end used the string's length that is 10.
 
console.log(numbers.slice(100,101)); // shows (an empty string)
If either argument is NaN, it is treated as if it were 0. 

console.log(numbers.slice(NaN,8)); // shows 01234567
console.log(numbers.slice(1,NaN)); // shows (an empty string)
2. substring() method can take 2 arguments:
Argument 1: from, Required. The position where to start the extraction. First character is at index 0.

Argument 2: to, Optional. The position (up to, but not including) where to end the extraction. If omitted, it extracts the rest of the string.

console.log(numbers.substring(3,5)); // shows 34
If to is omitted, substring extracts characters to the end of the string.

console.log(numbers.substring(3)); // shows 3456789
if from and to are equal or only from is provided with value greater than string’s length or equal to it, substring gives an empty string.

console.log(numbers.substring(10));
console.log(numbers.substring(100));
console.log(numbers.substring(3,3));  
 
//All of above shows (an empty string)
If either argument is greater than the string’s length, either argument will use the string’s length.

console.log(numbers.substring(0,101));   // shows 0123456789
console.log(numbers.substring(100,100)); // shows (an empty string)
If either argument is less than 0 or is NaN, it is treated as if it were 0.

console.log(numbers.substring(-3,5));  // shows 01234
console.log(numbers.substring(NaN,5)); // shows 01234
console.log(numbers.substring(-3));    // shows 0123456789
3. substr() method can take 2 arguments:
Argument 1: start, Required. The position where to start the extraction. First character is at index 0. To extract characters from the end of the string, use a negative start number.

Argument 2: length,Optional. The number of characters to extract. If omitted, it extracts the rest of the string.

console.log(numbers.substr(2,5)); // shows 23456
console.log(numbers.substr(-5,3)); //shows 567
if length is omitted than substr extracts characters to the end of the string.

console.log(numbers.substr(3)); // shows 3456789
console.log(numbers.substr(-3));// shows 789
if start is >= string’s length Or length <= 0 or NaN than substr gives empty string.

console.log(numbers.substr(23,2));
console.log(numbers.substr(10,6));
console.log(numbers.substr(3,-6));
console.log(numbers.substr(3,0));
console.log(numbers.substr(3,NaN));
 
// All of above shows (an empty string)
if start is NaN, it is treated as if it were 0.

console.log(numbers.substr(NaN,3)); // shows 012
Hope this blog was helpful. I would love to answer any of your queries regarding the methods discussed in this blog.

When .stop() is called on an element, the currently-running animation (if any) is immediately stopped. If, for instance, an element is being hidden with .slideUp() when .stop() is called, the element will now still be displayed, but will be a fraction of its previous height. Callback functions are not called.

If more than one animation method is called on the same element, the later animations are placed in the effects queue for the element. These animations will not begin until the first one completes. When .stop() is called, the next animation in the queue begins immediately. If the clearQueue parameter is provided with a value of true, then the rest of the animations in the queue are removed and never run.

When .finish() is called on an element, the currently-running animation and all queued animations (if any) immediately stop and their CSS properties set to their target values. All queued animations are removed.

If the first argument is provided, only the animations in the queue represented by that string will be stopped.

The .finish() method is similar to .stop(true, true) in that it clears the queue and the current animation jumps to its end value. It differs, however, in that .finish() also causes the CSS property of all queued animations to jump to their end values, as well.

Animating colors does not work unless you include a library for animating colors.
jQuery does not animate colors by default.

always need to call done when working with module.animation.

angular animate addClass and removeClass methods fire when we add or remove classes from ng-class.

Directive	Supported Animations
ngRepeat	enter, leave, and move
ngIf	enter and leave
ngSwitch	enter and leave
ngInclude	enter and leave
ngView	enter and leave
ngMessage / ngMessageExp	enter and leave
ngClass / {{class}​}	add and remove
ngClassEven	add and remove
ngClassOdd	add and remove
ngHide	add and remove (the ng-hide class)
ngShow	add and remove (the ng-hide class)
ngModel	add and remove (various classes)
form / ngForm	add and remove (various classes)
ngMessages	add and remove (the ng-active/ng-inactive classes)

The following CSS classes are added and removed on the associated input/select/textarea element depending on the validity of the model.
ng-valid: the model is valid
ng-invalid: the model is invalid
ng-valid-[key]: for each valid key added by $setValidity
ng-invalid-[key]: for each invalid key added by $setValidity
ng-pristine: the control hasn't been interacted with yet
ng-dirty: the control has been interacted with
ng-touched: the control has been blurred
ng-untouched: the control hasn't been blurred
ng-pending: any $asyncValidators are unfulfilled
ng-empty: the view does not contain a value or the value is deemed "empty", as defined by the ngModel.NgModelController method
ng-not-empty: the view contains a non-empty value


Form
ng-valid is set if the form is valid.
ng-invalid is set if the form is invalid.
ng-pending is set if the form is pending.
ng-pristine is set if the form is pristine.
ng-dirty is set if the form is dirty.
ng-submitted is set if the form was submitted.

// returns true or false
$animate.enabled();

// changes the enabled state for all animations
$animate.enabled(false);
$animate.enabled(true);

// returns true or false if animations are enabled for an element
$animate.enabled(element);

// changes the enabled state for an element and its children
$animate.enabled(element, true);
$animate.enabled(element, false);

// remove all the animation event listeners listening for `enter`
$animate.off('enter');

// remove listeners for all animation events from the container element
$animate.off(container);

// remove all the animation event listeners listening for `enter` on the given element and its children
$animate.off('enter', container);

// remove the event listener function provided by `callback` that is set
// to listen for `enter` on the given `container` as well as its children
$animate.off('enter', container, callback);

Note that class-based animations are treated differently compared to structural animations (like enter, move and leave) since the CSS classes may be added/removed at different points depending if CSS or JavaScript animations are used.

cancel(animationPromise);
Cancels the provided animation.

enter, leave, move or remove they all insert/remove elements from dom and trigger animation bound using javascript or css. These all return a promise which is resolved during the next digest cycle.

Whenever an animation is started, ngAnimate applies the ng-animate class to the element for the whole duration of the animation.

By setting transition: 0s, ngAnimate will ignore the existing transition styles, and not try to animate them (Javascript animations will still execute, though)

structural animaton -> leave, enter, move
add/remove class are class animations.

Prevent flickering animations
When we have nested structural animations such as ng-if into elements that have class-based animations such as ngClass, it sometimes happen that before the animation starts there is a slight flicker in the animation and the element with structiral animation is visible for a fraction of seconds.

To remedy that we may use .ng-[event]-prepare class to disable animation when this class is present. This class is added to the element as soon as animation is initialised.
This class is only added for structural animations (enter, move, and leave).

Here's an example where you might see flickering:

<div ng-class="{red: myProp}">
  <div ng-class="{blue: myProp}">
    <div class="message" ng-if="myProp"></div>
  </div>
</div>
It is possible that during the enter event, the .message div will be briefly visible before it starts animating. In that case, you can add styles to the CSS that make sure the element stays hidden before the animation starts:

.message.ng-enter-prepare {
  opacity: 0;
}

When setting the classNameFilter value, animations will only be performed on elements
 * that successfully match the filter expression

 angular animation don't work if not used inside the allowed elements which animate

 A Staggering animation is a collection of animations that are issued with a slight delay in between each successive operation resulting in a curtain-like effect. The ngAnimate module (versions >=1.2) supports staggering animations and the stagger effect can be performed by creating a ng-EVENT-stagger CSS class and attaching that class to the base CSS class used for the animation.

 When a bunch of animations are run at the same time then $animate will automatically queue up everything to make things run faster. So if you have a ngRepeat animation for 20+ elements then all 20 elements will be bundled together and one reflow will happen which will trigger the animation effect for each one all at the same time

 After things are queued up, $animate waits for 10ms and once that timeout has passed then it will trigger the animation for each element. If $animate comes across a timeout delay (via a CSS class) then it generates the transition/keyframe animation delay values for each animation so that they're spaced-out.

 $provide doesnot have animate in it.

 angular.element will depend if jquery is available or niot if not then it will returns a JqLite object which a very minimal implementation of jquery otherwise it will return a proper jquery object which will allow us to do everything possible in jquery.

 Stagger animations are currently only supported within CSS-defined animations.

 The ng-[event]-prepare class
This is a special class that can be used to prevent unwanted flickering / flash of content before the actual animation starts. The class is added as soon as an animation is initialized, but removed before the actual animation starts (after waiting for a $digest). It is also only added for structural animations (enter, move, and leave).
Just make sure to have the done() callback fire the doneFn function to signal when the animation is over.

You can have just one ng-view.
You can change its content in several ways: ng-include, ng-switch or mapping different controllers and templates through the routeProvider.

Due to aa077e8, the default hash-prefix used for $location hash-bang URLs has changed from the empty string ('') to the bang ('!').

If you actually want to have no hash-prefix, then you can restore the previous behavior by adding a configuration block to your application:

appModule.config(['$locationProvider', function($locationProvider) {
  $locationProvider.hashPrefix('');
}]);

feat($location): default hashPrefix to '!'

The $location service is designed to support hash prefixed URLs
for cases where the browser does not support HTML5 push-state navigation.

The Google Ajax Crawling Scheme expects that local paths within a SPA start
with a hash-bang (e.g. `somedomain.com/base/path/#!/client/side/path`).

The `$locationProvide` allows the application developer to configure the
hashPrefix, and it is normal to set this to a bang '!', but the default
has always been the empty string ''.

This has caused some confusion where a user is not aware of this feature
and wonders why adding a hash value to the location (e.g. `$location.hash('xxx')`)
results in a double hash: `##xxx`.

This commit changes the default value of the prefix to '!', which is more
natural and expected.

See https://developers.google.com/webmasters/ajax-crawling/docs/getting-started

Closes #13812
Closes #14202

BREAKING CHANGE

The hash-prefix for `$location` hash-bang URLs has changed from the empty
string "" to the bang "!". If your application does not use HTML5 mode
or is being run on browsers that do not support HTML5 mode, and you have
not specified your own hash-prefix then client side URLs will now contain
a "!" prefix. For example, rather than `mydomain.com/#/a/b/c` will become
`mydomain/#!/a/b/c`.

If you actually wanted to have no hash-prefix then you should configure
this by adding a configuration block to you application:

```
appModule.config(['$locationProvider', function($locationProvider) {
  $locationProvider.hashPrefix("");
}]);
```

Anchor animation works by taking into consideration a fact that when ng-view changes so that some elements leave and some elements enter we can bind those elememts togather to produce a effect that the curremt element is being removed and new being added to its position.
We attach two elements by ng-animate-ref attr so the elements in the old view and new view that have this attr will be animated togather like if they are conencted to each other.
When angular sees such relation it makes a clone of first element (transition element), puts ng-anchor class on that and tries to animate it to new element.

When the animation happens, there are two stages that occur: an out and an in stage. The out stage happens first and that is when the element is animated away from its origin. Once that animation is over then the in stage occurs which animates the element to its destination. The reason why there are two animations is to give enough time for the enter animation on the new element to be ready.

$animateCss is just another service that should be used when we want to animate any element from inside a directive or a javascript app.animation.
.ng-EVENT-stagger or ng-EVENT or ng-EVENT-active these all are internally done by using $animateCss.

If there is another css class that is animating an element and we attach $animateCss to it both of them will be running.
The missing parts will be taken from each other. So if we do not specify a transition in $animateCss then it will be picked from css class definition and used with $animateCss also.
When using $animateCss outside app.animation or a place which will not trigger digest then we need to trigger digest manually and for that we have two methods returned from the object that is start and end.
So var animator = $animateCss(element, { ... }); will return 
{
  // starts the animation
  start: Function,

  // ends (aborts) the animation
  end: Function
}

start starts the animation by triggering a digest and will return a promise. end will stop the execution of animation.

Usage
$animateCss(element, options);

Arguments
Param	Type	Details
element	DOMElement	
the element that will be animated

options	object	
the animation-related options that will be applied during the animation

event - The DOM event (e.g. enter, leave, move). When used, a generated CSS class of ng-EVENT and ng-EVENT-active will be applied to the element during the animation. Multiple events can be provided when spaces are used as a separator. (Note that this will not perform any DOM operation.)
structural - Indicates that the ng- prefix will be added to the event class. Setting to false or omitting will turn ng-EVENT and ng-EVENT-active in EVENT and EVENT-active. Unused if event is omitted.
easing - The CSS easing value that will be applied to the transition or keyframe animation (or both).
transitionStyle - The raw CSS transition style that will be used (e.g. 1s linear all).
keyframeStyle - The raw CSS keyframe animation style that will be used (e.g. 1s my_animation linear).
from - The starting CSS styles (a key/value object) that will be applied at the start of the animation.
to - The ending CSS styles (a key/value object) that will be applied across the animation via a CSS transition.
addClass - A space separated list of CSS classes that will be added to the element and spread across the animation.
removeClass - A space separated list of CSS classes that will be removed from the element and spread across the animation.
duration - A number value representing the total duration of the transition and/or keyframe (note that a value of 1 is 1000ms). If a value of 0 is provided then the animation will be skipped entirely.
delay - A number value representing the total delay of the transition and/or keyframe (note that a value of 1 is 1000ms). If a value of true is used then whatever delay value is detected from the CSS classes will be mirrored on the elements styles (e.g. by setting delay true then the style value of the element will be transition-delay: DETECTED_VALUE). Using true is useful when you want the CSS classes and inline styles to all share the same CSS delay value.
stagger - A numeric time value representing the delay between successively animated elements (Click here to learn how CSS-based staggering works in ngAnimate.)
staggerIndex - The numeric index representing the stagger item (e.g. a value of 5 is equal to the sixth item in the stagger; therefore when a stagger option value of 0.1 is used then there will be a stagger delay of 600ms)
applyClassesEarly - Whether or not the classes being added or removed will be used when detecting the animation. This is set by $animate when enter/leave/move animations are fired to ensure that the CSS classes are resolved in time. (Note that this will prevent any transitions from occurring on the classes being added and removed.)
cleanupStyles - Whether or not the provided from and to styles will be removed once the animation is closed. This is useful for when the styles are used purely for the sake of the animation and do not have a lasting visual effect on the element (e.g. a collapse and open animation). By default this value is set to false.

In angular js form with name is an instance of FormController and inputs inside form with ng-model are instance of NgModelController.
So both are different when we create a form with name we get values such as prestine or touched assigned to form from FormController but not to inputs inside form. So thats why we need to attach ng-model with inputs so that we can get those prestine or touched values on inputs as well.

A form is an instance of FormController. The form instance can optionally be published into the scope using the name attribute.

Similarly, an input control that has the ngModel directive holds an instance of NgModelController. Such a control instance can be published as a property of the form instance using the name attribute on the input control. The name attribute specifies the name of the property on the form instance.

This implies that the internal state of both the form and the control is available for binding in the view using the standard binding primitives.

This allows us to extend the above example with these features:

Custom error message displayed after the user interacted with a control (i.e. when $touched is set)
Custom error message displayed upon submitting the form ($submitted is set), even if the user didn't interact with a control

AngularJS provides basic implementation for most common HTML5 input types: (text, number, url, email, date, radio, checkbox), as well as some directives for validation (required, pattern, minlength, maxlength, min, max).

With a custom directive, you can add your own validation functions to the $validators object on the ngModelController. To get a hold of the controller, you require it in the directive as shown in the example below.

Each function in the $validators object receives the modelValue and the viewValue as parameters. AngularJS will then call $setValidity internally with the function's return value (true: valid, false: invalid). The validation functions are executed every time an input is changed ($setViewValue is called) or whenever the bound model changes. Validation happens after successfully running $parsers and $formatters, respectively. Failed validators are stored by key in ngModelController.$error.

Additionally, there is the $asyncValidators object which handles asynchronous validation, such as making an $http request to the backend. Functions added to the object must return a promise that must be resolved when valid or rejected when invalid. In-progress async validations are stored by key in ngModelController.$pending.

ng-valid: the model is valid
ng-invalid: the model is invalid
ng-valid-[key]: for each valid key added by $setValidity
ng-invalid-[key]: for each invalid key added by $setValidity
ng-pristine: the control hasn't been interacted with yet
ng-dirty: the control has been interacted with
ng-touched: the control has been blurred
ng-untouched: the control hasn't been blurred
ng-pending: any $asyncValidators are unfulfilled

Following is the $error value which gets generated when validators inside $validator fail.

{
	"email": [{
		"$viewValue": "@",
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": false,
		"$touched": true,
		"$pristine": false,
		"$dirty": true,
		"$valid": false,
		"$invalid": true,
		"$error": {
			"email": true
		},
		"$name": "emailI",
		"$options": {}
	}],
	"pattern": [{
		"$viewValue": "12",
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": false,
		"$touched": true,
		"$pristine": false,
		"$dirty": true,
		"$valid": false,
		"$invalid": true,
		"$error": {
			"pattern": true
		},
		"$name": "nameI",
		"$options": {}
	}, {
		"$viewValue": "10",
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [null, null],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": false,
		"$touched": true,
		"$pristine": false,
		"$dirty": true,
		"$valid": false,
		"$invalid": true,
		"$error": {
			"pattern": true
		},
		"$name": "numberI",
		"$options": {}
	}]
}

So inside error we get the validation information based on the type of validation used. So if type=email is there then inside validator we will find email key or if pattern is the validator then we will find pattern key.
Form in angular is instance of FormController and gets following properties
{
	"$error": {
		"required": [
      {
			"$validators": {},
			"$asyncValidators": {},
			"$parsers": [],
			"$formatters": [null],
			"$viewChangeListeners": [],
			"$untouched": true,
			"$touched": false,
			"$pristine": true,
			"$dirty": false,
			"$valid": false,
			"$invalid": true,
			"$error": {
				"required": true
			},
			"$name": "emailI",
			"$options": {}
		}, 
    {
			"$validators": {},
			"$asyncValidators": {},
			"$parsers": [],
			"$formatters": [null],
			"$viewChangeListeners": [],
			"$untouched": true,
			"$touched": false,
			"$pristine": true,
			"$dirty": false,
			"$valid": false,
			"$invalid": true,
			"$error": {
				"required": true
			},
			"$name": "nameI",
			"$options": {}
		}
    ]
	},
	"$name": "form",
	"$dirty": false,
	"$pristine": true,
	"$valid": false,
	"$invalid": true,
	"$submitted": false,
	"emailI": {
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": true,
		"$touched": false,
		"$pristine": true,
		"$dirty": false,
		"$valid": false,
		"$invalid": true,
		"$error": {
			"required": true
		},
		"$name": "emailI",
		"$options": {}
	},
	"nameI": {
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": true,
		"$touched": false,
		"$pristine": true,
		"$dirty": false,
		"$valid": false,
		"$invalid": true,
		"$error": {
			"required": true
		},
		"$name": "nameI",
		"$options": {}
	},
	"numberI": {
		"$validators": {},
		"$asyncValidators": {},
		"$parsers": [null, null],
		"$formatters": [null],
		"$viewChangeListeners": [],
		"$untouched": true,
		"$touched": false,
		"$pristine": true,
		"$dirty": false,
		"$valid": true,
		"$invalid": false,
		"$error": {},
		"$name": "numberI",
		"$options": {}
	}
}

We can also delay the updation of the model using debounce techniques.
We can bind the updation of model on certain specific events.
Or we can also combine both the approches and delay the updation of model only on certain specific events.

If there is an actual $scope value that is being used with ng-model in forms then that value will be updated only when the element validation is passed and form.element.$error is empty or form.element.$invalid = false;

Because of using debounce the validation also happens late because validation will take place only when model changes.

If we have multiple validators on an object then it will check all the validators without any order or blocking so if we have minlength and maxlength validator on same element then both will be run and status will be updated in form and element object like below.
"$error": {
  "phone": true,
  "minlength": true
},

block page reload or page close ( unload page )with a confirmation dialog
window.addEventListener("beforeunload", function (event) {
  event.returnValue = "\o/";
});
Detect hash change
$(window).on('hashchange', function() {
    alert('hello');
});

The root element of AngularJS application. This is either the element where ngApp was declared or the element passed into angular.bootstrap. The element represents the root element of application. It is also the location where the application's $injector service gets published, and can be retrieved using $rootElement.injector().

So while caseInsensitiveMatch flag is set to true whatever we have put in routeProvider registeration as the value of path the url wil have the same value 
So if we have PAGE is registeration and we trigger #!page then PAGE will be in route.

 reloadOnSearch: false which is by default  reloadOnSearch: true which means if we change $location.search or $location.hash then route will be reloaded.

 $route is used for deep-linking URLs to controllers and views (HTML partials). It watches $location.url() and tries to map the path to an existing route definition.
 The $route service is typically used in conjunction with the ngView directive and the $routeParams service.
Dependencies
$location
$routeParams

The $routeParams service allows you to retrieve the current set of route parameters.
The route parameters are a combination of $location's search() and path(). The path parameters are extracted when the $route path is matched.
In case of parameter name collision, path params take precedence over search params.

the route map defined in routeProvider config are used to update $route.current

$route have two methods 
reload and updateParams

$route has following structure
{routes: {…}, reload: ƒ, updateParams: ƒ, current: {…}}
current:{params: {…}, pathParams: {…}, $$route: {…}, loadedTemplateUrl: "views/page3.html", locals: {…}, …}
reload:ƒ ()
routes:{/: {…}, "": {…}, /page1/: {…}, /page1: {…}, /PAGE2: {…}, …}
updateParams:ƒ (newParams)

and current will have following structure which will have all the things related current matched route

$$route:{templateUrl: "views/page3.html", controller: Array(7), resolve: {…}, resolveAs: "deps", reloadOnSearch: true, …}
loadedTemplateUrl:"views/page3.html"
locals:{
  aps: {…}, 
  $template: "Page Three
  {{var}}
  <a class="btn btn-md btn-su…ick="changeSearch()"> click to change search </a>", 
  $scope: ChildScope
}
params:{age: "2000", name: "kushagra", location: "bangalore, india/300"}
pathParams:{name: "kushagra", location: "bangalore, india/300"}
scope:ChildScope {$$childTail: null, $$childHead: null, $$nextSibling: null, $$watchers: Array(1), $$listeners: {…}, …}

$$route is a subset of $route.routes in which it contains only currently matched route configuration from $route.routes
locals is equal to current.scope.$resolve
current.scope is scope of the current route controller.
params is equal to $routeParams.

:name matches everything till next /
location* matches everything till the end.

$route.updateParams({
    name: "mishra",
    age: 900,
    sibling: false
});
it will update any params whether it is $location.path params or $location.search params. Anything that is not matching will go to query params or $location.search 
updateParams Reloads the page

Note that the $routeParams are only updated after a route change completes successfully. This means that you cannot rely on $routeParams being correct in route resolve functions. Instead you can use $route.current.params to access the new route's parameters.

So $routeParams will only update when routeChangeSucces but $route.current.params will always have the current params.

Broadcasted before a route change. At this point the route services starts resolving all of the dependencies needed for the route change to occur. Typically this involves fetching the view template as well as any dependencies defined in resolve route property. Once all of the dependencies are resolved $routeChangeSuccess is fired.

The route change (and the $location change that triggered it) can be prevented by calling preventDefault method of the event.

Type:
broadcast
Target:
root scope
Parameters
Param	Type	Details
angularEvent	Object	
Synthetic event object.

next	Route	
Future route information.

current	Route	
Current route information.

$routeChangeSuccess
Broadcasted after a route change has happened successfully. The resolve dependencies are now available in the current.locals property.

ngView listens for the directive to instantiate the controller and render the view.
Type:
broadcast
Target:
root scope
Parameters
Param	Type	Details
angularEvent	Object	
Synthetic event object.

current	Route	
Current route information.

previous	RouteUndefined	
Previous route information, or undefined if current is first route entered.

$routeChangeError
Broadcasted if a redirection function fails or any redirection or resolve promises are rejected.

Type:
broadcast
Target:
root scope
Parameters
Param	Type	Details
angularEvent	Object	
Synthetic event object

current	Route	
Current route information.

previous	Route	
Previous route information.

rejection	Route	
The thrown error or the rejection reason of the promise. Usually the rejection reason is the error that caused the promise to get rejected.

$routeUpdate
The reloadOnSearch property has been set to false, and we are reusing the same instance of the Controller.

Type:
broadcast
Target:
root scope
Parameters
Param	Type	Details
angularEvent	Object	
Synthetic event object

current	Route	
Current/previous route information.

So we can think of a structure like 
next current previous
So for 
$routeChangeStart we have first two next and current
$routeChangeSuccess we have last two current and previous
$routeChangeError we have same as $routeChangeSuccess and rejection

target as root scope means the event originates from rootScope

The $location service parses the URL in the browser address bar (based on the window.location) and makes the URL available to your application. Changes to the URL in the address bar are reflected into $location service and changes to $location are reflected into the browser address bar.

replace();

If called, all changes to $location during the current $digest will replace the current history record, instead of adding a new one.

state([state]);

This method is getter / setter.

Return the history state object when called without any parameter.

Change the history state object when called with one parameter and return $location. The state object is later passed to pushState or replaceState.

NOTE: This method is supported only in HTML5 mode and only in browsers supporting the HTML5 History API (i.e. methods pushState and replaceState). If you need to support older browsers (like IE9 or Android < 4.0), don't use this method.

$locationChangeStart: this uses the $location provider and broadcasts whenever the URL changes. Location refers more to a Path of a specific URL. It's more like plain JavaScript, you can change to any path in your application and it doesn't matter if it's defined on your app as route or state.

$routeChangeStart: this uses the $route provider, and it's the same, it broadcasts when the route changes (default Angular router used with ngRoute). This is used to do a link between controllers and views.

The $http API is based on the deferred/promise APIs exposed by the $q service.

Returns
HttpPromise	
A Promise that will be resolved (request success) or rejected (request failure) with a response object.

The response object has these properties:

data – {string|Object} – The response body transformed with the transform functions.
status – {number} – HTTP status code of the response.
headers – {function([headerName])} – Header getter function.
config – {Object} – The configuration object that was used to generate the request.
statusText – {string} – HTTP status text of the response.
xhrStatus – {string} – Status of the XMLHttpRequest (complete, error, timeout or abort).
A response status code between 200 and 299 is considered a success status and will result in the success callback being called. Any response status code outside of that range is considered an error status and will result in the error callback being called. Also, status codes less than -1 are normalized to zero. -1 usually means the request was aborted, e.g. using a config.timeout. More information about the status might be available in the xhrStatus property.

eventHandlers and uploadEventHandlers are both used inside $apply block.

HTTP:  ƒ $http(requestConfig) {

if (!isObject(requestConfig)) {
  throw minErr('$http')('badreq', 'Http request configuration must be an object.  Received: {0}', requestConfig);
}

if…


HTTP Provider 

$HttpProvider 
{defaults: {…}, useApplyAsync: ƒ, interceptors: Array(0), $get: Array(9)}
$get:(9) ["$browser", "$httpBackend", "$$cookieReader", "$cacheFactory", "$rootScope", "$q", "$injector", "$sce", ƒ]
defaults:{transformResponse: Array(1), transformRequest: Array(1), headers: {…}, xsrfCookieName: "XSRF-TOKEN", xsrfHeaderName: "X-XSRF-TOKEN", …}
interceptors:[]
useApplyAsync:ƒ (value)

defaults:
  headers:{common: {…}, post: {…}, put: {…}, patch: {…}}
  jsonpCallbackParam:"callback"
  paramSerializer:ƒ ngParamSerializer(params)
  transformRequest:[ƒ]
  transformResponse:[ƒ]
  xsrfCookieName:"XSRF-TOKEN"
  xsrfHeaderName:"X-XSRF-TOKEN"

  $applyAsync([exp]);

Schedule the invocation of $apply to occur at a later time. The actual time difference varies across browsers, but is typically around ~10 milliseconds.

This can be used to queue up multiple expressions which need to be evaluated in the same digest.

$applyAsync([exp]);

Schedule the invocation of $apply to occur at a later time. The actual time difference varies across browsers, but is typically around ~10 milliseconds.

$apply([exp]);

$apply() is used to execute an expression in angular from outside of the angular framework. (For example from browser DOM events, setTimeout, XHR or third party libraries). Because we are calling into the angular framework we need to perform proper scope life cycle of exception handling, executing watches.

$http.prototype.constructor
defaults:{transformResponse: Array(1), transformRequest: Array(1), headers: {…}, xsrfCookieName: "XSRF-TOKEN", xsrfHeaderName: "X-XSRF-TOKEN", …}
delete:ƒ (url, config)
get:ƒ (url, config)
head:ƒ (url, config)
jsonp:ƒ (url, config)
patch:ƒ (url, data, config)
pendingRequests:[]
post:ƒ (url, data, config)
put:ƒ (url, data, config)

$http(requestConfig)
defaults:{transformResponse: Array(1), transformRequest: Array(1), headers: {…}, xsrfCookieName: "XSRF-TOKEN", xsrfHeaderName: "X-XSRF-TOKEN", …}
delete:ƒ (url, config)
get:ƒ (url, config)
head:ƒ (url, config)
jsonp:ƒ (url, config)
patch:ƒ (url, data, config)
pendingRequests:[]
post:ƒ (url, data, config)
put:ƒ (url, data, config)

Take note that Cache will:

Only GET and JSONP requests are cached.
The cache key is the request URL including search parameters; headers are not considered.
Cached responses are returned asynchronously, in the same way as responses from the server.
If multiple identical requests are made using the same cache, which is not yet populated, one request will be made to the server and remaining requests will return the same response.
A cache-control header on the response does not affect if or how responses are cached.

defaults
Object containing default values for all $http requests.

defaults.cache - {boolean|Object} - A boolean value or object created with $cacheFactory to enable or disable caching of HTTP responses by default. See $http Caching for more information.

defaults.headers - {Object} - Default headers for all $http requests. Refer to $http for documentation on setting default headers.

defaults.headers.common
defaults.headers.post
defaults.headers.put
defaults.headers.patch
defaults.jsonpCallbackParam - {string} - the name of the query parameter that passes the name of the callback in a JSONP request. The value of this parameter will be replaced with the expression generated by the $jsonpCallbacks service. Defaults to 'callback'.

defaults.paramSerializer - {string|function(Object<string,string>):string} - A function used to the prepare string representation of request parameters (specified as an object). If specified as string, it is interpreted as a function registered with the $injector. Defaults to $httpParamSerializer.

defaults.transformRequest - {Array<function(data, headersGetter)>|function(data, headersGetter)} - An array of functions (or a single function) which are applied to the request data. By default, this is an array with one request transformation function:

If the data property of the request configuration object contains an object, serialize it into JSON format.
defaults.transformResponse - {Array<function(data, headersGetter, status)>|function(data, headersGetter, status)} - An array of functions (or a single function) which are applied to the response data. By default, this is an array which applies one response transformation function that does two things:

If XSRF prefix is detected, strip it (see Security Considerations in the $http docs).
If the Content-Type is application/json or the response looks like JSON, deserialize it using a JSON parser.
defaults.xsrfCookieName - {string} - Name of cookie containing the XSRF token. Defaults value is 'XSRF-TOKEN'.

defaults.xsrfHeaderName - {string} - Name of HTTP header to populate with the XSRF token. Defaults value is 'X-XSRF-TOKEN'.

ng-repeat
track by will allow us to track the rendering of elements based on certain fields. It will keep track of the property and its associated element and the template being used with it.
So if we track by item.id then ng-repeat will keep track that which id was on which position and uses which template and hence when in future if we change the element with a certain id then instead of removing and re rendering the complete element it will just update that element.

By default if we remove or change anything from the collection ng-repeat will have to update all the elements. Remove and then re add them.

By default ng-repeat will track everything with $id(item). $id being an internally generated integer value.

One-time binding
An expression that starts with :: is considered a one-time expression. One-time expressions will stop recalculating once they are stable, which happens after the first digest if the expression result is a non-undefined value (see value stabilization algorithm below).

To repeat a series of elements instead of just one parent element, ngRepeat (as well as other ng directives) supports extending the range of the repeater by defining explicit start and end points by using ng-repeat-start and ng-repeat-end respectively. The ng-repeat-start directive works the same as ng-repeat, but will repeat all the HTML code (including the tag it's defined on) up to and including the ending HTML tag where ng-repeat-end is placed.

item in items | filter : x | orderBy : order | limitTo : limit as results track by item.id

the track by expression must come last - after any filters, and the alias expression: item in items | filter:searchText as results track by item.id

While working with track by on ng-options it overrites the value returned from select as.
select as will set the value of options.

Angular components
Components have isolated scopes by default.
They automatically use controllerAs syntax therefore we can use $ctrl to access component data.
They use controllers instead of link functions.
The bindToController option is on by default.

// before
app.directive(name, fn)

// after
app.component(name, options)

can be created on Elements only and not on comments or class or attributes.

difference between < and @ is that @ is suitable for simple expressions like number or string but if we need complex expressions like object or array then in that case with @ we will have to take value only which will have to be assigned on a attribute on the directive or component element as plain open text but with < we can refer such complex expression as variables as in case with =.
In case of @ the element is treated as string so if object or array is used it won't be usable inside ng-repeat sort of things.

When working with ng-repeat then if we want to convert string to object then we need to be carefull because if we directly return from JSON.parse it means that every time we are creating new object which means as ng-repeat shallow watches the collections it will trigger change as a result data will be again rendered in dom which will again call filter which in turn will again return new object . this creates an infinite loop and we get digest error that iteration are more than 10.

inside component we always get $ctrl . A controller is implemented internally who controllerAs is $ctrl.So even if we don't specify controller we have a controller created internally.

in components controller gets executed first before any other binding are done. So thats why this.parent and this.name etc from bindings object are not available initially in controller.

This change coming from the parent will trigger $onChanges in the child. Parent changes results in child components getting told about it. That’s it.

$onInit happens when all controllers are constructed and dependencies resolved. We can put out initilization code here and initialize some variables.

$postLink happens when all the child templates and data are ready and inserted into parent only transclude is left.

Setting base href to a certain value will make the scripts and style to be loaded from that base path.
<base href='/learning/ui/component-router.html/' />
So now in above the scripts an styles will be loaded from /learning/ui/component-router.html/

The Lifecycle Hooks that can be implemented as instance methods on the Component are as follows:

$routerCanReuse : called to to determine whether a Component can be reused across Route Definitions that match the same type of Component, or whether to destroy and instantiate a new Component every time.
$routerOnActivate / $routerOnReuse : called by the Router at the end of a successful navigation. Only one of $routerOnActivate and $routerOnReuse will be called depending upon the result of a call to $routerCanReuse.
$routerCanDeactivate : called by the Router to determine if a Component can be removed as part of a navigation.
$routerOnDeactivate : called by the Router before destroying a Component as part of a navigation.

Each component has its own Router.

Unlike in the new Angular, we cannot use the dependency injector to get hold of a component's Router. We can only inject the $rootRouter. Instead we use the fact that the ng-outlet directive binds the current router to a $router attribute on our component.

$$router is current router.

bindings: { $router: '<' }

The binding is available once the component has been activated, and the $routerOnActivate hook is called.

As you might know from reading the component guide, the binding is actually available by the time the $onInit hook is called, which is before the call to $routerOnActivate.
After getting the $router we can try to naviagte to different places.
this.$router.navigate(['HeroList']);

manually create the URL and call this.$router.navigateByUrl(url) - this is discouraged because it couples the code of your component to the router URLs.
generate an Instruction for a route and navigate directly with this instruction.
var instruction = this.$router.generate(['HeroList']);
this.$router.navigateByInstruction(instruction);
this form gives you the possibility of caching the instruction, but is more verbose.

But if we want to navigate to a nested route we need to pass all the routes like this 
['App', 'Heroes', 'HeroDetails']


We can also pass additional optional parameters to routes, which get encoded into the URL and are again available to the $routerOnActivate(next, previous) hook.

this.$router.navigate(['HeroList', {id: heroId}]);

The Object.assign() method is used to copy the values of all enumerable own properties from one or more source objects to a target object. It will return the target object.
Object.assign(target, ...sources)

The Object.is() method determines whether two values are the same value
Object.is(value1, value2);

Object.is('foo', 'foo');     // true
Object.is(window, window);   // true